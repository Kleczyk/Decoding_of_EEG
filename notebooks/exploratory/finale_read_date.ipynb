{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Import libraries"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T19:49:56.670337Z",
     "start_time": "2024-06-04T19:49:55.590988Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mne  # library for reading edf files\n",
    "import pywt  # library for continuous wavelet transform\n",
    "import sqlite3\n",
    "import pickle\n",
    "from tqdm import tqdm\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Create functions to read data from file and save to database"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T19:49:56.682619Z",
     "start_time": "2024-06-04T19:49:56.672413Z"
    }
   },
   "source": [
    "def file_to_DataDrame(path):\n",
    "    \"\"\"\n",
    "    This function takes in a file path and returns a dataframe with the data and the target values\n",
    "\n",
    "    Args:\n",
    "        path (str): The path to the file\n",
    "    Returns:\n",
    "        pd.DataFrame: The dataframe containing the data and the target values\n",
    "    Examples:\n",
    "        >>> df = file_to_DataDrame(\"data/S001/S001R03.edf\")\n",
    "        >>> print(df)\n",
    "            Fc5\t        Fc3\t        Fc1\t        ...\tOz\t        O2\t        Iz\t        target     \n",
    "        0\t-0.000046\t-0.000041\t-0.000032\t...\t0.000040\t0.000108\t0.000055\t0\n",
    "        1    -0.000054\t-0.000048\t-0.000034\t...\t0.000064\t0.000114\t0.000074\t0\n",
    "        ...\n",
    "    \"\"\"\n",
    "\n",
    "    reader = mne.io.read_raw_edf(path, preload=True)\n",
    "    annotations = reader.annotations  # get the values of the annotations\n",
    "    codes = annotations.description  # get the codes from the annotations\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        reader.get_data().T,\n",
    "        columns=[channel.replace(\".\", \"\") for channel in reader.ch_names],\n",
    "    )  # transpose the data to get the right shape\n",
    "    df = df[~(df == 0).all(axis=1)]  # remove rows with all zeros\n",
    "    timeArray = np.array(\n",
    "        [round(x, 10) for x in np.arange(0, len(df) / 160, 0.00625)]\n",
    "    )  # create an array of time values treanig \n",
    "\n",
    "    codeArray = []\n",
    "    counter = 0\n",
    "    for timeVal in timeArray:\n",
    "        if (\n",
    "                timeVal in annotations.onset\n",
    "        ):\n",
    "            counter += 1\n",
    "        code_of_target = int(\n",
    "            codes[counter - 1].replace(\"T\", \"\")\n",
    "        )\n",
    "        codeArray.append(code_of_target)\n",
    "\n",
    "    df[\"target\"] = np.array(codeArray).T\n",
    "    return df\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T19:49:59.865383Z",
     "start_time": "2024-06-04T19:49:59.859572Z"
    }
   },
   "source": [
    "def read_all_file_df(num_exp=[3, 4], num_people=[1, 2], path=\"../../data/raw/\"):\n",
    "    \"\"\"\n",
    "    This function reads all the files in the path and returns a dataframe with the data and the target values\n",
    "    format:\n",
    "        Fc5\t        Fc3\t        Fc1\t        ...\tOz\t        O2\t        Iz\t        target\n",
    "    0\t-0.000046\t-0.000041\t-0.000032\t...\t0.000040\t0.000108\t0.000055\t0\n",
    "    1    -0.000054\t-0.000048\t-0.000034\t...\t0.000064\t0.000114\t0.000074\t0\n",
    "    ...\n",
    "    Args:\n",
    "        num_exp (list): The list of experiments to read\n",
    "        num_people (list): The list of people to read\n",
    "        path (str): The path to the files\n",
    "    Returns:\n",
    "        pd.DataFrame: The dataframe containing the data and the target values\n",
    "    \"\"\"\n",
    "    all_df = pd.DataFrame()\n",
    "    for subject in num_people:\n",
    "        for file in num_exp:\n",
    "            fileName = f\"{path}/S{subject:03d}/S{subject:03d}R{file:02d}.edf\"\n",
    "            df = file_to_DataDrame(fileName)\n",
    "            all_df = pd.concat([all_df, df], axis=0)\n",
    "    return all_df"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import psycopg2\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "def create_database(dbname, user, password, host):\n",
    "    conn = psycopg2.connect(dbname=dbname, user=user, password=password, host=host)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\n",
    "        \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS wavelet_transforms (\n",
    "            id SERIAL PRIMARY KEY,\n",
    "            cwt_data BYTEA,\n",
    "            target INTEGER\n",
    "        )\n",
    "        \"\"\"\n",
    "    )\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "def insert_cwt_data(dbname, user, password, host, cwt_data, targets):\n",
    "    conn = psycopg2.connect(dbname=dbname, user=user, password=password, host=host)\n",
    "    cursor = conn.cursor()\n",
    "    cwt_data = cwt_data.transpose(2, 0, 1)\n",
    "    cwt_data = cwt_data.reshape(cwt_data.shape[0], -1)\n",
    "\n",
    "    for i, single_cwt in enumerate(cwt_data):\n",
    "        cwt_blob = pickle.dumps(np.array(single_cwt, dtype=np.float32))\n",
    "        cursor.execute(\n",
    "            \"INSERT INTO wavelet_transforms (cwt_data, target) VALUES (%s, %s)\",\n",
    "            (psycopg2.Binary(cwt_blob), targets[i]),\n",
    "        )\n",
    "    \n",
    "    conn.commit()\n",
    "    conn.close()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import psycopg2\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "def create_database(dbname, user, password, host):\n",
    "    conn = psycopg2.connect(dbname=dbname, user=user, password=password, host=host)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\n",
    "        \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS wavelet_transforms (\n",
    "            id SERIAL PRIMARY KEY,\n",
    "            cwt_data BYTEA,\n",
    "            target INTEGER\n",
    "        )\n",
    "        \"\"\"\n",
    "    )\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "def insert_cwt_data(dbname=, user, password, host, cwt_data, targets):\n",
    "    conn = psycopg2.connect(dbname=dbname, user=user, password=password, host=host)\n",
    "    cursor = conn.cursor()\n",
    "    cwt_data = cwt_data.transpose(2, 0, 1)\n",
    "    cwt_data = cwt_data.reshape(cwt_data.shape[0], -1)\n",
    "\n",
    "    for i, single_cwt in enumerate(cwt_data):\n",
    "        cwt_blob = pickle.dumps(np.array(single_cwt, dtype=np.float32))\n",
    "        cursor.execute(\n",
    "            \"INSERT INTO wavelet_transforms (cwt_data, target) VALUES (%s, %s)\",\n",
    "            (psycopg2.Binary(cwt_blob), targets[i]),\n",
    "        )\n",
    "    \n",
    "    conn.commit()\n",
    "    conn.close()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T12:14:39.515004Z",
     "start_time": "2024-05-15T12:14:39.507044Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# from tqdm import tqdm\n",
    "# import numpy as np\n",
    "# import pywt\n",
    "# \n",
    "# def df_to_CWTfiles(\n",
    "#         df, num_of_rows=1000, wave=\"cgau4\", frq=160, resolution=100, db_path=\"cwt_data.db\"\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     This function takes in a dataframe and saves the continuous wavelet transform of the signals to a database.\n",
    "# \n",
    "#     Args:\n",
    "#         df (pd.DataFrame): The dataframe containing the signals\n",
    "#         num_of_rows (int): The number of rows to process \n",
    "#         wave (str): The type of wave to use\n",
    "#         frq (int): The frequency of the signals\n",
    "#         resolution (int): The resolution of the wavelet transform\n",
    "#         db_path (str): The path to the database\n",
    "#     Returns:\n",
    "#         None\n",
    "#     \"\"\"\n",
    "#     create_database(db_path)  # Ensure this function is defined elsewhere in your code.\n",
    "# \n",
    "#     # Calculate the number of chunks to process\n",
    "#     num_chunks = len(df) // num_of_rows + (1 if len(df) % num_of_rows != 0 else 0)\n",
    "#     \n",
    "#     # Create a tqdm progress bar for the loop\n",
    "#     for i in range(0, len(df), num_of_rows):\n",
    "#         end_index = i + num_of_rows\n",
    "#         if end_index > len(df):\n",
    "#             end_index = len(df)\n",
    "#         signals = df.iloc[i:end_index].values\n",
    "#         list_cwt = []\n",
    "# \n",
    "#         if signals.shape == (num_of_rows, 65):\n",
    "#             signals = signals.transpose(1, 0)\n",
    "#         \n",
    "#         for signal in signals[:-1]:  # Exclude the last item assuming it's the target\n",
    "#             signal = (signal - np.min(signal)) / (np.max(signal) - np.min(signal))\n",
    "#             time = np.linspace(0, len(signal) / frq, len(signal))\n",
    "#             widths = np.geomspace(1, 200, num=resolution)\n",
    "#             sampling_period = np.diff(time).mean()\n",
    "#             cwtmatr, freqs = pywt.cwt(\n",
    "#                 signal, widths, wave, sampling_period=sampling_period\n",
    "#             )\n",
    "#             cwtmatr = np.abs(cwtmatr)\n",
    "#             list_cwt.append(cwtmatr)\n",
    "# \n",
    "#         targets = signals[-1]  # Assuming the last row are the targets\n",
    "#         array_cwt = np.stack(list_cwt, axis=0)\n",
    "#         insert_cwt_data(db_path, array_cwt, targets)  # Ensure this function is defined elsewhere in your code.\n",
    "#         del array_cwt\n"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def df_to_CWTdb(\n",
    "        df, num_of_rows=1000, wave=\"cgau4\", frq=160, resolution=100, db_path=\"cwt_data.db\"\n",
    "):\n",
    "    create_database(dbname=\"mydatabase\", user='myuser', password='mysecretpassword', host=5432)\n",
    "\n",
    "    for i in range(0, len(df), num_of_rows):\n",
    "        if i + num_of_rows > len(df):\n",
    "            break\n",
    "        signals = df.iloc[i: i + num_of_rows].values\n",
    "        list_cwt = []\n",
    "        targets = ()\n",
    "        if signals.shape == (num_of_rows, 65):\n",
    "            signals = signals.transpose(1, 0)\n",
    "        j = 0\n",
    "        # print(len(signals))\n",
    "        for signal in signals:\n",
    "            j += 1\n",
    "            if j == len(signals):\n",
    "                targets = signal\n",
    "                break\n",
    "            signal = (signal - np.min(signal)) / (np.max(signal) - np.min(signal))\n",
    "            time = np.linspace(0, len(signal) / frq, len(signal))\n",
    "            widths = np.geomspace(1, 200, num=resolution)\n",
    "            sampling_period = np.diff(time).mean()\n",
    "            cwtmatr, freqs = pywt.cwt(\n",
    "                signal, widths, wave, sampling_period=sampling_period\n",
    "            )\n",
    "            cwtmatr = np.abs(cwtmatr)\n",
    "            list_cwt.append(cwtmatr)\n",
    "\n",
    "        array_cwt = np.stack(list_cwt, axis=0)\n",
    "        insert_cwt_data(dbname=\"mydatabase\", user=\"myuser\", password='mysecretpassword',host=5432, cwt_data=array_cwt, targets= targets )\n",
    "        # Zapis do bazy danych\n",
    "        del array_cwt"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Reading data"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is done in experiment\n",
    "\n",
    "1. Baseline, eyes open\n",
    "2. Baseline, eyes closed\n",
    "3. Task 1 (open and close left or right fist)\n",
    "4. Task 2 (imagine opening and closing left or right fist)\n",
    "5. Task 3 (open and close both fists or both feet)\n",
    "6. Task 4 (imagine opening and closing both fists or both feet)\n",
    "7. Task 1\n",
    "8. Task 2\n",
    "9. Task 3\n",
    "10. Task 4\n",
    "11. Task 1\n",
    "12. Task 2\n",
    "13. Task 3\n",
    "14. Task 4"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Read data from files to dataframe"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T19:54:54.075019Z",
     "start_time": "2024-06-04T19:54:51.147382Z"
    }
   },
   "source": [
    "df_train = read_all_file_df([3, 7], [1, 2, 3], path=\"../../data/raw/\")\n",
    "df_val = read_all_file_df([3, 7], [5, 6], path=\"../../data/raw/\") "
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from /home/daniel/repos/Decoding_of_EEG/data/raw/S001/S001R03.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Extracting EDF parameters from /home/daniel/repos/Decoding_of_EEG/data/raw/S001/S001R07.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Extracting EDF parameters from /home/daniel/repos/Decoding_of_EEG/data/raw/S002/S002R03.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19679  =      0.000 ...   122.994 secs...\n",
      "Extracting EDF parameters from /home/daniel/repos/Decoding_of_EEG/data/raw/S002/S002R07.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19679  =      0.000 ...   122.994 secs...\n",
      "Extracting EDF parameters from /home/daniel/repos/Decoding_of_EEG/data/raw/S003/S003R03.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Extracting EDF parameters from /home/daniel/repos/Decoding_of_EEG/data/raw/S003/S003R07.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Extracting EDF parameters from /home/daniel/repos/Decoding_of_EEG/data/raw/S005/S005R03.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19679  =      0.000 ...   122.994 secs...\n",
      "Extracting EDF parameters from /home/daniel/repos/Decoding_of_EEG/data/raw/S005/S005R07.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19679  =      0.000 ...   122.994 secs...\n",
      "Extracting EDF parameters from /home/daniel/repos/Decoding_of_EEG/data/raw/S006/S006R03.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19679  =      0.000 ...   122.994 secs...\n",
      "Extracting EDF parameters from /home/daniel/repos/Decoding_of_EEG/data/raw/S006/S006R07.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19679  =      0.000 ...   122.994 secs...\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Transform data to CWT and save to database"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T20:36:25.052634Z",
     "start_time": "2024-06-04T20:34:09.783806Z"
    }
   },
   "source": [
    "df_to_CWTdb(\n",
    "    df_val, num_of_rows=1000, wave=\"cgau4\", frq=160, resolution=10, db_path=\"./df_val_cwt_data.db\"\n",
    ")\n",
    "df_to_CWTdb(\n",
    "    df_train, num_of_rows=1000, wave=\"cgau4\", frq=160, resolution=10,\n",
    "    db_path=\"./df_train_cwt_data.db\"\n",
    ")"
   ],
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "connection to server at \"2222\" (0.0.8.174), port 5432 failed: Connection timed out\n\tIs the server running on that host and accepting TCP/IP connections?\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mOperationalError\u001B[0m                          Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[17], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mdf_to_CWTdb\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      2\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdf_val\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_of_rows\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1000\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwave\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcgau4\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrq\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m160\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mresolution\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdb_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m./df_val_cwt_data.db\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\n\u001B[1;32m      3\u001B[0m \u001B[43m)\u001B[49m\n\u001B[1;32m      4\u001B[0m df_to_CWTdb(\n\u001B[1;32m      5\u001B[0m     df_train, num_of_rows\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1000\u001B[39m, wave\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcgau4\u001B[39m\u001B[38;5;124m\"\u001B[39m, frq\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m160\u001B[39m, resolution\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m,\n\u001B[1;32m      6\u001B[0m     db_path\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m./df_train_cwt_data.db\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m      7\u001B[0m )\n",
      "Cell \u001B[0;32mIn[11], line 4\u001B[0m, in \u001B[0;36mdf_to_CWTdb\u001B[0;34m(df, num_of_rows, wave, frq, resolution, db_path)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdf_to_CWTdb\u001B[39m(\n\u001B[1;32m      2\u001B[0m         df, num_of_rows\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1000\u001B[39m, wave\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcgau4\u001B[39m\u001B[38;5;124m\"\u001B[39m, frq\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m160\u001B[39m, resolution\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m100\u001B[39m, db_path\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcwt_data.db\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m      3\u001B[0m ):\n\u001B[0;32m----> 4\u001B[0m     \u001B[43mcreate_database\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdbname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmydatabase\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muser\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmyuser\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpassword\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmysecretpassword\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhost\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m2222\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      6\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;28mlen\u001B[39m(df), num_of_rows):\n\u001B[1;32m      7\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m i \u001B[38;5;241m+\u001B[39m num_of_rows \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mlen\u001B[39m(df):\n",
      "Cell \u001B[0;32mIn[5], line 6\u001B[0m, in \u001B[0;36mcreate_database\u001B[0;34m(dbname, user, password, host)\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcreate_database\u001B[39m(dbname, user, password, host):\n\u001B[0;32m----> 6\u001B[0m     conn \u001B[38;5;241m=\u001B[39m \u001B[43mpsycopg2\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconnect\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdbname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdbname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muser\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muser\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpassword\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpassword\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhost\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhost\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      7\u001B[0m     cursor \u001B[38;5;241m=\u001B[39m conn\u001B[38;5;241m.\u001B[39mcursor()\n\u001B[1;32m      8\u001B[0m     cursor\u001B[38;5;241m.\u001B[39mexecute(\n\u001B[1;32m      9\u001B[0m \u001B[38;5;250m        \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;124;03m        CREATE TABLE IF NOT EXISTS wavelet_transforms (\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;124;03m        \"\"\"\u001B[39;00m\n\u001B[1;32m     16\u001B[0m     )\n",
      "File \u001B[0;32m~/miniconda3/envs/EEG311/lib/python3.11/site-packages/psycopg2/__init__.py:122\u001B[0m, in \u001B[0;36mconnect\u001B[0;34m(dsn, connection_factory, cursor_factory, **kwargs)\u001B[0m\n\u001B[1;32m    119\u001B[0m     kwasync[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124masync_\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m kwargs\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124masync_\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    121\u001B[0m dsn \u001B[38;5;241m=\u001B[39m _ext\u001B[38;5;241m.\u001B[39mmake_dsn(dsn, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m--> 122\u001B[0m conn \u001B[38;5;241m=\u001B[39m \u001B[43m_connect\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdsn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconnection_factory\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconnection_factory\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwasync\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    123\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cursor_factory \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    124\u001B[0m     conn\u001B[38;5;241m.\u001B[39mcursor_factory \u001B[38;5;241m=\u001B[39m cursor_factory\n",
      "\u001B[0;31mOperationalError\u001B[0m: connection to server at \"2222\" (0.0.8.174), port 5432 failed: Connection timed out\n\tIs the server running on that host and accepting TCP/IP connections?\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "df_train",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_val",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def df_to_CWT(\n",
    "        df, num_of_rows=1000, wave=\"cgau4\", frq=160, resolution=100, db_path=\"cwt_data.db\"\n",
    "):\n",
    "    create_database(db_path)\n",
    "\n",
    "    for i in range(0, len(df), num_of_rows):\n",
    "        if i + num_of_rows > len(df):\n",
    "            break\n",
    "        signals = df.iloc[i: i + num_of_rows].values\n",
    "        list_cwt = []\n",
    "        targets = ()\n",
    "        if signals.shape == (num_of_rows, 65):\n",
    "            signals = signals.transpose(1, 0)\n",
    "        j = 0\n",
    "        for signal in signals:\n",
    "            j += 1\n",
    "            if j == len(signals):\n",
    "                targets = signal\n",
    "                break\n",
    "            signal = (signal - np.min(signal)) / (np.max(signal) - np.min(signal))\n",
    "            time = np.linspace(0, len(signal) / frq, len(signal))\n",
    "            widths = np.geomspace(1, 200, num=resolution)\n",
    "            sampling_period = np.diff(time).mean()\n",
    "            cwtmatr, freqs = pywt.cwt(\n",
    "                signal, widths, wave, sampling_period=sampling_period\n",
    "            )\n",
    "            cwtmatr = np.abs(cwtmatr)\n",
    "            list_cwt.append(cwtmatr)\n",
    "\n",
    "        array_cwt = np.stack(list_cwt, axis=0)\n",
    "        return array_cwt, targets  # Zapis do bazy danych\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "cwt, targ = df_to_CWT(\n",
    "    df, num_of_rows=1000, wave=\"cgau4\", frq=160, resolution=10, db_path=\"cwt_data.db\"\n",
    ")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "array_cwt.shape",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (EEG311)",
   "language": "python",
   "name": "eeg311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
