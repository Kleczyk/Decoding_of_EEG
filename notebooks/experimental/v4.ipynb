{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Import libraries"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T15:52:32.409648Z",
     "start_time": "2024-05-11T15:52:31.688685Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mne  # library for reading edf files\n",
    "import pywt  # library for continuous wavelet transform\n",
    "import sqlite3\n",
    "import pickle\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Create functions to read data from file and save to database"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T15:52:32.418579Z",
     "start_time": "2024-05-11T15:52:32.411469Z"
    }
   },
   "source": [
    "def file_to_DataDrame(path):\n",
    "    \"\"\"\n",
    "    This function takes in a file path and returns a dataframe with the data and the target values\n",
    "\n",
    "    Args:\n",
    "        path (str): The path to the file\n",
    "    Returns:\n",
    "        pd.DataFrame: The dataframe containing the data and the target values\n",
    "    Examples:\n",
    "        >>> df = file_to_DataDrame(\"data/S001/S001R03.edf\")\n",
    "        >>> print(df)\n",
    "            Fc5\t        Fc3\t        Fc1\t        ...\tOz\t        O2\t        Iz\t        target     \n",
    "        0\t-0.000046\t-0.000041\t-0.000032\t...\t0.000040\t0.000108\t0.000055\t0\n",
    "        1    -0.000054\t-0.000048\t-0.000034\t...\t0.000064\t0.000114\t0.000074\t0\n",
    "        ...\n",
    "    \"\"\"\n",
    "\n",
    "    reader = mne.io.read_raw_edf(path, preload=True)\n",
    "    annotations = reader.annotations  # get the values of the annotations\n",
    "    codes = annotations.description  # get the codes from the annotations\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        reader.get_data().T,\n",
    "        columns=[channel.replace(\".\", \"\") for channel in reader.ch_names],\n",
    "    )  # transpose the data to get the right shape\n",
    "    df = df[~(df == 0).all(axis=1)]  # remove rows with all zeros\n",
    "    timeArray = np.array(\n",
    "        [round(x, 10) for x in np.arange(0, len(df) / 160, 0.00625)]\n",
    "    )  # create an array of time values\n",
    "\n",
    "    codeArray = []\n",
    "    counter = 0\n",
    "    for timeVal in timeArray:\n",
    "        if (\n",
    "                timeVal in annotations.onset\n",
    "        ):\n",
    "            counter += 1\n",
    "        code_of_target = int(\n",
    "            codes[counter - 1].replace(\"T\", \"\")\n",
    "        )\n",
    "        codeArray.append(code_of_target)\n",
    "\n",
    "    df[\"target\"] = np.array(codeArray).T\n",
    "    return df\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T15:52:32.432451Z",
     "start_time": "2024-05-11T15:52:32.421230Z"
    }
   },
   "source": [
    "def read_all_file_df(num_exp=[3, 4], num_people=[1, 2], path=\"../../data/raw/\"):\n",
    "    \"\"\"\n",
    "    This function reads all the files in the path and returns a dataframe with the data and the target values\n",
    "    format:\n",
    "        Fc5\t        Fc3\t        Fc1\t        ...\tOz\t        O2\t        Iz\t        target\n",
    "    0\t-0.000046\t-0.000041\t-0.000032\t...\t0.000040\t0.000108\t0.000055\t0\n",
    "    1    -0.000054\t-0.000048\t-0.000034\t...\t0.000064\t0.000114\t0.000074\t0\n",
    "    ...\n",
    "    Args:\n",
    "        num_exp (list): The list of experiments to read\n",
    "        num_people (list): The list of people to read\n",
    "        path (str): The path to the files\n",
    "    Returns:\n",
    "        pd.DataFrame: The dataframe containing the data and the target values\n",
    "    \"\"\"\n",
    "    all_df = pd.DataFrame()\n",
    "    for subject in num_people:\n",
    "        for file in num_exp:\n",
    "            fileName = f\"{path}/S{subject:03d}/S{subject:03d}R{file:02d}.edf\"\n",
    "            df = file_to_DataDrame(fileName)\n",
    "            all_df = pd.concat([all_df, df], axis=0)\n",
    "    return all_df"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def create_database(db_path):\n",
    "    \"\"\" \n",
    "    This function creates a database with a table to store the continuous wavelet transform of the signals\n",
    "    \n",
    "    Args:\n",
    "        db_path (str): The path to the database\n",
    "    Returns:\n",
    "        None\n",
    "    examples:\n",
    "        >>> create_database(\"cwt_data.db\")\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\n",
    "        \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS wavelet_transforms (\n",
    "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "            cwt_data BLOB,\n",
    "            target INTEGER\n",
    "        )\n",
    "    \"\"\"\n",
    "    )\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "\n",
    "def insert_cwt_data(db_path, cwt_data, targets):\n",
    "    \"\"\"\n",
    "    This function takes in the continuous wavelet transform of the signals and the target values and saves them to a database\n",
    "    Args:\n",
    "        db_path (str): The path to the database\n",
    "        cwt_data (np.array): The continuous wavelet transform of the signals\n",
    "        targets (np.array): The target values\n",
    "    Returns:\n",
    "        None\n",
    "    Examples:\n",
    "        >>> insert_cwt_data(\"cwt_data.db\", cwt_data, targets)\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "    cwt_data = cwt_data.transpose(2, 0, 1)\n",
    "\n",
    "    cwt_data = cwt_data.reshape(cwt_data.shape[0], -1)  # <-------- this is option \n",
    "    print(f\"success save: {cwt_data.shape}\")\n",
    "    i = 0\n",
    "    for single_cwt in cwt_data:\n",
    "        cwt_blob = pickle.dumps(np.array(single_cwt, dtype=np.float32))\n",
    "        cursor.execute(\n",
    "            \"INSERT INTO wavelet_transforms (cwt_data, target) VALUES (?, ?)\",\n",
    "            (cwt_blob, targets[i]),\n",
    "        )\n",
    "        i += 1\n",
    "    conn.commit()\n",
    "    conn.close()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def df_to_CWTfiles(\n",
    "        df, num_of_rows=1000, wave=\"cgau4\", frq=160, resolution=100, db_path=\"cwt_data.db\"\n",
    "):\n",
    "    \"\"\"\n",
    "    This function takes in a dataframe and saves the continuous wavelet transform of the signals to a database\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The dataframe containing the signals\n",
    "        num_of_rows (int): The number of rows to process \n",
    "        wave (str): The type of wave to use\n",
    "        frq (int): The frequency of the signals\n",
    "        resolution (int): The resolution of the wavelet transform\n",
    "        db_path (str): The path to the database\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    create_database(db_path)\n",
    "\n",
    "    for i in range(0, len(df), num_of_rows):\n",
    "        if i + num_of_rows > len(df):\n",
    "            break\n",
    "        signals = df.iloc[i: i + num_of_rows].values\n",
    "        list_cwt = []\n",
    "        targets = ()\n",
    "        if signals.shape == (num_of_rows, 65):\n",
    "            signals = signals.transpose(1, 0)\n",
    "        j = 0\n",
    "        for signal in signals:\n",
    "            j += 1\n",
    "            if j == len(signals):\n",
    "                targets = signal\n",
    "                break\n",
    "            signal = (signal - np.min(signal)) / (np.max(signal) - np.min(signal))\n",
    "            time = np.linspace(0, len(signal) / frq, len(signal))\n",
    "            widths = np.geomspace(1, 200, num=resolution)\n",
    "            sampling_period = np.diff(time).mean()\n",
    "            cwtmatr, freqs = pywt.cwt(\n",
    "                signal, widths, wave, sampling_period=sampling_period\n",
    "            )\n",
    "            cwtmatr = np.abs(cwtmatr)\n",
    "            list_cwt.append(cwtmatr)\n",
    "\n",
    "        array_cwt = np.stack(list_cwt, axis=0)\n",
    "        insert_cwt_data(db_path, array_cwt, targets)\n",
    "        del array_cwt"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Reading data from files"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is done in experiment\n",
    "\n",
    "1. Baseline, eyes open\n",
    "2. Baseline, eyes closed\n",
    "3. Task 1 (open and close left or right fist)\n",
    "4. Task 2 (imagine opening and closing left or right fist)\n",
    "5. Task 3 (open and close both fists or both feet)\n",
    "6. Task 4 (imagine opening and closing both fists or both feet)\n",
    "7. Task 1\n",
    "8. Task 2\n",
    "9. Task 3\n",
    "10. Task 4\n",
    "11. Task 1\n",
    "12. Task 2\n",
    "13. Task 3\n",
    "14. Task 4"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T15:54:52.774403Z",
     "start_time": "2024-05-11T15:54:52.622299Z"
    }
   },
   "source": [
    "df_train = read_all_file_df([3, 7], [1, 2, 3])\n",
    "df_val = read_all_file_df([3, 7], [5, 6])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from /home/daniel/repos/Decoding_of_EEG/data/raw/S001/S001R03.edf...\n",
      "EDF file detected\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/daniel/repos/Decoding_of_EEG/data/raw/S001/S001R03.edf'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m df_train \u001B[38;5;241m=\u001B[39m \u001B[43mread_all_file_df\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m7\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m df_val \u001B[38;5;241m=\u001B[39m read_all_file_df([\u001B[38;5;241m3\u001B[39m, \u001B[38;5;241m7\u001B[39m], [\u001B[38;5;241m5\u001B[39m, \u001B[38;5;241m6\u001B[39m])\n",
      "Cell \u001B[0;32mIn[3], line 20\u001B[0m, in \u001B[0;36mread_all_file_df\u001B[0;34m(num_exp, num_people, path)\u001B[0m\n\u001B[1;32m     18\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m file \u001B[38;5;129;01min\u001B[39;00m num_exp:\n\u001B[1;32m     19\u001B[0m         fileName \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpath\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/S\u001B[39m\u001B[38;5;132;01m{\u001B[39;00msubject\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m03d\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/S\u001B[39m\u001B[38;5;132;01m{\u001B[39;00msubject\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m03d\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124mR\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfile\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m02d\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.edf\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m---> 20\u001B[0m         df \u001B[38;5;241m=\u001B[39m \u001B[43mfile_to_DataDrame\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfileName\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     21\u001B[0m         all_df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mconcat([all_df, df], axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m     22\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m all_df\n",
      "Cell \u001B[0;32mIn[2], line 18\u001B[0m, in \u001B[0;36mfile_to_DataDrame\u001B[0;34m(path)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfile_to_DataDrame\u001B[39m(path):\n\u001B[1;32m      2\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;124;03m    This function takes in a file path and returns a dataframe with the data and the target values\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;124;03m        ...\u001B[39;00m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m---> 18\u001B[0m     reader \u001B[38;5;241m=\u001B[39m \u001B[43mmne\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mio\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_raw_edf\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpreload\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m     19\u001B[0m     annotations \u001B[38;5;241m=\u001B[39m reader\u001B[38;5;241m.\u001B[39mannotations  \u001B[38;5;66;03m# get the values of the annotations\u001B[39;00m\n\u001B[1;32m     20\u001B[0m     codes \u001B[38;5;241m=\u001B[39m annotations\u001B[38;5;241m.\u001B[39mdescription  \u001B[38;5;66;03m# get the codes from the annotations\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/EEG311/lib/python3.11/site-packages/mne/io/edf/edf.py:1675\u001B[0m, in \u001B[0;36mread_raw_edf\u001B[0;34m(input_fname, eog, misc, stim_channel, exclude, infer_types, include, preload, units, encoding, verbose)\u001B[0m\n\u001B[1;32m   1673\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ext \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124medf\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m   1674\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOnly EDF files are supported, got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mext\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m-> 1675\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mRawEDF\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1676\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_fname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_fname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1677\u001B[0m \u001B[43m    \u001B[49m\u001B[43meog\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meog\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1678\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmisc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmisc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1679\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstim_channel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstim_channel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1680\u001B[0m \u001B[43m    \u001B[49m\u001B[43mexclude\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mexclude\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1681\u001B[0m \u001B[43m    \u001B[49m\u001B[43minfer_types\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minfer_types\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1682\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpreload\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpreload\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1683\u001B[0m \u001B[43m    \u001B[49m\u001B[43minclude\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minclude\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1684\u001B[0m \u001B[43m    \u001B[49m\u001B[43munits\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43munits\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1685\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1686\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1687\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m<decorator-gen-179>:12\u001B[0m, in \u001B[0;36m__init__\u001B[0;34m(self, input_fname, eog, misc, stim_channel, exclude, infer_types, preload, include, units, encoding, verbose)\u001B[0m\n",
      "File \u001B[0;32m~/miniconda3/envs/EEG311/lib/python3.11/site-packages/mne/io/edf/edf.py:155\u001B[0m, in \u001B[0;36mRawEDF.__init__\u001B[0;34m(self, input_fname, eog, misc, stim_channel, exclude, infer_types, preload, include, units, encoding, verbose)\u001B[0m\n\u001B[1;32m    153\u001B[0m logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExtracting EDF parameters from \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m...\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(input_fname))\n\u001B[1;32m    154\u001B[0m input_fname \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mabspath(input_fname)\n\u001B[0;32m--> 155\u001B[0m info, edf_info, orig_units \u001B[38;5;241m=\u001B[39m \u001B[43m_get_info\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    156\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_fname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstim_channel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meog\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmisc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexclude\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minfer_types\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpreload\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minclude\u001B[49m\n\u001B[1;32m    157\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    158\u001B[0m logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCreating raw.info structure...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    160\u001B[0m _validate_type(units, (\u001B[38;5;28mstr\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;28mdict\u001B[39m), \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124munits\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/miniconda3/envs/EEG311/lib/python3.11/site-packages/mne/io/edf/edf.py:521\u001B[0m, in \u001B[0;36m_get_info\u001B[0;34m(fname, stim_channel, eog, misc, exclude, infer_types, preload, include)\u001B[0m\n\u001B[1;32m    518\u001B[0m eog \u001B[38;5;241m=\u001B[39m eog \u001B[38;5;28;01mif\u001B[39;00m eog \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m []\n\u001B[1;32m    519\u001B[0m misc \u001B[38;5;241m=\u001B[39m misc \u001B[38;5;28;01mif\u001B[39;00m misc \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m []\n\u001B[0;32m--> 521\u001B[0m edf_info, orig_units \u001B[38;5;241m=\u001B[39m \u001B[43m_read_header\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexclude\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minfer_types\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minclude\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    523\u001B[0m \u001B[38;5;66;03m# XXX: `tal_ch_names` to pass to `_check_stim_channel` should be computed\u001B[39;00m\n\u001B[1;32m    524\u001B[0m \u001B[38;5;66;03m#      from `edf_info['ch_names']` and `edf_info['tal_idx']` but 'tal_idx'\u001B[39;00m\n\u001B[1;32m    525\u001B[0m \u001B[38;5;66;03m#      contains stim channels that are not TAL.\u001B[39;00m\n\u001B[1;32m    526\u001B[0m stim_channel_idxs, _ \u001B[38;5;241m=\u001B[39m _check_stim_channel(stim_channel, edf_info[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mch_names\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n",
      "File \u001B[0;32m~/miniconda3/envs/EEG311/lib/python3.11/site-packages/mne/io/edf/edf.py:505\u001B[0m, in \u001B[0;36m_read_header\u001B[0;34m(fname, exclude, infer_types, include)\u001B[0m\n\u001B[1;32m    503\u001B[0m logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m file detected\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m ext\u001B[38;5;241m.\u001B[39mupper())\n\u001B[1;32m    504\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ext \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbdf\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124medf\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m--> 505\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read_edf_header\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexclude\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minfer_types\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minclude\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    506\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m ext \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgdf\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    507\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _read_gdf_header(fname, exclude, include), \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/EEG311/lib/python3.11/site-packages/mne/io/edf/edf.py:796\u001B[0m, in \u001B[0;36m_read_edf_header\u001B[0;34m(fname, exclude, infer_types, include)\u001B[0m\n\u001B[1;32m    793\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Read header information from EDF+ or BDF file.\"\"\"\u001B[39;00m\n\u001B[1;32m    794\u001B[0m edf_info \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mevents\u001B[39m\u001B[38;5;124m\"\u001B[39m: []}\n\u001B[0;32m--> 796\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mfname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m fid:\n\u001B[1;32m    797\u001B[0m     fid\u001B[38;5;241m.\u001B[39mread(\u001B[38;5;241m8\u001B[39m)  \u001B[38;5;66;03m# version (unused here)\u001B[39;00m\n\u001B[1;32m    799\u001B[0m     \u001B[38;5;66;03m# patient ID\u001B[39;00m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '/home/daniel/repos/Decoding_of_EEG/data/raw/S001/S001R03.edf'"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Save data after transform to database"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "df_to_CWTfiles(\n",
    "    df_val, num_of_rows=1000, wave=\"cgau4\", frq=160, resolution=10, db_path=\"df_val_cwt_data.db\"\n",
    ")\n",
    "df_to_CWTfiles(\n",
    "    df_train, num_of_rows=1000, wave=\"cgau4\", frq=160, resolution=10, db_path=\"df_train_cwt_data.db\"\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def df_to_CWT(\n",
    "        df, num_of_rows=1000, wave=\"cgau4\", frq=160, resolution=100, db_path=\"cwt_data.db\"\n",
    "):\n",
    "    # Utworzenie bazy danych, jeśli nie istnieje\n",
    "    create_database(db_path)\n",
    "\n",
    "    for i in range(0, len(df), num_of_rows):\n",
    "        if i + num_of_rows > len(df):\n",
    "            break\n",
    "        signals = df.iloc[i: i + num_of_rows].values\n",
    "        list_cwt = []\n",
    "        targets = ()\n",
    "        if signals.shape == (num_of_rows, 65):\n",
    "            signals = signals.transpose(1, 0)\n",
    "        j = 0\n",
    "        # print(len(signals))\n",
    "        for signal in signals:\n",
    "            j += 1\n",
    "            if j == len(signals):\n",
    "                targets = signal\n",
    "                break\n",
    "            signal = (signal - np.min(signal)) / (np.max(signal) - np.min(signal))\n",
    "            time = np.linspace(0, len(signal) / frq, len(signal))\n",
    "            widths = np.geomspace(1, 200, num=resolution)\n",
    "            sampling_period = np.diff(time).mean()\n",
    "            cwtmatr, freqs = pywt.cwt(\n",
    "                signal, widths, wave, sampling_period=sampling_period\n",
    "            )\n",
    "            cwtmatr = np.abs(cwtmatr)\n",
    "            list_cwt.append(cwtmatr)\n",
    "\n",
    "        array_cwt = np.stack(list_cwt, axis=0)\n",
    "        return array_cwt, targets  # Zapis do bazy danych\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "cwt, targ = df_to_CWT(\n",
    "    df, num_of_rows=1000, wave=\"cgau4\", frq=160, resolution=10, db_path=\"cwt_data.db\"\n",
    ")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "frq = 160\n",
    "resolution = 10\n",
    "num_of_rows = 1000\n",
    "wave = \"cgau4\"\n",
    "signals = df.iloc[0: 0 + num_of_rows].values\n",
    "list_cwt = []\n",
    "targets = ()\n",
    "if signals.shape == (num_of_rows, 65):\n",
    "    signals = signals.transpose(1, 0)\n",
    "j = 0\n",
    "# print(len(signals))\n",
    "for signal in signals:\n",
    "    j += 1\n",
    "    if j == len(signals):\n",
    "        targets = signal\n",
    "        break\n",
    "    signal = (signal - np.min(signal)) / (np.max(signal) - np.min(signal))\n",
    "    time = np.linspace(0, len(signal) / frq, len(signal))\n",
    "    widths = np.geomspace(1, 200, num=resolution)\n",
    "    sampling_period = np.diff(time).mean()\n",
    "    cwtmatr, freqs = pywt.cwt(\n",
    "        signal, widths, wave, sampling_period=sampling_period\n",
    "    )\n",
    "    cwtmatr = np.abs(cwtmatr)\n",
    "    list_cwt.append(cwtmatr)\n",
    "array_cwt = np.stack(list_cwt, axis=0)"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (EEG311)",
   "language": "python",
   "name": "eeg311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
