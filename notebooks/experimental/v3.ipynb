{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "source": [
    "#334a4ba3ee7a3dc9ff8373e22d7cf2fd31e6198668a4ae16\n",
    "#!pip install PyWavelets mne  pandas numpy matplotlib"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import mne\n",
    "import pywt\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "import pickle\n",
    "import os"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "source": [
    "def file_to_DataDrame(path):\n",
    "    \"\"\"\n",
    "    This function takes in a file path and returns a dataframe with the data and the target values\n",
    "    format:\n",
    "        Fc5\t        Fc3\t        Fc1\t        ...\tOz\t        O2\t        Iz\t        target\n",
    "    0\t-0.000046\t-0.000041\t-0.000032\t...\t0.000040\t0.000108\t0.000055\t0\n",
    "    1\t-0.000054\t-0.000048\t-0.000034\t...\t0.000064\t0.000114\t0.000074\t0\n",
    "    ...\n",
    "    \"\"\"\n",
    "\n",
    "    reader = mne.io.read_raw_edf(path, preload=True)\n",
    "    annotations = reader.annotations  # get the values of the annotations\n",
    "    codes = annotations.description  # get the codes from the annotations\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        reader.get_data().T,\n",
    "        columns=[channel.replace(\".\", \"\") for channel in reader.ch_names],\n",
    "    )  # transpose the data to get the right shape\n",
    "    df = df[~(df == 0).all(axis=1)]  # remove rows with all zeros\n",
    "    timeArray = np.array(\n",
    "        [round(x, 10) for x in np.arange(0, len(df) / 160, 0.00625)]\n",
    "    )  # create an array of time values\n",
    "\n",
    "    codeArray = []\n",
    "    counter = 0\n",
    "    for timeVal in timeArray:\n",
    "        if (\n",
    "            timeVal in annotations.onset\n",
    "        ):  # if the time value is in the onset array, add the corresponding code to the codeArray\n",
    "            counter += 1\n",
    "        code_of_target = int(\n",
    "            codes[counter - 1].replace(\"T\", \"\")\n",
    "        )  # convert T0 to 0, T1 to 1, etc\n",
    "        codeArray.append(code_of_target)\n",
    "\n",
    "    df[\"target\"] = np.array(codeArray).T\n",
    "    return df\n",
    "\n",
    "\n",
    "def save_to_pickle(data, file_path):\n",
    "    with open(file_path, \"wb\") as f:\n",
    "        pickle.dump(data, f)\n",
    "\n",
    "\n",
    "def load_from_pickle(file_path):\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "    return data"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "source": [
    "def read_all_file_df(num_exp=[3, 4], num_people=2):\n",
    "    \"\"\"condct all files in one dataframe\"\"\"\n",
    "    all_df = pd.DataFrame()\n",
    "    for subject in range(1, num_people):\n",
    "        for file in num_exp:\n",
    "            fileName = f\"files/S{subject:03d}/S{subject:03d}R{file:02d}.edf\"\n",
    "            df = file_to_DataDrame(fileName)\n",
    "            all_df = pd.concat([all_df, df], axis=0)\n",
    "    return all_df"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "source": [
    "df = read_all_file_df()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "source": [
    "len(df)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "source": [
    "def df_to_CWTfiles(df, num_of_rows):\n",
    "    \"\"\"i\"\"\"\n",
    "    for i in range(0, len(df), num_of_rows):\n",
    "        signals = df.iloc[i : i + num_of_rows].values\n",
    "        all_cwt= np.zeros((num_of_rows,100,65))\n",
    "        if signals.shape == (1000,64):\n",
    "            signals=signals.transpose(1,0)\n",
    "        for signal in signals:\n",
    "            signal = (signal - signal.mean()) / signal.std()\n",
    "            time = np.linspace(0, len(signal) / 160, len(signal))\n",
    "            widths = np.geomspace(1, 200, num=100)  # range of scales\n",
    "            sampling_period = np.diff(time).mean()  # 0.006251562890722681\n",
    "            cwtmatr, _ = pywt.cwt(signal, widths, \"cgau4\", sampling_period=sampling_period)\n",
    "            cwtmatr= np.abs(cwtmatr[:-1,:-1])\n",
    "            cwtmatr = np.abs(cwtmatr)\n",
    "            print(cwtmatr.shape)\n",
    "        \n",
    "        print(int(i/num_of_rows))\n",
    "        save_to_pickle(cwtmatr,f\"cwt_data{i}\")\n",
    "\n",
    "        del cwtmatr"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "source": [
    "num_of_rows = 1000\n",
    "df_to_CWTfiles(df,1000)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "zer=np.zeros((4,100))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "len(zer)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "for i in range(0, len(df), num_of_rows):\n",
    "    chunks = df.iloc[i : i + num_of_rows].values\n",
    "    print(len(chunks[:,1]))\n",
    "    chanks_to_CWTchanks(chunks)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "num_of_rows = 1000\n",
    "chunks = [df[i : i + num_of_rows] for i in range(0, df.shape[0], num_of_rows)]\n",
    "chunks.value\n",
    "chanks_to_CWTchanks(chunks.value)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class EEGDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, target):\n",
    "        self.data = data\n",
    "        self.target = target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.target[idx]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "dataset = EEGDataset(df.iloc[:, :-1].values, df.iloc[:, -1].values)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "dataset.__getitem__(0)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "signal = df.iloc[:1000, 0]  # First column\n",
    "\n",
    "signals = df.iloc[:1000, :-1]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# conwert ot np array\n",
    "signals = signals.values\n",
    "signal = signal.values"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "signal2 = signals[:,0]\n",
    "print(signal2.shape)\n",
    "print(signal2.dtype)\n",
    "print(type(signal2))\n",
    "print(signal.shape)\n",
    "print(signal.dtype)\n",
    "print(type(signal))\n",
    "is_same = np.array_equal(signal2, signal)\n",
    "print(is_same)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# normalization signal\n",
    "signal = (signal - signal.mean()) / signal.std()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "time = np.linspace(0, len(signal) / 160, len(signal))\n",
    "widths = np.geomspace(1, 200, num=100)  # range of scales\n",
    "sampling_period = np.diff(time).mean()  # 0.006251562890722681\n",
    "print(signal.shape)\n",
    "cwtmatr, freqs = pywt.cwt(signal, widths, \"cgau4\", sampling_period=sampling_period)\n",
    "# cwtmatr= np.abs(cwtmatr[:-1,:-1])\n",
    "cwtmatr = np.abs(cwtmatr)\n",
    "# cwtmatr= torch.tensor(cwtmatr)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "signal.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "plt.figure(figsize=(20, 3))\n",
    "print(cwtmatr.shape)\n",
    "plt.pcolormesh(time, freqs, cwtmatr)\n",
    "maxval = np.max(freqs)\n",
    "plt.yscale(\"log\")\n",
    "plt.ylabel(\"Frequency [Hz]\")\n",
    "plt.xlabel(\"Time [s]\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "#if shpae in == 100x64 do not transpose\n",
    "\n",
    "if signals.shape == (1000,64):\n",
    "    signals=signals.transpose(1,0)\n",
    "for signal in signals:\n",
    "    signal = (signal - signal.mean()) / signal.std()\n",
    "    time = np.linspace(0, len(signal) / 160, len(signal))\n",
    "    widths = np.geomspace(1, 200, num=100)  # range of scales\n",
    "    sampling_period = np.diff(time).mean()  # 0.006251562890722681\n",
    "    cwtmatr, freqs = pywt.cwt(signal, widths, \"cgau4\", sampling_period=sampling_period)\n",
    "    # cwtmatr= np.abs(cwtmatr[:-1,:-1])\n",
    "    cwtmatr = np.abs(cwtmatr)\n",
    "    # cwtmatr= torch.tensor(cwtmatr)\n",
    "    plt.figure(figsize=(20, 3))\n",
    "    plt.pcolormesh(time, freqs, cwtmatr)\n",
    "    maxval = np.max(freqs)\n",
    "    plt.yscale(\"log\")\n",
    "    plt.ylabel(\"Frequency [Hz]\")\n",
    "    plt.xlabel(\"Time [s]\")\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "    \n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "signal2 = (signal2 - signal2.mean()) / signal2.std()\n",
    "time = np.linspace(0, len(signal2) / 160, len(signal2))\n",
    "widths = np.geomspace(1, 200, num=100)  # range of scales\n",
    "sampling_period = np.diff(time).mean()  # 0.006251562890722681\n",
    "print(signal.shape)\n",
    "cwtmatr, freqs = pywt.cwt(signal2, widths, \"cgau4\", sampling_period=sampling_period)\n",
    "# cwtmatr= np.abs(cwtmatr[:-1,:-1])\n",
    "cwtmatr = np.abs(cwtmatr)\n",
    "# cwtmatr= torch.tensor(cwtmatr)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "plt.figure(figsize=(20, 3))\n",
    "plt.pcolormesh(time, freqs, cwtmatr)\n",
    "maxval = np.max(freqs)\n",
    "plt.yscale(\"log\")\n",
    "plt.ylabel(\"Frequency [Hz]\")\n",
    "plt.xlabel(\"Time [s]\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EEG311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
