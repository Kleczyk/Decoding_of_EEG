{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import mne\n",
    "import pywt\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "import pickle"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "source": [
    "def file_to_DataDrame(path):\n",
    "    \"\"\"\n",
    "    This function takes in a file path and returns a dataframe with the data and the target values\n",
    "    format:\n",
    "        Fc5\t        Fc3\t        Fc1\t        ...\tOz\t        O2\t        Iz\t        target\n",
    "    0\t-0.000046\t-0.000041\t-0.000032\t...\t0.000040\t0.000108\t0.000055\t0\n",
    "    1\t-0.000054\t-0.000048\t-0.000034\t...\t0.000064\t0.000114\t0.000074\t0\n",
    "    ...\n",
    "    \"\"\"\n",
    "\n",
    "    reader = mne.io.read_raw_edf(path, preload=True)\n",
    "    annotations = reader.annotations  # get the values of the annotations\n",
    "    codes = annotations.description  # get the codes from the annotations\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        reader.get_data().T,\n",
    "        columns=[channel.replace(\".\", \"\") for channel in reader.ch_names],\n",
    "    )  # transpose the data to get the right shape\n",
    "    df = df[~(df == 0).all(axis=1)]  # remove rows with all zeros\n",
    "    timeArray = np.array(\n",
    "        [round(x, 10) for x in np.arange(0, len(df) / 160, 0.00625)]\n",
    "    )  # create an array of time values\n",
    "\n",
    "    codeArray = []\n",
    "    counter = 0\n",
    "    for timeVal in timeArray:\n",
    "        if (\n",
    "            timeVal in annotations.onset\n",
    "        ):  # if the time value is in the onset array, add the corresponding code to the codeArray\n",
    "            counter += 1\n",
    "        code_of_target = int(\n",
    "            codes[counter - 1].replace(\"T\", \"\") \n",
    "        )  # convert T0 to 0, T1 to 1, etc\n",
    "        codeArray.append(code_of_target)\n",
    "\n",
    "    df[\"target\"] = np.array(codeArray).T\n",
    "    return df\n",
    "\n",
    "def save_to_pickle(data, file_path):\n",
    "    with open(file_path, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "\n",
    "def load_from_pickle(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    return data\n",
    "\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "source": [
    "import os"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "source": [
    "def read_all_file_df(num_exp=[3, 4], num_people=10):\n",
    "    \"\"\"    condct all files in one dataframe\"\"\"\n",
    "    all_df = pd.DataFrame()\n",
    "    for subject in range(1, num_people):\n",
    "        for file in num_exp:\n",
    "            fileName = f\"files/S{subject:03d}/S{subject:03d}R{file:02d}.edf\"\n",
    "            df = file_to_DataDrame(fileName)\n",
    "            all_df = pd.concat([all_df, df], axis=0)\n",
    "    return all_df\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "source": [
    "class EEGDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, target):\n",
    "        self.data = data\n",
    "        self.target = target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.target[idx]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "source": [
    "\n",
    "df = read_all_file_df([3,7,11],109)\n",
    "\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "source": [
    "df"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "source": [
    "signal=df.iloc[:,:-1].values"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "source": [
    "signal.shape\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "source": [
    "time= np.linspace(0, len(signal)/160, len(signal))\n",
    "widths = np.geomspace(1, 1024, num=4)\n",
    "sampling_period = sampling_period = np.diff(time).mean()\n",
    "cwtmatr, freqs =pywt.cwt(signal, widths,'cgau4', sampling_period=sampling_period)\n",
    "cwtmatr= torch.tensor(cwtmatr)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from torchvision.io import read_image\n",
    "from torchvision.transforms import Compose, Resize, ToTensor\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "\n",
    "class MyImageDataset(Dataset):\n",
    "    def __init__(self, directory, transform=None):\n",
    "        self.directory = directory\n",
    "        self.transform = transform\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "\n",
    "        for label, label_dir in enumerate(sorted(os.listdir(directory))):\n",
    "            for image_name in os.listdir(os.path.join(directory, label_dir)):\n",
    "                self.images.append(os.path.join(directory, label_dir, image_name))\n",
    "                self.labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.images[idx]\n",
    "        image = read_image(image_path)\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "cwt_df = "
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class CWTDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, target):\n",
    "        self.data = data\n",
    "        self.target = target\n",
    "    \n",
    "    # def transform(self, signal):\n",
    "    #     time= np.linspace(0, len(signal)/160, len(signal))\n",
    "    #     widths = np.geomspace(1, 1024, num=10)\n",
    "    #     sampling_period = sampling_period = np.diff(time).mean()\n",
    "    #     cwtmatr, _ = pywt.cwt(signal, widths,'cgau4', sampling_period=sampling_period)\n",
    "    #     return cwtmatr\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # data = self.transform(self.data[idx-640:idx])\n",
    "        return torch.tensor(self.data[idx]), torch.tensor(self.target[idx])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SimpleLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(SimpleLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)  # Pełnopołączona warstwa\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Inicjalizacja ukrytych stanów i stanu komórek\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "\n",
    "        # Forward propagate LSTM\n",
    "        out, _ = self.lstm(x, (h0, c0))  # wyjście ma rozmiar (batch_size, sequence_length, hidden_size)\n",
    "        \n",
    "        # Dekodowanie ukrytego stanu ostatniej czasowej sekwencji\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU jest dostępne. Używanie GPU...\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU nie jest dostępne. Używanie CPU...\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from torch.utils.data import DataLoader\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "dataset = CWTDataset(df.iloc[:, :-1].values, df.iloc[:, -1].values)\n",
    "x = dataset.__getitem__(0)\n",
    "x\n",
    "DataLoader = DataLoader(dataset, batch_size=10, shuffle=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Parametry modelu i danych\n",
    "input_size = 64  # Liczba cech wejściowych\n",
    "hidden_size = 128  # Rozmiar ukrytej warstwy LSTM\n",
    "num_layers = 4  # Liczba warstw LSTM\n",
    "num_classes = 3  # Liczba klas wyjściowych\n",
    "\n",
    "model = SimpleLSTM(input_size, hidden_size, num_layers, num_classes)\n",
    "\n",
    "# Funkcja straty i optymalizator\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Dla przykładu, załóżmy, że `dataloader` jest już zdefiniowany i przygotowany\n",
    "\n",
    "num_epochs = 5  # Liczba epok\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (sequences, labels) in enumerate(DataLoader):\n",
    "        # Przesyłanie danych i etykiet na właściwe urządzenie\n",
    "        sequences = sequences.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(sequences)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward i optymalizacja\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(DataLoader)}], Loss: {loss.item():.4f}')\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "\n",
    "time = np.linspace(0, 4000 / 160, 4000)  # time of the signal\n",
    "signal = fc5\n",
    "widths = np.geomspace(1, 1024, num=100)  # range of scales\n",
    "sampling_period = np.diff(time).mean()  # 0.006251562890722681\n",
    "print(sampling_period)\n",
    "wavlist = pywt.wavelist(kind=\"continuous\")\n",
    "for wavelet in wavlist:\n",
    "    # A few wavelet families require parameters in the string name\n",
    "    if wavelet in [\"cmor\", \"shan\"]:\n",
    "        wavelet += \"1-1\"\n",
    "    elif wavelet == \"fbsp\":\n",
    "        wavelet += \"1-1.5-1.0\"\n",
    "\n",
    "    # compute the wavelet transform\n",
    "    cwtmatr, freqs = pywt.cwt(signal, widths, wavelet, sampling_period=sampling_period)\n",
    "    # cwtmatr= np.abs(cwtmatr[:-1,:-1])\n",
    "    cwtmatr = np.abs(cwtmatr)\n",
    "    # plot the wavelet transform\n",
    "    plt.figure(figsize=(20, 3))\n",
    "    plt.pcolormesh(time, freqs, cwtmatr)\n",
    "\n",
    "    maxval = np.max(freqs)\n",
    "    plt.vlines(x=xT0, ymin=0, ymax=maxval, color=\"r\", label=\"T0\", linestyles=\"dashed\")\n",
    "    plt.vlines(x=xT1, ymin=0, ymax=maxval, color=\"c\", label=\"T1\", linestyles=\"dashed\")\n",
    "    plt.vlines(x=xT2, ymin=0, ymax=maxval, color=\"y\", label=\"T2\", linestyles=\"dashed\")\n",
    "    plt.yscale(\"log\")\n",
    "    plt.ylabel(\"Frequency [Hz]\")\n",
    "    plt.xlabel(\"Time [s]\")\n",
    "    plt.title(f\"Wavelet Transform with {wavelet}\")\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "def file_to_tensor(path):\n",
    "\n",
    "\n",
    "    reader = mne.io.read_raw_edf(path, preload=True)\n",
    "    annotations = reader.annotations  # get the values of the annotations\n",
    "    codes = annotations.description  # get the codes from the annotations\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        reader.get_data().T,\n",
    "        columns=[channel.replace(\".\", \"\") for channel in reader.ch_names],\n",
    "    )  # transpose the data to get the right shape\n",
    "    df = df[~(df == 0).all(axis=1)]  # remove rows with all zeros\n",
    "    timeArray = np.array(\n",
    "        [round(x, 10) for x in np.arange(0, len(df) / 160, 0.00625)]\n",
    "    )  # create an array of time values\n",
    "\n",
    "    codeArray = []\n",
    "    counter = 0\n",
    "    for timeVal in timeArray:\n",
    "        if (\n",
    "            timeVal in annotations.onset\n",
    "        ):  # if the time value is in the onset array, add the corresponding code to the codeArray\n",
    "            counter += 1\n",
    "        code_of_target = int(\n",
    "            codes[counter - 1].replace(\"T\", \"\")\n",
    "        )  # convert T0 to 0, T1 to 1, etc\n",
    "        codeArray.append(code_of_target)\n",
    "\n",
    "    df[\"target\"] = np.array(codeArray).T\n",
    "    \n",
    "    # Convert DataFrame to PyTorch tensors\n",
    "    signals = torch.tensor(df.drop(columns=['target']).values).float()\n",
    "    targets = torch.tensor(df['target'].values).long()\n",
    "    \n",
    "    return signals, targets\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "subject = 1\n",
    "file = 5\n",
    "fileName = f\"files/S{subject:03d}/S{subject:03d}R{file:02d}.edf\"\n",
    "\n",
    "signals, targets = file_to_tensor(fileName)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "print(signals.shape, targets.shape)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def read_all_files_tensor():\n",
    "    all_signals = []\n",
    "    all_targets = []\n",
    "    for subject in range(1, 110):\n",
    "        for file in range(1, 15):\n",
    "            fileName = f\"files/S{subject:03d}/S{subject:03d}R{file:02d}.edf\"\n",
    "            signals, targets = file_to_tensor(fileName)\n",
    "            all_signals.append(signals)\n",
    "            all_targets.append(targets)\n",
    "    return torch.cat(all_signals), torch.cat(all_targets)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import pickle\n",
    "\n",
    "def save_tensors_to_pickle(X, y, file_path):\n",
    "    with open(file_path, 'wb') as f:\n",
    "        pickle.dump((X, y), f)\n",
    "\n",
    "def load_tensors_from_pickle(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        X, y = pickle.load(f)\n",
    "    return X, y"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is done in experiment\n",
    "\n",
    "1. Baseline, eyes open\n",
    "2. Baseline, eyes closed\n",
    "3. Task 1 (open and close left or right fist)\n",
    "4. Task 2 (imagine opening and closing left or right fist)\n",
    "5. Task 3 (open and close both fists or both feet)\n",
    "6. Task 4 (imagine opening and closing both fists or both feet)\n",
    "7. Task 1\n",
    "8. Task 2\n",
    "9. Task 3\n",
    "10. Task 4\n",
    "11. Task 1\n",
    "12. Task 2\n",
    "13. Task 3\n",
    "14. Task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def read_all_file_batch(batch_size=640, num_exp=[3, 4], num_people=10):\n",
    "    all_signals = torch.empty(num_people, len(num_exp), 20000, batch_size, 64)\n",
    "    all_targets = torch.empty(num_people, len(num_exp), 20000)\n",
    "    index_exp = 0\n",
    "    index_people = 0\n",
    "    for subject in range(1, num_people):\n",
    "        for file in num_exp:\n",
    "            fileName = f\"files/S{subject:03d}/S{subject:03d}R{file:02d}.edf\"\n",
    "            signals, targets = file_to_tensor(fileName)\n",
    "            var_signals = torch.empty(20000, batch_size, 64)\n",
    "            var_targets = torch.empty(20000)\n",
    "            for i in range(0, 20000):\n",
    "                if i > batch_size:\n",
    "                    if i >= len(signals):\n",
    "                        var_signals[i - batch_size] = torch.full(\n",
    "                            (batch_size, 64), float(\"nan\")\n",
    "                        )\n",
    "                        var_targets[i - batch_size] = float(\"nan\")\n",
    "                    else:\n",
    "                        var_signals[i - batch_size] = signals[i - batch_size : i]\n",
    "                        var_targets[i - batch_size] = targets[i]\n",
    "            all_signals[index_people][index_exp] = var_signals\n",
    "            all_targets[index_people][index_exp] = var_targets\n",
    "            index_exp += 1\n",
    "        index_people += 1\n",
    "    return all_signals, all_targets"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "del signals, targets"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "all_signals, all_targets = read_all_file_batch(640,[3,7,1],109)\n",
    "save_tensors_to_pickle(all_signals, all_targets, 'all_signals_targets_batch.pickle')\n",
    "del all_signals, all_targets"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "all_signals, all_targets = read_all_files_tensor()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import pickle\n",
    "\n",
    "def save_tensors_to_pickle(X, y, file_path):\n",
    "    with open(file_path, 'wb') as f:\n",
    "        pickle.dump((X, y), f)\n",
    "\n",
    "def load_tensors_from_pickle(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        X, y = pickle.load(f)\n",
    "    return X, y"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "save_tensors_to_pickle(all_signals, all_targets, 'pkl/all_signals_targets.pkl')\n",
    "del all_signals, all_targets"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "all_signals, all_targets = load_tensors_from_pickle('pkl/all_signals_targets.pkl')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "all_signals.shape, all_targets.shape"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
