{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T19:38:44.306939Z",
     "start_time": "2024-05-13T19:38:44.131259Z"
    }
   },
   "cell_type": "code",
   "source": "!nvidia-smi",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon May 13 21:38:44 2024       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 525.125.06   Driver Version: 525.125.06   CUDA Version: 12.0     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Quadro RTX 8000     On   | 00000000:01:00.0 Off |                  Off |\r\n",
      "| 33%   27C    P8    15W / 260W |      1MiB / 49152MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T19:38:48.128955Z",
     "start_time": "2024-05-13T19:38:44.308570Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import mne\n",
    "import pywt\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from torch import nn\n",
    "import torch\n",
    "import pickle\n",
    "import os\n",
    "from datetime import datetime\n",
    "import sqlite3\n",
    "from pytorch_lightning import LightningModule, Trainer\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchmetrics.functional.classification.accuracy import accuracy"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-13 21:38:46.746839: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 21:38:46.800916: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 21:38:47.772726: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T19:38:48.143293Z",
     "start_time": "2024-05-13T19:38:48.130069Z"
    }
   },
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Training on device: {device}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on device: cuda\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T19:38:48.233553Z",
     "start_time": "2024-05-13T19:38:48.144583Z"
    }
   },
   "source": [
    "class CWTDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset for EEG data after CWT transformation stored in SQLite database.\n",
    "    \n",
    "    Attributes:\n",
    "        db_path: str - path to SQLite database\n",
    "        sequence_length: int - length of the sequence\n",
    "    Methods:\n",
    "        __len__ - returns the number of samples in the dataset minus the sequence length\n",
    "        __getitem__ - returns a sample from the dataset\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, db_path, sequence_length=4000):\n",
    "        \"\"\"\n",
    "        Constructor for CWTDataset class that initializes the dataset.\n",
    "        Args:\n",
    "            db_path: str - path to SQLite database\n",
    "            sequence_length: int - length of the sequence\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        self.db_path = db_path\n",
    "        self.sequence_length = sequence_length\n",
    "        self.conn = sqlite3.connect(db_path)\n",
    "        self.cursor = self.conn.cursor()\n",
    "        self.cursor.execute(\"SELECT COUNT(*) FROM wavelet_transforms\")\n",
    "        self.total_samples = self.cursor.fetchone()[0]\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the number of samples in the dataset.\n",
    "        Args:\n",
    "            None\n",
    "        Returns:\n",
    "            int - number of samples in the dataset minus the sequence length\n",
    "        \"\"\"\n",
    "        return self.total_samples - self.sequence_length + 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        function that returns as many samples as the sequence length\n",
    "        Args:\n",
    "            idx: int - index of the sample\n",
    "        Returns:\n",
    "            tuple - (cwt_tensor, target_tensor)\n",
    "        \n",
    "        \"\"\"\n",
    "        query = (\n",
    "            \"SELECT cwt_data, target FROM wavelet_transforms WHERE id BETWEEN ? AND ?\"\n",
    "        )\n",
    "\n",
    "        self.cursor.execute(query, (idx + 1, idx + self.sequence_length))\n",
    "        rows = self.cursor.fetchall()\n",
    "\n",
    "        cwt_sequence = np.stack([pickle.loads(row[0]) for row in rows])\n",
    "\n",
    "        target = rows[-1][1]\n",
    "\n",
    "        cwt_tensor = torch.tensor(cwt_sequence, dtype=torch.float32)\n",
    "\n",
    "        target_tensor = torch.tensor(target, dtype=torch.int64)\n",
    "        return cwt_tensor, target_tensor\n",
    "\n",
    "    def __del__(self):\n",
    "        self.conn.close()"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T19:38:48.278153Z",
     "start_time": "2024-05-13T19:38:48.234333Z"
    }
   },
   "source": [
    "class CWTSubset(Dataset):\n",
    "    def __init__(self, dataset, indices):\n",
    "        self.dataset = dataset\n",
    "        self.indices = indices\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.dataset.__getitem__(int(self.indices[idx]))\n",
    "        return row\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T19:38:48.323449Z",
     "start_time": "2024-05-13T19:38:48.278984Z"
    }
   },
   "source": [
    "class CWT_EEG(LightningModule):\n",
    "    def __init__(\n",
    "            self,\n",
    "            batch_size,\n",
    "            sequence_length,\n",
    "            input_size,\n",
    "            hidden_size,\n",
    "            num_layers,\n",
    "            lr,\n",
    "            label_smoothing=0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.hparams.batch_size = batch_size\n",
    "        self.hparams.input_size = input_size\n",
    "        self.hparams.sequence_length = sequence_length\n",
    "        self.hparams.lr = lr\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.num_of_classes = 3\n",
    "        self.val_percent = 0.01\n",
    "        self.loss = torch.nn.CrossEntropyLoss(label_smoothing=label_smoothing)\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, self.num_of_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "\n",
    "        out, (hn, cn) = self.lstm(x, (h0, c0))\n",
    "        out = hn[-1, :, :]\n",
    "        out = self.fc(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "    # custom\n",
    "    def count_parameters(model):\n",
    "        return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "    # only for HP\n",
    "    def on_train_start(self):\n",
    "        self.logger.log_hyperparams(\n",
    "            self.hparams,\n",
    "            {\n",
    "                \"hp/train_loss\": float(\"nan\"),\n",
    "                \"hp/train_acc\": float(\"nan\"),\n",
    "                \"hp/val_loss\": float(\"nan\"),\n",
    "                \"hp/val_acc\": float(\"nan\"),\n",
    "            },\n",
    "        )\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.loss(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = accuracy(preds, y, task=\"multiclass\", num_classes=self.num_of_classes)\n",
    "\n",
    "        self.log(\"hp/train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"hp/train_acc\", acc, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.hparams.lr)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.loss(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = accuracy(preds, y, task=\"multiclass\", num_classes=self.num_of_classes)\n",
    "\n",
    "        self.log(\"hp/val_loss\", loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"hp/val_acc\", acc, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def generate_validation_indices(\n",
    "            self, data_length, num_of_val_samples, sequence_length\n",
    "    ):\n",
    "        available_indices = set(range(data_length))\n",
    "        val_indices = []\n",
    "        for _ in range(num_of_val_samples):\n",
    "            if len(available_indices) == 0:\n",
    "                raise ValueError(\n",
    "                    \"Nie można wygenerować więcej próbek z uwzględnieniem minimalnego dystansu\"\n",
    "                )\n",
    "            chosen_index = int(np.random.choice(list(available_indices)))\n",
    "            val_indices.append(chosen_index)\n",
    "            indices_to_remove = set(\n",
    "                range(\n",
    "                    max(0, chosen_index - (2 * sequence_length) - 3),\n",
    "                    min(data_length, chosen_index + (2 * sequence_length) + 3),\n",
    "                )\n",
    "            )\n",
    "            available_indices.difference_update(indices_to_remove)\n",
    "\n",
    "        return val_indices\n",
    "\n",
    "    def generate_train_indices(self, data_length, val_i, sequence_length):\n",
    "        min_distance = sequence_length + 1\n",
    "        mask = np.ones(data_length, dtype=bool)\n",
    "        for index in val_i:\n",
    "            start = max(0, index - min_distance)\n",
    "            end = min(data_length, index + min_distance + 1)\n",
    "\n",
    "            mask[start:end] = False\n",
    "\n",
    "        training_indices = list(np.where(mask)[0])\n",
    "        return training_indices\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.ds = CWTDataset(\"df_train_cwt_data.db\", self.hparams.sequence_length)\n",
    "        self.num_val_samples = int(\n",
    "            len(self.ds) / (4 * self.hparams.sequence_length + 6)\n",
    "        )\n",
    "\n",
    "        val_indices = self.generate_validation_indices(\n",
    "            len(self.ds), self.num_val_samples, self.hparams.sequence_length\n",
    "        )\n",
    "        train_indices = self.generate_train_indices(\n",
    "            len(self.ds), val_indices, self.hparams.sequence_length\n",
    "        )\n",
    "        print(\n",
    "            \"percent of val samples\",\n",
    "            len(val_indices) / (len(val_indices) + len(train_indices)),\n",
    "        )\n",
    "        self.train_set = CWTSubset(self.ds, train_indices)\n",
    "        self.val_set = CWTSubset(self.ds, val_indices)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.train_set,\n",
    "            batch_size=self.hparams.batch_size,\n",
    "            num_workers=7,\n",
    "            shuffle=True,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.val_set, batch_size=self.hparams.batch_size, num_workers=7\n",
    "        )\n",
    "\n",
    "    def get_len_train_val(self):\n",
    "        self.setup()\n",
    "        return len(self.train_set), len(self.val_set)"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T19:38:48.365144Z",
     "start_time": "2024-05-13T19:38:48.324447Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class CWT_EEG_CrossPersonValidation(CWT_EEG):\n",
    "    def __init__(self, batch_size, sequence_length, input_size, hidden_size, num_layers, lr, label_smoothing=0):\n",
    "        super().__init__(batch_size, sequence_length, input_size, hidden_size, num_layers, lr, label_smoothing)\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.train_set = CWTDataset(\"./df_train_cwt_data.db\", self.hparams.sequence_length)\n",
    "        self.val_set = CWTDataset(\"./df_val_cwt_data.db\", self.hparams.sequence_length)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(self.train_set, batch_size=self.hparams.batch_size, num_workers=14,\n",
    "                                           shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(self.val_set, batch_size=self.hparams.batch_size, num_workers=14)\n"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T19:38:49.039593Z",
     "start_time": "2024-05-13T19:38:48.366191Z"
    }
   },
   "source": [
    "\n",
    "lr = 0.001\n",
    "\n",
    "model = CWT_EEG(batch_size=11, sequence_length=10, input_size=640, num_layers=3, hidden_size=3,\n",
    "                lr=lr).to(device)\n",
    "logger = TensorBoardLogger(\"logs\", name=\"CWT_EEG\", default_hp_metric=False)\n",
    "logger.log_hyperparams(model.hparams, {})\n",
    "trainer = Trainer(\n",
    "    max_epochs=2,\n",
    "    logger=logger\n",
    "\n",
    ")\n",
    "print(model.get_len_train_val())\n",
    "trainer.fit(model)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "ename": "OperationalError",
     "evalue": "no such table: wavelet_transforms",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mOperationalError\u001B[0m                          Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 12\u001B[0m\n\u001B[1;32m      6\u001B[0m logger\u001B[38;5;241m.\u001B[39mlog_hyperparams(model\u001B[38;5;241m.\u001B[39mhparams, {})\n\u001B[1;32m      7\u001B[0m trainer \u001B[38;5;241m=\u001B[39m Trainer(\n\u001B[1;32m      8\u001B[0m     max_epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m,\n\u001B[1;32m      9\u001B[0m     logger\u001B[38;5;241m=\u001B[39mlogger\n\u001B[1;32m     10\u001B[0m \n\u001B[1;32m     11\u001B[0m )\n\u001B[0;32m---> 12\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_len_train_val\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m     13\u001B[0m trainer\u001B[38;5;241m.\u001B[39mfit(model)\n",
      "Cell \u001B[0;32mIn[6], line 146\u001B[0m, in \u001B[0;36mCWT_EEG.get_len_train_val\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    145\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_len_train_val\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m--> 146\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msetup\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    147\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrain_set), \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mval_set)\n",
      "Cell \u001B[0;32mIn[6], line 114\u001B[0m, in \u001B[0;36mCWT_EEG.setup\u001B[0;34m(self, stage)\u001B[0m\n\u001B[1;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msetup\u001B[39m(\u001B[38;5;28mself\u001B[39m, stage\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m--> 114\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mds \u001B[38;5;241m=\u001B[39m \u001B[43mCWTDataset\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdf_train_cwt_data.db\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhparams\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msequence_length\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    115\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_val_samples \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(\n\u001B[1;32m    116\u001B[0m         \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mds) \u001B[38;5;241m/\u001B[39m (\u001B[38;5;241m4\u001B[39m \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhparams\u001B[38;5;241m.\u001B[39msequence_length \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m6\u001B[39m)\n\u001B[1;32m    117\u001B[0m     )\n\u001B[1;32m    119\u001B[0m     val_indices \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgenerate_validation_indices(\n\u001B[1;32m    120\u001B[0m         \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mds), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_val_samples, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhparams\u001B[38;5;241m.\u001B[39msequence_length\n\u001B[1;32m    121\u001B[0m     )\n",
      "Cell \u001B[0;32mIn[4], line 27\u001B[0m, in \u001B[0;36mCWTDataset.__init__\u001B[0;34m(self, db_path, sequence_length)\u001B[0m\n\u001B[1;32m     25\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconn \u001B[38;5;241m=\u001B[39m sqlite3\u001B[38;5;241m.\u001B[39mconnect(db_path)\n\u001B[1;32m     26\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcursor \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconn\u001B[38;5;241m.\u001B[39mcursor()\n\u001B[0;32m---> 27\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcursor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mSELECT COUNT(*) FROM wavelet_transforms\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     28\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtotal_samples \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcursor\u001B[38;5;241m.\u001B[39mfetchone()[\u001B[38;5;241m0\u001B[39m]\n",
      "\u001B[0;31mOperationalError\u001B[0m: no such table: wavelet_transforms"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T19:39:21.109276Z",
     "start_time": "2024-05-13T19:39:18.817944Z"
    }
   },
   "source": [
    "import datetime\n",
    "from pytorch_lightning import Trainer, loggers\n",
    "\n",
    "current_time = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "logger = loggers.TensorBoardLogger(\"logs\", name=f\"CWT_EEG_{current_time}\", default_hp_metric=False)\n",
    "lr = 0.001\n",
    "model = CWT_EEG_CrossPersonValidation(batch_size=11, sequence_length=10, input_size=640, num_layers=3, hidden_size=100,\n",
    "                                   lr=lr).to(device)\n",
    "logger.log_hyperparams(model.hparams)\n",
    "trainer = Trainer(\n",
    "    max_epochs=2,\n",
    "    logger=logger\n",
    ")\n",
    "trainer.fit(model)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: logs/CWT_EEG_2024-05-13_21-39-18\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type             | Params\n",
      "------------------------------------------\n",
      "0 | loss | CrossEntropyLoss | 0     \n",
      "1 | lstm | LSTM             | 458 K \n",
      "2 | fc   | Linear           | 303   \n",
      "------------------------------------------\n",
      "458 K     Trainable params\n",
      "0         Non-trainable params\n",
      "458 K     Total params\n",
      "1.835     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   1%|        | 91/10818 [00:00<01:19, 135.54it/s, v_num=0, hp/train_loss_step=1.170, hp/train_acc_step=0.273]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "model.hparams"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T20:16:29.111979Z",
     "start_time": "2024-05-13T20:15:49.921410Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from ray import tune\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "def train_model(config):\n",
    "    model = CWT_EEG_CrossPersonValidation(\n",
    "        batch_size=config[\"batch_size\"],  # hiperparametr rozmiaru batcha\n",
    "        sequence_length=config[\"sequence_length\"],  # hiperparametr długości sekwencji\n",
    "        input_size=640,  # hiperparametr rozmiaru wejścia\n",
    "        hidden_size=config[\"hidden_size\"],  # hiperparametr rozmiaru stanu ukrytego\n",
    "        num_layers=config[\"num_layers\"],  # hiperparametr liczby warstw\n",
    "        lr=config[\"lr\"],  # hiperparametr prędkości uczenia\n",
    "        label_smoothing=0  # hiperparametr wygładzania etykiet\n",
    "    )\n",
    "\n",
    "    # Callbacks\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        monitor='hp/val_loss',\n",
    "        dirpath='model_checkpoints',\n",
    "        filename='model-{epoch:02d}-{hp/val_loss:.2f}',\n",
    "        save_top_k=3,\n",
    "        mode='min'\n",
    "    )\n",
    "    early_stop_callback = EarlyStopping(\n",
    "        monitor='hp/val_loss',\n",
    "        min_delta=0.00,\n",
    "        patience=3,\n",
    "        verbose=False,\n",
    "        mode='min'\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        max_epochs=10,\n",
    "        callbacks=[checkpoint_callback, early_stop_callback],\n",
    "    )\n",
    "\n",
    "    trainer.fit(model)\n",
    "\n",
    "search_space = {\n",
    "    \"batch_size\": tune.choice([8, 16, 32, 64]),\n",
    "    \"sequence_length\": tune.choice([10, 100, 200]),\n",
    "    \"hidden_size\": tune.choice([256, 512, 1024]),\n",
    "    \"num_layers\": tune.choice([1, 2, 3]),\n",
    "    \"lr\": tune.loguniform(1e-4, 1e-1),\n",
    "}\n",
    "\n",
    "analysis = tune.run(\n",
    "    train_model,\n",
    "    config=search_space,\n",
    "    num_samples=10,\n",
    "    resources_per_trial={\"cpu\": 1, \"gpu\": 1}\n",
    ")\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-13 22:15:49,927\tINFO tune.py:614 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-05-13 22:15:55</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:05.28        </td></tr>\n",
       "<tr><td>Memory:      </td><td>6.9/196.5 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 1.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  hidden_size</th><th style=\"text-align: right;\">         lr</th><th style=\"text-align: right;\">  num_layers</th><th style=\"text-align: right;\">  sequence_length</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_model_974c0_00000</td><td>RUNNING </td><td>10.20.30.2:53453</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">         1024</td><td style=\"text-align: right;\">0.0731392  </td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">              200</td></tr>\n",
       "<tr><td>train_model_974c0_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">0.0011528  </td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">               10</td></tr>\n",
       "<tr><td>train_model_974c0_00002</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">         1024</td><td style=\"text-align: right;\">0.00208421 </td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">               10</td></tr>\n",
       "<tr><td>train_model_974c0_00003</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">0.00027608 </td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">              200</td></tr>\n",
       "<tr><td>train_model_974c0_00004</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">         1024</td><td style=\"text-align: right;\">0.0191765  </td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">               10</td></tr>\n",
       "<tr><td>train_model_974c0_00005</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">0.000174582</td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\">               10</td></tr>\n",
       "<tr><td>train_model_974c0_00006</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">          512</td><td style=\"text-align: right;\">0.000796605</td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">               10</td></tr>\n",
       "<tr><td>train_model_974c0_00007</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          512</td><td style=\"text-align: right;\">0.00405581 </td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">               10</td></tr>\n",
       "<tr><td>train_model_974c0_00008</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">0.0143415  </td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\">               10</td></tr>\n",
       "<tr><td>train_model_974c0_00009</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">         1024</td><td style=\"text-align: right;\">0.00980253 </td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">              200</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-13 22:15:55,449\tERROR tune_controller.py:1331 -- Trial task failed for trial train_model_974c0_00000\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/_private/worker.py\", line 2623, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/_private/worker.py\", line 861, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(OperationalError): ray::ImplicitFunc.train() (pid=53453, ip=10.20.30.2, actor_id=c56e4df51aed403e3170c78801000000, repr=train_model)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/tune/trainable/trainable.py\", line 331, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/air/_internal/util.py\", line 98, in run\n",
      "    self._ret = self._target(*self._args, **self._kwargs)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/tune/trainable/function_trainable.py\", line 45, in <lambda>\n",
      "    training_func=lambda: self._trainable_func(self.config),\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/tune/trainable/function_trainable.py\", line 248, in _trainable_func\n",
      "    output = fn()\n",
      "             ^^^^\n",
      "  File \"/tmp/ipykernel_49542/864962306.py\", line 37, in train_model\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 544, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py\", line 44, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 580, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 949, in _run\n",
      "    call._call_setup_hook(self)  # allow user to set up LightningModule in accelerator environment\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py\", line 94, in _call_setup_hook\n",
      "    _call_lightning_module_hook(trainer, \"setup\", stage=fn)\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py\", line 157, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_49542/2118502779.py\", line 6, in setup\n",
      "  File \"/tmp/ipykernel_49542/1551172284.py\", line 25, in __init__\n",
      "sqlite3.OperationalError: unable to open database file\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-05-13 22:16:27</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:37.85        </td></tr>\n",
       "<tr><td>Memory:      </td><td>6.6/196.5 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 1.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "<div class=\"messages\">\n",
       "  <h3>Messages</h3>\n",
       "  \n",
       "  \n",
       "  Number of errored trials: 6<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                                                                                                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_model_974c0_00000</td><td style=\"text-align: right;\">           1</td><td>/tmp/ray/session_2024-05-13_21-39-24_464251_49542/artifacts/2024-05-13_22-15-49/train_model_2024-05-13_22-15-49/driver_artifacts/train_model_974c0_00000_0_batch_size=64,hidden_size=1024,lr=0.0731,num_layers=2,sequence_length=200_2024-05-13_22-15-49/error.txt</td></tr>\n",
       "<tr><td>train_model_974c0_00001</td><td style=\"text-align: right;\">           1</td><td>/tmp/ray/session_2024-05-13_21-39-24_464251_49542/artifacts/2024-05-13_22-15-49/train_model_2024-05-13_22-15-49/driver_artifacts/train_model_974c0_00001_1_batch_size=64,hidden_size=256,lr=0.0012,num_layers=1,sequence_length=10_2024-05-13_22-15-49/error.txt  </td></tr>\n",
       "<tr><td>train_model_974c0_00002</td><td style=\"text-align: right;\">           1</td><td>/tmp/ray/session_2024-05-13_21-39-24_464251_49542/artifacts/2024-05-13_22-15-49/train_model_2024-05-13_22-15-49/driver_artifacts/train_model_974c0_00002_2_batch_size=64,hidden_size=1024,lr=0.0021,num_layers=2,sequence_length=10_2024-05-13_22-15-49/error.txt </td></tr>\n",
       "<tr><td>train_model_974c0_00003</td><td style=\"text-align: right;\">           1</td><td>/tmp/ray/session_2024-05-13_21-39-24_464251_49542/artifacts/2024-05-13_22-15-49/train_model_2024-05-13_22-15-49/driver_artifacts/train_model_974c0_00003_3_batch_size=32,hidden_size=256,lr=0.0003,num_layers=1,sequence_length=200_2024-05-13_22-15-49/error.txt </td></tr>\n",
       "<tr><td>train_model_974c0_00004</td><td style=\"text-align: right;\">           1</td><td>/tmp/ray/session_2024-05-13_21-39-24_464251_49542/artifacts/2024-05-13_22-15-49/train_model_2024-05-13_22-15-49/driver_artifacts/train_model_974c0_00004_4_batch_size=32,hidden_size=1024,lr=0.0192,num_layers=2,sequence_length=10_2024-05-13_22-15-50/error.txt </td></tr>\n",
       "<tr><td>train_model_974c0_00005</td><td style=\"text-align: right;\">           1</td><td>/tmp/ray/session_2024-05-13_21-39-24_464251_49542/artifacts/2024-05-13_22-15-49/train_model_2024-05-13_22-15-49/driver_artifacts/train_model_974c0_00005_5_batch_size=8,hidden_size=256,lr=0.0002,num_layers=3,sequence_length=10_2024-05-13_22-15-50/error.txt   </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".messages {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  padding-left: 1em;\n",
       "  overflow-y: auto;\n",
       "}\n",
       ".messages h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n",
       "\n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  hidden_size</th><th style=\"text-align: right;\">         lr</th><th style=\"text-align: right;\">  num_layers</th><th style=\"text-align: right;\">  sequence_length</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_model_974c0_00006</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">          512</td><td style=\"text-align: right;\">0.000796605</td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">               10</td></tr>\n",
       "<tr><td>train_model_974c0_00007</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          512</td><td style=\"text-align: right;\">0.00405581 </td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">               10</td></tr>\n",
       "<tr><td>train_model_974c0_00008</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">0.0143415  </td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\">               10</td></tr>\n",
       "<tr><td>train_model_974c0_00009</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">         1024</td><td style=\"text-align: right;\">0.00980253 </td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">              200</td></tr>\n",
       "<tr><td>train_model_974c0_00000</td><td>ERROR   </td><td>10.20.30.2:53453</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">         1024</td><td style=\"text-align: right;\">0.0731392  </td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">              200</td></tr>\n",
       "<tr><td>train_model_974c0_00001</td><td>ERROR   </td><td>10.20.30.2:53518</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">0.0011528  </td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">               10</td></tr>\n",
       "<tr><td>train_model_974c0_00002</td><td>ERROR   </td><td>10.20.30.2:53583</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">         1024</td><td style=\"text-align: right;\">0.00208421 </td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">               10</td></tr>\n",
       "<tr><td>train_model_974c0_00003</td><td>ERROR   </td><td>10.20.30.2:53646</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">0.00027608 </td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">              200</td></tr>\n",
       "<tr><td>train_model_974c0_00004</td><td>ERROR   </td><td>10.20.30.2:53711</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">         1024</td><td style=\"text-align: right;\">0.0191765  </td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">               10</td></tr>\n",
       "<tr><td>train_model_974c0_00005</td><td>ERROR   </td><td>10.20.30.2:53775</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">0.000174582</td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\">               10</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-13 22:16:02,054\tERROR tune_controller.py:1331 -- Trial task failed for trial train_model_974c0_00001\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/_private/worker.py\", line 2623, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/_private/worker.py\", line 861, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(OperationalError): ray::ImplicitFunc.train() (pid=53518, ip=10.20.30.2, actor_id=31144f975829e4b25be76dff01000000, repr=train_model)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/tune/trainable/trainable.py\", line 331, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/air/_internal/util.py\", line 98, in run\n",
      "    self._ret = self._target(*self._args, **self._kwargs)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/tune/trainable/function_trainable.py\", line 45, in <lambda>\n",
      "    training_func=lambda: self._trainable_func(self.config),\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/tune/trainable/function_trainable.py\", line 248, in _trainable_func\n",
      "    output = fn()\n",
      "             ^^^^\n",
      "  File \"/tmp/ipykernel_49542/864962306.py\", line 37, in train_model\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 544, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py\", line 44, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 580, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 949, in _run\n",
      "    call._call_setup_hook(self)  # allow user to set up LightningModule in accelerator environment\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py\", line 94, in _call_setup_hook\n",
      "    _call_lightning_module_hook(trainer, \"setup\", stage=fn)\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py\", line 157, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_49542/2118502779.py\", line 6, in setup\n",
      "  File \"/tmp/ipykernel_49542/1551172284.py\", line 25, in __init__\n",
      "sqlite3.OperationalError: unable to open database file\n",
      "2024-05-13 22:16:07,504\tERROR tune_controller.py:1331 -- Trial task failed for trial train_model_974c0_00002\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/_private/worker.py\", line 2623, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/_private/worker.py\", line 861, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(OperationalError): ray::ImplicitFunc.train() (pid=53583, ip=10.20.30.2, actor_id=c5f828045d0317f97ce4f96801000000, repr=train_model)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/tune/trainable/trainable.py\", line 331, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/air/_internal/util.py\", line 98, in run\n",
      "    self._ret = self._target(*self._args, **self._kwargs)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/tune/trainable/function_trainable.py\", line 45, in <lambda>\n",
      "    training_func=lambda: self._trainable_func(self.config),\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/tune/trainable/function_trainable.py\", line 248, in _trainable_func\n",
      "    output = fn()\n",
      "             ^^^^\n",
      "  File \"/tmp/ipykernel_49542/864962306.py\", line 37, in train_model\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 544, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py\", line 44, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 580, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 949, in _run\n",
      "    call._call_setup_hook(self)  # allow user to set up LightningModule in accelerator environment\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py\", line 94, in _call_setup_hook\n",
      "    _call_lightning_module_hook(trainer, \"setup\", stage=fn)\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py\", line 157, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_49542/2118502779.py\", line 6, in setup\n",
      "  File \"/tmp/ipykernel_49542/1551172284.py\", line 25, in __init__\n",
      "sqlite3.OperationalError: unable to open database file\n",
      "2024-05-13 22:16:13,809\tERROR tune_controller.py:1331 -- Trial task failed for trial train_model_974c0_00003\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/_private/worker.py\", line 2623, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/_private/worker.py\", line 861, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(OperationalError): ray::ImplicitFunc.train() (pid=53646, ip=10.20.30.2, actor_id=13cfc76943269ff07552142801000000, repr=train_model)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/tune/trainable/trainable.py\", line 331, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/air/_internal/util.py\", line 98, in run\n",
      "    self._ret = self._target(*self._args, **self._kwargs)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/tune/trainable/function_trainable.py\", line 45, in <lambda>\n",
      "    training_func=lambda: self._trainable_func(self.config),\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/tune/trainable/function_trainable.py\", line 248, in _trainable_func\n",
      "    output = fn()\n",
      "             ^^^^\n",
      "  File \"/tmp/ipykernel_49542/864962306.py\", line 37, in train_model\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 544, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py\", line 44, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 580, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 949, in _run\n",
      "    call._call_setup_hook(self)  # allow user to set up LightningModule in accelerator environment\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py\", line 94, in _call_setup_hook\n",
      "    _call_lightning_module_hook(trainer, \"setup\", stage=fn)\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py\", line 157, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_49542/2118502779.py\", line 6, in setup\n",
      "  File \"/tmp/ipykernel_49542/1551172284.py\", line 25, in __init__\n",
      "sqlite3.OperationalError: unable to open database file\n",
      "2024-05-13 22:16:19,943\tERROR tune_controller.py:1331 -- Trial task failed for trial train_model_974c0_00004\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/_private/worker.py\", line 2623, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/_private/worker.py\", line 861, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(OperationalError): ray::ImplicitFunc.train() (pid=53711, ip=10.20.30.2, actor_id=75432f4510cac7ebc3cba5f701000000, repr=train_model)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/tune/trainable/trainable.py\", line 331, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/air/_internal/util.py\", line 98, in run\n",
      "    self._ret = self._target(*self._args, **self._kwargs)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/tune/trainable/function_trainable.py\", line 45, in <lambda>\n",
      "    training_func=lambda: self._trainable_func(self.config),\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/tune/trainable/function_trainable.py\", line 248, in _trainable_func\n",
      "    output = fn()\n",
      "             ^^^^\n",
      "  File \"/tmp/ipykernel_49542/864962306.py\", line 37, in train_model\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 544, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py\", line 44, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 580, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 949, in _run\n",
      "    call._call_setup_hook(self)  # allow user to set up LightningModule in accelerator environment\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py\", line 94, in _call_setup_hook\n",
      "    _call_lightning_module_hook(trainer, \"setup\", stage=fn)\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py\", line 157, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_49542/2118502779.py\", line 6, in setup\n",
      "  File \"/tmp/ipykernel_49542/1551172284.py\", line 25, in __init__\n",
      "sqlite3.OperationalError: unable to open database file\n",
      "2024-05-13 22:16:25,509\tERROR tune_controller.py:1331 -- Trial task failed for trial train_model_974c0_00005\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/_private/worker.py\", line 2623, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/_private/worker.py\", line 861, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(OperationalError): ray::ImplicitFunc.train() (pid=53775, ip=10.20.30.2, actor_id=1c2ca8b8eb7faf100a86d51c01000000, repr=train_model)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/tune/trainable/trainable.py\", line 331, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/air/_internal/util.py\", line 98, in run\n",
      "    self._ret = self._target(*self._args, **self._kwargs)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/tune/trainable/function_trainable.py\", line 45, in <lambda>\n",
      "    training_func=lambda: self._trainable_func(self.config),\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/tune/trainable/function_trainable.py\", line 248, in _trainable_func\n",
      "    output = fn()\n",
      "             ^^^^\n",
      "  File \"/tmp/ipykernel_49542/864962306.py\", line 37, in train_model\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 544, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py\", line 44, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 580, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 949, in _run\n",
      "    call._call_setup_hook(self)  # allow user to set up LightningModule in accelerator environment\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py\", line 94, in _call_setup_hook\n",
      "    _call_lightning_module_hook(trainer, \"setup\", stage=fn)\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py\", line 157, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_49542/2118502779.py\", line 6, in setup\n",
      "  File \"/tmp/ipykernel_49542/1551172284.py\", line 25, in __init__\n",
      "sqlite3.OperationalError: unable to open database file\n",
      "2024-05-13 22:16:27,796\tWARNING tune.py:219 -- Stop signal received (e.g. via SIGINT/Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C (or send SIGINT/SIGKILL/SIGTERM) to skip. \n",
      "2024-05-13 22:16:27,801\tINFO tune.py:1007 -- Wrote the latest version of all result files and experiment state to '/home/danielkleczykkleczynski/ray_results/train_model_2024-05-13_22-15-49' in 0.0030s.\n",
      "2024-05-13 22:16:29,103\tERROR tune.py:1035 -- Trials did not complete: [train_model_974c0_00000, train_model_974c0_00001, train_model_974c0_00002, train_model_974c0_00003, train_model_974c0_00004, train_model_974c0_00005]\n",
      "2024-05-13 22:16:29,104\tINFO tune.py:1039 -- Total run time: 39.18 seconds (37.84 seconds for the tuning loop).\n",
      "2024-05-13 22:16:29,105\tWARNING tune.py:1054 -- Experiment has been interrupted, but the most recent state was saved.\n",
      "Resume experiment with: tune.run(..., resume=True)\n",
      "2024-05-13 22:16:29,109\tWARNING experiment_analysis.py:180 -- Failed to fetch metrics for 4 trial(s):\n",
      "- train_model_974c0_00006: FileNotFoundError('Could not fetch metrics for train_model_974c0_00006: both result.json and progress.csv were not found at /home/danielkleczykkleczynski/ray_results/train_model_2024-05-13_22-15-49/train_model_974c0_00006_6_batch_size=8,hidden_size=512,lr=0.0008,num_layers=2,sequence_length=10_2024-05-13_22-15-50')\n",
      "- train_model_974c0_00007: FileNotFoundError('Could not fetch metrics for train_model_974c0_00007: both result.json and progress.csv were not found at /home/danielkleczykkleczynski/ray_results/train_model_2024-05-13_22-15-49/train_model_974c0_00007_7_batch_size=64,hidden_size=512,lr=0.0041,num_layers=1,sequence_length=10_2024-05-13_22-15-50')\n",
      "- train_model_974c0_00008: FileNotFoundError('Could not fetch metrics for train_model_974c0_00008: both result.json and progress.csv were not found at /home/danielkleczykkleczynski/ray_results/train_model_2024-05-13_22-15-49/train_model_974c0_00008_8_batch_size=32,hidden_size=256,lr=0.0143,num_layers=3,sequence_length=10_2024-05-13_22-15-50')\n",
      "- train_model_974c0_00009: FileNotFoundError('Could not fetch metrics for train_model_974c0_00009: both result.json and progress.csv were not found at /home/danielkleczykkleczynski/ray_results/train_model_2024-05-13_22-15-49/train_model_974c0_00009_9_batch_size=16,hidden_size=1024,lr=0.0098,num_layers=1,sequence_length=200_2024-05-13_22-15-50')\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T19:39:59.447086Z",
     "start_time": "2024-05-13T19:39:23.882456Z"
    }
   },
   "source": [
    "import os\n",
    "from ray import tune\n",
    "from ray.tune.integration.pytorch_lightning import TuneReportCallback\n",
    "from pytorch_lightning import Trainer, LightningModule\n",
    "import torch\n",
    "\n",
    "\n",
    "def train_cwt_eeg(config):\n",
    "    model = CWT_EEG_CrossPersonValidation(config)\n",
    "    trainer = Trainer(\n",
    "        max_epochs=10,\n",
    "        progress_bar_refresh_rate=0,  # Disable progress bar for clearer logs\n",
    "        callbacks=[TuneReportCallback({\"loss\": \"ptl/val_loss\"}, on=\"validation_end\")],\n",
    "    )\n",
    "    trainer.fit(model)\n",
    "\n",
    "\n",
    "search_space = {\n",
    "    \"batch_size\": tune.choice([8, 16, 32, 64]),\n",
    "    \"sequence_length\": tune.choice([10, 100, 200]),\n",
    "    \"input_size\": 640,  # This is fixed for our dataset\n",
    "    \"hidden_size\": tune.choice([256, 512, 1024]),\n",
    "    \"num_layers\": tune.choice([1, 2, 3]),\n",
    "    \"lr\": tune.loguniform(1e-5, 1e-1),\n",
    "    \"label_smoothing\": 0,\n",
    "}\n",
    "# Uruchomienie procesu optymalizacji\n",
    "analysis = tune.run(\n",
    "    train_cwt_eeg,\n",
    "    config=search_space,\n",
    "    num_samples=10,\n",
    "    resources_per_trial={\"cpu\": 1, \"gpu\": 1},  # Adjust based on your system's resources\n",
    ")\n",
    "\n",
    "print(\"Best hyperparameters found were: \", analysis.best_config)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-05-13 21:39:24,055\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2024-05-13 21:39:24,126\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2024-05-13 21:39:27,385\tINFO worker.py:1749 -- Started a local Ray instance.\n",
      "2024-05-13 21:39:28,115\tINFO tune.py:253 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `tune.run(...)`.\n",
      "2024-05-13 21:39:28,118\tINFO tune.py:614 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-05-13 21:39:28</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:00.20        </td></tr>\n",
       "<tr><td>Memory:      </td><td>6.2/196.5 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 1.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name               </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  hidden_size</th><th style=\"text-align: right;\">         lr</th><th style=\"text-align: right;\">  num_layers</th><th style=\"text-align: right;\">  sequence_length</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_cwt_eeg_82d7b_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">         1024</td><td style=\"text-align: right;\">0.0021997  </td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">              100</td></tr>\n",
       "<tr><td>train_cwt_eeg_82d7b_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">2.37989e-05</td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">               10</td></tr>\n",
       "<tr><td>train_cwt_eeg_82d7b_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">          512</td><td style=\"text-align: right;\">2.43385e-05</td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">               10</td></tr>\n",
       "<tr><td>train_cwt_eeg_82d7b_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">0.00446787 </td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">              100</td></tr>\n",
       "<tr><td>train_cwt_eeg_82d7b_00004</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">5.90858e-05</td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\">              200</td></tr>\n",
       "<tr><td>train_cwt_eeg_82d7b_00005</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">          512</td><td style=\"text-align: right;\">5.28101e-05</td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\">              100</td></tr>\n",
       "<tr><td>train_cwt_eeg_82d7b_00006</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">          512</td><td style=\"text-align: right;\">1.41447e-05</td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">               10</td></tr>\n",
       "<tr><td>train_cwt_eeg_82d7b_00007</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">          512</td><td style=\"text-align: right;\">0.0187044  </td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\">              200</td></tr>\n",
       "<tr><td>train_cwt_eeg_82d7b_00008</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          512</td><td style=\"text-align: right;\">0.006521   </td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">              200</td></tr>\n",
       "<tr><td>train_cwt_eeg_82d7b_00009</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">0.0183269  </td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">              200</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-13 21:39:31,237\tERROR tune_controller.py:1331 -- Trial task failed for trial train_cwt_eeg_82d7b_00000\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/_private/worker.py\", line 2623, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/_private/worker.py\", line 861, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): ray::ImplicitFunc.train() (pid=51902, ip=10.20.30.2, actor_id=632c0e06764298e56534958a01000000, repr=train_cwt_eeg)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/tune/trainable/trainable.py\", line 331, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/air/_internal/util.py\", line 98, in run\n",
      "    self._ret = self._target(*self._args, **self._kwargs)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/tune/trainable/function_trainable.py\", line 45, in <lambda>\n",
      "    training_func=lambda: self._trainable_func(self.config),\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/tune/trainable/function_trainable.py\", line 248, in _trainable_func\n",
      "    output = fn()\n",
      "             ^^^^\n",
      "  File \"/tmp/ipykernel_49542/2705197209.py\", line 9, in train_cwt_eeg\n",
      "TypeError: CWT_EEG_CrossPersonValidation.__init__() missing 5 required positional arguments: 'sequence_length', 'input_size', 'hidden_size', 'num_layers', and 'lr'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-05-13 21:39:57</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:29.29        </td></tr>\n",
       "<tr><td>Memory:      </td><td>6.4/196.5 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 1.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "<div class=\"messages\">\n",
       "  <h3>Messages</h3>\n",
       "  \n",
       "  \n",
       "  Number of errored trials: 9<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name               </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                                                                                                                                                                            </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_cwt_eeg_82d7b_00000</td><td style=\"text-align: right;\">           1</td><td>/tmp/ray/session_2024-05-13_21-39-24_464251_49542/artifacts/2024-05-13_21-39-28/train_cwt_eeg_2024-05-13_21-39-28/driver_artifacts/train_cwt_eeg_82d7b_00000_0_batch_size=64,hidden_size=1024,lr=0.0022,num_layers=2,sequence_length=100_2024-05-13_21-39-28/error.txt</td></tr>\n",
       "<tr><td>train_cwt_eeg_82d7b_00001</td><td style=\"text-align: right;\">           1</td><td>/tmp/ray/session_2024-05-13_21-39-24_464251_49542/artifacts/2024-05-13_21-39-28/train_cwt_eeg_2024-05-13_21-39-28/driver_artifacts/train_cwt_eeg_82d7b_00001_1_batch_size=16,hidden_size=256,lr=0.0000,num_layers=1,sequence_length=10_2024-05-13_21-39-28/error.txt  </td></tr>\n",
       "<tr><td>train_cwt_eeg_82d7b_00002</td><td style=\"text-align: right;\">           1</td><td>/tmp/ray/session_2024-05-13_21-39-24_464251_49542/artifacts/2024-05-13_21-39-28/train_cwt_eeg_2024-05-13_21-39-28/driver_artifacts/train_cwt_eeg_82d7b_00002_2_batch_size=8,hidden_size=512,lr=0.0000,num_layers=1,sequence_length=10_2024-05-13_21-39-28/error.txt   </td></tr>\n",
       "<tr><td>train_cwt_eeg_82d7b_00003</td><td style=\"text-align: right;\">           1</td><td>/tmp/ray/session_2024-05-13_21-39-24_464251_49542/artifacts/2024-05-13_21-39-28/train_cwt_eeg_2024-05-13_21-39-28/driver_artifacts/train_cwt_eeg_82d7b_00003_3_batch_size=64,hidden_size=256,lr=0.0045,num_layers=2,sequence_length=100_2024-05-13_21-39-28/error.txt </td></tr>\n",
       "<tr><td>train_cwt_eeg_82d7b_00004</td><td style=\"text-align: right;\">           1</td><td>/tmp/ray/session_2024-05-13_21-39-24_464251_49542/artifacts/2024-05-13_21-39-28/train_cwt_eeg_2024-05-13_21-39-28/driver_artifacts/train_cwt_eeg_82d7b_00004_4_batch_size=64,hidden_size=256,lr=0.0001,num_layers=3,sequence_length=200_2024-05-13_21-39-28/error.txt </td></tr>\n",
       "<tr><td>train_cwt_eeg_82d7b_00005</td><td style=\"text-align: right;\">           1</td><td>/tmp/ray/session_2024-05-13_21-39-24_464251_49542/artifacts/2024-05-13_21-39-28/train_cwt_eeg_2024-05-13_21-39-28/driver_artifacts/train_cwt_eeg_82d7b_00005_5_batch_size=8,hidden_size=512,lr=0.0001,num_layers=3,sequence_length=100_2024-05-13_21-39-28/error.txt  </td></tr>\n",
       "<tr><td>train_cwt_eeg_82d7b_00006</td><td style=\"text-align: right;\">           1</td><td>/tmp/ray/session_2024-05-13_21-39-24_464251_49542/artifacts/2024-05-13_21-39-28/train_cwt_eeg_2024-05-13_21-39-28/driver_artifacts/train_cwt_eeg_82d7b_00006_6_batch_size=8,hidden_size=512,lr=0.0000,num_layers=2,sequence_length=10_2024-05-13_21-39-28/error.txt   </td></tr>\n",
       "<tr><td>train_cwt_eeg_82d7b_00007</td><td style=\"text-align: right;\">           1</td><td>/tmp/ray/session_2024-05-13_21-39-24_464251_49542/artifacts/2024-05-13_21-39-28/train_cwt_eeg_2024-05-13_21-39-28/driver_artifacts/train_cwt_eeg_82d7b_00007_7_batch_size=16,hidden_size=512,lr=0.0187,num_layers=3,sequence_length=200_2024-05-13_21-39-28/error.txt </td></tr>\n",
       "<tr><td>train_cwt_eeg_82d7b_00008</td><td style=\"text-align: right;\">           1</td><td>/tmp/ray/session_2024-05-13_21-39-24_464251_49542/artifacts/2024-05-13_21-39-28/train_cwt_eeg_2024-05-13_21-39-28/driver_artifacts/train_cwt_eeg_82d7b_00008_8_batch_size=64,hidden_size=512,lr=0.0065,num_layers=2,sequence_length=200_2024-05-13_21-39-28/error.txt </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".messages {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  padding-left: 1em;\n",
       "  overflow-y: auto;\n",
       "}\n",
       ".messages h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n",
       "\n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name               </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  hidden_size</th><th style=\"text-align: right;\">         lr</th><th style=\"text-align: right;\">  num_layers</th><th style=\"text-align: right;\">  sequence_length</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_cwt_eeg_82d7b_00009</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">0.0183269  </td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">              200</td></tr>\n",
       "<tr><td>train_cwt_eeg_82d7b_00000</td><td>ERROR   </td><td>10.20.30.2:51902</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">         1024</td><td style=\"text-align: right;\">0.0021997  </td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">              100</td></tr>\n",
       "<tr><td>train_cwt_eeg_82d7b_00001</td><td>ERROR   </td><td>10.20.30.2:51989</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">2.37989e-05</td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">               10</td></tr>\n",
       "<tr><td>train_cwt_eeg_82d7b_00002</td><td>ERROR   </td><td>10.20.30.2:52075</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">          512</td><td style=\"text-align: right;\">2.43385e-05</td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">               10</td></tr>\n",
       "<tr><td>train_cwt_eeg_82d7b_00003</td><td>ERROR   </td><td>10.20.30.2:52135</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">0.00446787 </td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">              100</td></tr>\n",
       "<tr><td>train_cwt_eeg_82d7b_00004</td><td>ERROR   </td><td>10.20.30.2:52198</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">5.90858e-05</td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\">              200</td></tr>\n",
       "<tr><td>train_cwt_eeg_82d7b_00005</td><td>ERROR   </td><td>10.20.30.2:52258</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">          512</td><td style=\"text-align: right;\">5.28101e-05</td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\">              100</td></tr>\n",
       "<tr><td>train_cwt_eeg_82d7b_00006</td><td>ERROR   </td><td>10.20.30.2:52318</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">          512</td><td style=\"text-align: right;\">1.41447e-05</td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">               10</td></tr>\n",
       "<tr><td>train_cwt_eeg_82d7b_00007</td><td>ERROR   </td><td>10.20.30.2:52379</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">          512</td><td style=\"text-align: right;\">0.0187044  </td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\">              200</td></tr>\n",
       "<tr><td>train_cwt_eeg_82d7b_00008</td><td>ERROR   </td><td>10.20.30.2:52439</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          512</td><td style=\"text-align: right;\">0.006521   </td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">              200</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-13 21:39:34,378\tERROR tune_controller.py:1331 -- Trial task failed for trial train_cwt_eeg_82d7b_00001\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/_private/worker.py\", line 2623, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/_private/worker.py\", line 861, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): ray::ImplicitFunc.train() (pid=51989, ip=10.20.30.2, actor_id=50170d417102afd9fbb4053401000000, repr=train_cwt_eeg)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/tune/trainable/trainable.py\", line 331, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/air/_internal/util.py\", line 98, in run\n",
      "    self._ret = self._target(*self._args, **self._kwargs)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/tune/trainable/function_trainable.py\", line 45, in <lambda>\n",
      "    training_func=lambda: self._trainable_func(self.config),\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/tune/trainable/function_trainable.py\", line 248, in _trainable_func\n",
      "    output = fn()\n",
      "             ^^^^\n",
      "  File \"/tmp/ipykernel_49542/2705197209.py\", line 9, in train_cwt_eeg\n",
      "TypeError: CWT_EEG_CrossPersonValidation.__init__() missing 5 required positional arguments: 'sequence_length', 'input_size', 'hidden_size', 'num_layers', and 'lr'\n",
      "2024-05-13 21:39:37,259\tERROR tune_controller.py:1331 -- Trial task failed for trial train_cwt_eeg_82d7b_00002\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/_private/worker.py\", line 2623, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/_private/worker.py\", line 861, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): ray::ImplicitFunc.train() (pid=52075, ip=10.20.30.2, actor_id=9f4ac7679fe014fbab5f593801000000, repr=train_cwt_eeg)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/tune/trainable/trainable.py\", line 331, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/air/_internal/util.py\", line 98, in run\n",
      "    self._ret = self._target(*self._args, **self._kwargs)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/tune/trainable/function_trainable.py\", line 45, in <lambda>\n",
      "    training_func=lambda: self._trainable_func(self.config),\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/tune/trainable/function_trainable.py\", line 248, in _trainable_func\n",
      "    output = fn()\n",
      "             ^^^^\n",
      "  File \"/tmp/ipykernel_49542/2705197209.py\", line 9, in train_cwt_eeg\n",
      "TypeError: CWT_EEG_CrossPersonValidation.__init__() missing 5 required positional arguments: 'sequence_length', 'input_size', 'hidden_size', 'num_layers', and 'lr'\n",
      "2024-05-13 21:39:40,473\tERROR tune_controller.py:1331 -- Trial task failed for trial train_cwt_eeg_82d7b_00003\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/_private/worker.py\", line 2623, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/_private/worker.py\", line 861, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): ray::ImplicitFunc.train() (pid=52135, ip=10.20.30.2, actor_id=32a424ea9259eec57a6a830f01000000, repr=train_cwt_eeg)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/tune/trainable/trainable.py\", line 331, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/air/_internal/util.py\", line 98, in run\n",
      "    self._ret = self._target(*self._args, **self._kwargs)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/tune/trainable/function_trainable.py\", line 45, in <lambda>\n",
      "    training_func=lambda: self._trainable_func(self.config),\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/tune/trainable/function_trainable.py\", line 248, in _trainable_func\n",
      "    output = fn()\n",
      "             ^^^^\n",
      "  File \"/tmp/ipykernel_49542/2705197209.py\", line 9, in train_cwt_eeg\n",
      "TypeError: CWT_EEG_CrossPersonValidation.__init__() missing 5 required positional arguments: 'sequence_length', 'input_size', 'hidden_size', 'num_layers', and 'lr'\n",
      "2024-05-13 21:39:43,253\tERROR tune_controller.py:1331 -- Trial task failed for trial train_cwt_eeg_82d7b_00004\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/_private/worker.py\", line 2623, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/_private/worker.py\", line 861, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): ray::ImplicitFunc.train() (pid=52198, ip=10.20.30.2, actor_id=3db2d2bd4b239da63d142b2501000000, repr=train_cwt_eeg)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/tune/trainable/trainable.py\", line 331, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/air/_internal/util.py\", line 98, in run\n",
      "    self._ret = self._target(*self._args, **self._kwargs)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/tune/trainable/function_trainable.py\", line 45, in <lambda>\n",
      "    training_func=lambda: self._trainable_func(self.config),\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/tune/trainable/function_trainable.py\", line 248, in _trainable_func\n",
      "    output = fn()\n",
      "             ^^^^\n",
      "  File \"/tmp/ipykernel_49542/2705197209.py\", line 9, in train_cwt_eeg\n",
      "TypeError: CWT_EEG_CrossPersonValidation.__init__() missing 5 required positional arguments: 'sequence_length', 'input_size', 'hidden_size', 'num_layers', and 'lr'\n",
      "2024-05-13 21:39:46,237\tERROR tune_controller.py:1331 -- Trial task failed for trial train_cwt_eeg_82d7b_00005\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/_private/worker.py\", line 2623, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/_private/worker.py\", line 861, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): ray::ImplicitFunc.train() (pid=52258, ip=10.20.30.2, actor_id=075500d19ba2fda4f2b7304601000000, repr=train_cwt_eeg)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/tune/trainable/trainable.py\", line 331, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/air/_internal/util.py\", line 98, in run\n",
      "    self._ret = self._target(*self._args, **self._kwargs)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/tune/trainable/function_trainable.py\", line 45, in <lambda>\n",
      "    training_func=lambda: self._trainable_func(self.config),\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/tune/trainable/function_trainable.py\", line 248, in _trainable_func\n",
      "    output = fn()\n",
      "             ^^^^\n",
      "  File \"/tmp/ipykernel_49542/2705197209.py\", line 9, in train_cwt_eeg\n",
      "TypeError: CWT_EEG_CrossPersonValidation.__init__() missing 5 required positional arguments: 'sequence_length', 'input_size', 'hidden_size', 'num_layers', and 'lr'\n",
      "2024-05-13 21:39:49,536\tERROR tune_controller.py:1331 -- Trial task failed for trial train_cwt_eeg_82d7b_00006\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/_private/worker.py\", line 2623, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/_private/worker.py\", line 861, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): ray::ImplicitFunc.train() (pid=52318, ip=10.20.30.2, actor_id=2db632bca58cd236f35cef4d01000000, repr=train_cwt_eeg)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/tune/trainable/trainable.py\", line 331, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/air/_internal/util.py\", line 98, in run\n",
      "    self._ret = self._target(*self._args, **self._kwargs)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/tune/trainable/function_trainable.py\", line 45, in <lambda>\n",
      "    training_func=lambda: self._trainable_func(self.config),\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/tune/trainable/function_trainable.py\", line 248, in _trainable_func\n",
      "    output = fn()\n",
      "             ^^^^\n",
      "  File \"/tmp/ipykernel_49542/2705197209.py\", line 9, in train_cwt_eeg\n",
      "TypeError: CWT_EEG_CrossPersonValidation.__init__() missing 5 required positional arguments: 'sequence_length', 'input_size', 'hidden_size', 'num_layers', and 'lr'\n",
      "2024-05-13 21:39:53,359\tERROR tune_controller.py:1331 -- Trial task failed for trial train_cwt_eeg_82d7b_00007\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/_private/worker.py\", line 2623, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/_private/worker.py\", line 861, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): ray::ImplicitFunc.train() (pid=52379, ip=10.20.30.2, actor_id=fb9008f18eb4ae3c623f479001000000, repr=train_cwt_eeg)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/tune/trainable/trainable.py\", line 331, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/air/_internal/util.py\", line 98, in run\n",
      "    self._ret = self._target(*self._args, **self._kwargs)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/tune/trainable/function_trainable.py\", line 45, in <lambda>\n",
      "    training_func=lambda: self._trainable_func(self.config),\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/tune/trainable/function_trainable.py\", line 248, in _trainable_func\n",
      "    output = fn()\n",
      "             ^^^^\n",
      "  File \"/tmp/ipykernel_49542/2705197209.py\", line 9, in train_cwt_eeg\n",
      "TypeError: CWT_EEG_CrossPersonValidation.__init__() missing 5 required positional arguments: 'sequence_length', 'input_size', 'hidden_size', 'num_layers', and 'lr'\n",
      "2024-05-13 21:39:56,267\tERROR tune_controller.py:1331 -- Trial task failed for trial train_cwt_eeg_82d7b_00008\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/_private/worker.py\", line 2623, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/_private/worker.py\", line 861, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): ray::ImplicitFunc.train() (pid=52439, ip=10.20.30.2, actor_id=c5b9d42e88eaf335274ba41e01000000, repr=train_cwt_eeg)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/tune/trainable/trainable.py\", line 331, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/air/_internal/util.py\", line 98, in run\n",
      "    self._ret = self._target(*self._args, **self._kwargs)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/tune/trainable/function_trainable.py\", line 45, in <lambda>\n",
      "    training_func=lambda: self._trainable_func(self.config),\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/danielkleczykkleczynski/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/tune/trainable/function_trainable.py\", line 248, in _trainable_func\n",
      "    output = fn()\n",
      "             ^^^^\n",
      "  File \"/tmp/ipykernel_49542/2705197209.py\", line 9, in train_cwt_eeg\n",
      "TypeError: CWT_EEG_CrossPersonValidation.__init__() missing 5 required positional arguments: 'sequence_length', 'input_size', 'hidden_size', 'num_layers', and 'lr'\n",
      "2024-05-13 21:39:57,479\tWARNING tune.py:219 -- Stop signal received (e.g. via SIGINT/Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C (or send SIGINT/SIGKILL/SIGTERM) to skip. \n",
      "2024-05-13 21:39:57,489\tINFO tune.py:1007 -- Wrote the latest version of all result files and experiment state to '/home/danielkleczykkleczynski/ray_results/train_cwt_eeg_2024-05-13_21-39-28' in 0.0091s.\n",
      "2024-05-13 21:39:59,353\tERROR tune.py:1035 -- Trials did not complete: [train_cwt_eeg_82d7b_00000, train_cwt_eeg_82d7b_00001, train_cwt_eeg_82d7b_00002, train_cwt_eeg_82d7b_00003, train_cwt_eeg_82d7b_00004, train_cwt_eeg_82d7b_00005, train_cwt_eeg_82d7b_00006, train_cwt_eeg_82d7b_00007, train_cwt_eeg_82d7b_00008]\n",
      "2024-05-13 21:39:59,354\tINFO tune.py:1039 -- Total run time: 31.24 seconds (29.28 seconds for the tuning loop).\n",
      "2024-05-13 21:39:59,355\tWARNING tune.py:1054 -- Experiment has been interrupted, but the most recent state was saved.\n",
      "Resume experiment with: tune.run(..., resume=True)\n",
      "2024-05-13 21:39:59,360\tWARNING experiment_analysis.py:180 -- Failed to fetch metrics for 1 trial(s):\n",
      "- train_cwt_eeg_82d7b_00009: FileNotFoundError('Could not fetch metrics for train_cwt_eeg_82d7b_00009: both result.json and progress.csv were not found at /home/danielkleczykkleczynski/ray_results/train_cwt_eeg_2024-05-13_21-39-28/train_cwt_eeg_82d7b_00009_9_batch_size=64,hidden_size=256,lr=0.0183,num_layers=2,sequence_length=200_2024-05-13_21-39-28')\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "To fetch the `best_config`, pass a `metric` and `mode` parameter to `tune.run()`. Alternatively, use the `get_best_config(metric, mode)` method to set the metric and mode explicitly.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 35\u001B[0m\n\u001B[1;32m     27\u001B[0m \u001B[38;5;66;03m# Uruchomienie procesu optymalizacji\u001B[39;00m\n\u001B[1;32m     28\u001B[0m analysis \u001B[38;5;241m=\u001B[39m tune\u001B[38;5;241m.\u001B[39mrun(\n\u001B[1;32m     29\u001B[0m     train_cwt_eeg,\n\u001B[1;32m     30\u001B[0m     config\u001B[38;5;241m=\u001B[39msearch_space,\n\u001B[1;32m     31\u001B[0m     num_samples\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m,\n\u001B[1;32m     32\u001B[0m     resources_per_trial\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m1\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgpu\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m1\u001B[39m},  \u001B[38;5;66;03m# Adjust based on your system's resources\u001B[39;00m\n\u001B[1;32m     33\u001B[0m )\n\u001B[0;32m---> 35\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBest hyperparameters found were: \u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[43manalysis\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbest_config\u001B[49m)\n",
      "File \u001B[0;32m~/miniconda3/envs/EEG311M/lib/python3.11/site-packages/ray/tune/analysis/experiment_analysis.py:240\u001B[0m, in \u001B[0;36mExperimentAnalysis.best_config\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    231\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Get the config of the best trial of the experiment\u001B[39;00m\n\u001B[1;32m    232\u001B[0m \n\u001B[1;32m    233\u001B[0m \u001B[38;5;124;03mThe best trial is determined by comparing the last trial results\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    237\u001B[0m \u001B[38;5;124;03m`get_best_config(metric, mode, scope)` instead.\u001B[39;00m\n\u001B[1;32m    238\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    239\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdefault_metric \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdefault_mode:\n\u001B[0;32m--> 240\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    241\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTo fetch the `best_config`, pass a `metric` and `mode` \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    242\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter to `tune.run()`. Alternatively, use the \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    243\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`get_best_config(metric, mode)` method to set the metric \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    244\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mand mode explicitly.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    245\u001B[0m     )\n\u001B[1;32m    246\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_best_config(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdefault_metric, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdefault_mode)\n",
      "\u001B[0;31mValueError\u001B[0m: To fetch the `best_config`, pass a `metric` and `mode` parameter to `tune.run()`. Alternatively, use the `get_best_config(metric, mode)` method to set the metric and mode explicitly."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(train_model pid=53252) GPU available: True (cuda), used: True\n",
      "(train_model pid=53252) TPU available: False, using: 0 TPU cores\n",
      "(train_model pid=53252) IPU available: False, using: 0 IPUs\n",
      "(train_model pid=53252) HPU available: False, using: 0 HPUs\n",
      "(train_model pid=53252) Missing logger folder: /tmp/ray/session_2024-05-13_21-39-24_464251_49542/artifacts/2024-05-13_22-10-12/train_model_2024-05-13_22-10-12/working_dirs/train_model_ce18c_00000_0_batch_size=32,hidden_size=256,lr=0.0016,num_layers=2,sequence_length=200_2024-05-13_22-10-12/lightning_logs\n",
      "(train_model pid=53252) 2024-05-13 22:10:16.704882: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "(train_model pid=53252) 2024-05-13 22:10:16.762331: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "(train_model pid=53252) To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "(train_model pid=53252) 2024-05-13 22:10:17.605124: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "(train_model pid=53252) Exception ignored in: <function CWTDataset.__del__ at 0x7f57fae7d300>\n",
      "(train_model pid=53252) Traceback (most recent call last):\n",
      "(train_model pid=53252)   File \"/tmp/ipykernel_49542/1551172284.py\", line 66, in __del__\n",
      "(train_model pid=53252) AttributeError: 'CWTDataset' object has no attribute 'conn'\n",
      "(train_model pid=53317) GPU available: True (cuda), used: True\n",
      "(train_model pid=53317) TPU available: False, using: 0 TPU cores\n",
      "(train_model pid=53317) IPU available: False, using: 0 IPUs\n",
      "(train_model pid=53317) HPU available: False, using: 0 HPUs\n",
      "(train_model pid=53317) Missing logger folder: /tmp/ray/session_2024-05-13_21-39-24_464251_49542/artifacts/2024-05-13_22-10-12/train_model_2024-05-13_22-10-12/working_dirs/train_model_ce18c_00001_1_batch_size=32,hidden_size=512,lr=0.0032,num_layers=1,sequence_length=10_2024-05-13_22-10-12/lightning_logs\n",
      "(train_model pid=53317) 2024-05-13 22:10:23.060967: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "(train_model pid=53317) 2024-05-13 22:10:23.114908: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "(train_model pid=53317) To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "(train_model pid=53317) 2024-05-13 22:10:23.992436: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "(train_model pid=53382) GPU available: True (cuda), used: True\n",
      "(train_model pid=53382) TPU available: False, using: 0 TPU cores\n",
      "(train_model pid=53382) IPU available: False, using: 0 IPUs\n",
      "(train_model pid=53382) HPU available: False, using: 0 HPUs\n",
      "(train_model pid=53382) Missing logger folder: /tmp/ray/session_2024-05-13_21-39-24_464251_49542/artifacts/2024-05-13_22-10-12/train_model_2024-05-13_22-10-12/working_dirs/train_model_ce18c_00002_2_batch_size=16,hidden_size=1024,lr=0.0005,num_layers=2,sequence_length=200_2024-05-13_22-10-12/lightning_logs\n",
      "(train_model pid=53382) 2024-05-13 22:10:29.086852: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "(train_model pid=53382) 2024-05-13 22:10:29.143617: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "(train_model pid=53382) To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "(train_model pid=53382) 2024-05-13 22:10:30.110645: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "(train_model pid=53453) GPU available: True (cuda), used: True\n",
      "(train_model pid=53453) TPU available: False, using: 0 TPU cores\n",
      "(train_model pid=53453) IPU available: False, using: 0 IPUs\n",
      "(train_model pid=53453) HPU available: False, using: 0 HPUs\n",
      "(train_model pid=53453) Missing logger folder: /tmp/ray/session_2024-05-13_21-39-24_464251_49542/artifacts/2024-05-13_22-15-49/train_model_2024-05-13_22-15-49/working_dirs/train_model_974c0_00000_0_batch_size=64,hidden_size=1024,lr=0.0731,num_layers=2,sequence_length=200_2024-05-13_22-15-49/lightning_logs\n",
      "(train_model pid=53453) 2024-05-13 22:15:53.943672: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "(train_model pid=53453) 2024-05-13 22:15:53.997893: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "(train_model pid=53453) To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "(train_model pid=53453) 2024-05-13 22:15:54.794308: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "(train_model pid=53453) Exception ignored in: <function CWTDataset.__del__ at 0x7f276ec4d300>\n",
      "(train_model pid=53453) Traceback (most recent call last):\n",
      "(train_model pid=53453)   File \"/tmp/ipykernel_49542/1551172284.py\", line 66, in __del__\n",
      "(train_model pid=53453) AttributeError: 'CWTDataset' object has no attribute 'conn'\n",
      "(train_model pid=53518) GPU available: True (cuda), used: True\n",
      "(train_model pid=53518) TPU available: False, using: 0 TPU cores\n",
      "(train_model pid=53518) IPU available: False, using: 0 IPUs\n",
      "(train_model pid=53518) HPU available: False, using: 0 HPUs\n",
      "(train_model pid=53518) Missing logger folder: /tmp/ray/session_2024-05-13_21-39-24_464251_49542/artifacts/2024-05-13_22-15-49/train_model_2024-05-13_22-15-49/working_dirs/train_model_974c0_00001_1_batch_size=64,hidden_size=256,lr=0.0012,num_layers=1,sequence_length=10_2024-05-13_22-15-49/lightning_logs\n",
      "(train_model pid=53518) 2024-05-13 22:16:00.238472: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "(train_model pid=53518) 2024-05-13 22:16:00.299927: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "(train_model pid=53518) To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "(train_model pid=53518) 2024-05-13 22:16:01.280510: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "(train_model pid=53583) GPU available: True (cuda), used: True\n",
      "(train_model pid=53583) TPU available: False, using: 0 TPU cores\n",
      "(train_model pid=53583) IPU available: False, using: 0 IPUs\n",
      "(train_model pid=53583) HPU available: False, using: 0 HPUs\n",
      "(train_model pid=53583) Missing logger folder: /tmp/ray/session_2024-05-13_21-39-24_464251_49542/artifacts/2024-05-13_22-15-49/train_model_2024-05-13_22-15-49/working_dirs/train_model_974c0_00002_2_batch_size=64,hidden_size=1024,lr=0.0021,num_layers=2,sequence_length=10_2024-05-13_22-15-49/lightning_logs\n",
      "(train_model pid=53583) 2024-05-13 22:16:05.972759: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "(train_model pid=53583) 2024-05-13 22:16:06.026738: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "(train_model pid=53583) To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "(train_model pid=53583) 2024-05-13 22:16:06.839141: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "(train_model pid=53646) GPU available: True (cuda), used: True\n",
      "(train_model pid=53646) TPU available: False, using: 0 TPU cores\n",
      "(train_model pid=53646) IPU available: False, using: 0 IPUs\n",
      "(train_model pid=53646) HPU available: False, using: 0 HPUs\n",
      "(train_model pid=53646) Missing logger folder: /tmp/ray/session_2024-05-13_21-39-24_464251_49542/artifacts/2024-05-13_22-15-49/train_model_2024-05-13_22-15-49/working_dirs/train_model_974c0_00003_3_batch_size=32,hidden_size=256,lr=0.0003,num_layers=1,sequence_length=200_2024-05-13_22-15-49/lightning_logs\n",
      "(train_model pid=53646) 2024-05-13 22:16:12.010930: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "(train_model pid=53646) 2024-05-13 22:16:12.071825: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "(train_model pid=53646) To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "(train_model pid=53646) 2024-05-13 22:16:13.043476: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "(train_model pid=53711) GPU available: True (cuda), used: True\n",
      "(train_model pid=53711) TPU available: False, using: 0 TPU cores\n",
      "(train_model pid=53711) IPU available: False, using: 0 IPUs\n",
      "(train_model pid=53711) HPU available: False, using: 0 HPUs\n",
      "(train_model pid=53711) Missing logger folder: /tmp/ray/session_2024-05-13_21-39-24_464251_49542/artifacts/2024-05-13_22-15-49/train_model_2024-05-13_22-15-49/working_dirs/train_model_974c0_00004_4_batch_size=32,hidden_size=1024,lr=0.0192,num_layers=2,sequence_length=10_2024-05-13_22-15-50/lightning_logs\n",
      "(train_model pid=53711) 2024-05-13 22:16:18.173319: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "(train_model pid=53711) 2024-05-13 22:16:18.229480: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "(train_model pid=53711) To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "(train_model pid=53711) 2024-05-13 22:16:19.166362: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "(train_model pid=53775) GPU available: True (cuda), used: True\n",
      "(train_model pid=53775) TPU available: False, using: 0 TPU cores\n",
      "(train_model pid=53775) IPU available: False, using: 0 IPUs\n",
      "(train_model pid=53775) HPU available: False, using: 0 HPUs\n",
      "(train_model pid=53775) Missing logger folder: /tmp/ray/session_2024-05-13_21-39-24_464251_49542/artifacts/2024-05-13_22-15-49/train_model_2024-05-13_22-15-49/working_dirs/train_model_974c0_00005_5_batch_size=8,hidden_size=256,lr=0.0002,num_layers=3,sequence_length=10_2024-05-13_22-15-50/lightning_logs\n",
      "(train_model pid=53775) 2024-05-13 22:16:23.970960: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "(train_model pid=53775) 2024-05-13 22:16:24.025757: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "(train_model pid=53775) To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "(train_model pid=53775) 2024-05-13 22:16:24.845839: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Utworzenie folderu dla logów\n",
    "writer = SummaryWriter('./lightning_logs/CWT_EEG')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "dummy_input = torch.randn(11, 10, 640).to(device)  # Przykładowe dane wejściowe (batch_size, input_size)\n",
    "writer.add_graph(model, dummy_input)\n",
    "writer.close()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class SimpleLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(SimpleLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # Warstwa LSTM\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size)\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        # Inicjalizacja stanu ukrytego i stanu komórki\n",
    "        # (num_layers * num_directions, batch, hidden_size)\n",
    "        h0 = torch.zeros(1, input_seq.size(1), self.hidden_size)\n",
    "        c0 = torch.zeros(1, input_seq.size(1), self.hidden_size)\n",
    "\n",
    "        # Przejście przez LSTM\n",
    "        lstm_out, _ = self.lstm(input_seq, (h0, c0))\n",
    "\n",
    "        return lstm_out\n",
    "\n",
    "\n",
    "# Parametry modelu\n",
    "input_size = 20  # Wymiary wejściowe (np. cechy)\n",
    "hidden_size = 10  # Wymiary stanu ukrytego LSTM\n",
    "\n",
    "# Tworzenie instancji modelu\n",
    "model = SimpleLSTM(input_size, hidden_size)\n",
    "\n",
    "dummy_input = torch.randn(1, 10, 20)  # Przykładowe dane wejściowe (batch_size, input_size)\n",
    "writer.add_graph(model, dummy_input)\n",
    "writer.close()\n",
    "# Wyświetlenie struktury modelu\n",
    "print(sum(p.numel() for p in model.parameters() if p.requires_grad))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def create_train_val_split(data_length, val_percent, sequence_length):\n",
    "    available_lenght = data_length - sequence_length\n",
    "    val_count = int(val_percent * available_lenght)\n",
    "    all_indices = np.arange(available_lenght)\n",
    "    val_indices = np.sort(np.random.choice(all_indices, size=val_count, replace=False))\n",
    "    mask = np.ones(available_lenght, dtype=bool)\n",
    "    for idx in val_indices:\n",
    "        start = max(0, idx - sequence_length + 1)\n",
    "        end = min(available_lenght, idx + sequence_length)\n",
    "        mask[start:end] = False\n",
    "    train_indices = np.where(mask)[0]\n",
    "    # convert evry number to int\n",
    "    train_indices = list(train_indices)\n",
    "    val_indices = list(val_indices)\n",
    "\n",
    "    return train_indices, val_indices"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from tensorboard.backend.event_processing import event_accumulator\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def load_tensorboard_scalars(logdir):\n",
    "    # Tworzy akumulator do odczytu danych\n",
    "    ea = event_accumulator.EventAccumulator(logdir,\n",
    "                                            size_guidance={event_accumulator.SCALARS: 0})  # 0 = bez ograniczeń\n",
    "    ea.Reload()  # Wczytaj wszystkie dane z dysku\n",
    "\n",
    "    # Odczyt danych skalarnych\n",
    "    scalars = {}\n",
    "    for tag in ea.Tags()['scalars']:\n",
    "        events = ea.Scalars(tag)\n",
    "        scalars[tag] = [(e.wall_time, e.step, e.value) for e in events]\n",
    "\n",
    "    return scalars\n",
    "\n",
    "\n",
    "# Ścieżka do katalogu z logami TensorBoard\n",
    "logdir = '/home/daniel/repos/Decoding_of_EEG/lightning_logs/CWT_EEG/version_51/events.out.tfevents.1713204451.pop-os.32833.5'\n",
    "\n",
    "# Wczytanie danych\n",
    "scalars = load_tensorboard_scalars(logdir)\n",
    "\n",
    "# Przykład wyświetlenia danych skalarnych\n",
    "tag = 'hp/train_acc_step'  # Zmień na odpowiedni tag, który chcesz wyświetlić\n",
    "times, steps, values = zip(*scalars[tag])\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(steps, values, label=tag)\n",
    "plt.xlabel('Krok')\n",
    "plt.ylabel('Wartość')\n",
    "plt.title('Wykres danych z TensorBoard')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "tag = 'hp/val_acc_step'  # Zmień na odpowiedni tag, który chcesz wyświetlić\n",
    "times, steps, values = zip(*scalars[tag])\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(steps, values, label=tag)\n",
    "plt.xlabel('Krok')\n",
    "plt.ylabel('Wartość')\n",
    "plt.title('Wykres danych z TensorBoard')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def generate_validation_indices(data_length, num_of_val_samples, sequence_length):\n",
    "    # Ustal minimalną odległość pomiędzy indeksami\n",
    "    min_distance = sequence_length + 1\n",
    "    # Utwórz set możliwych indeksów\n",
    "    available_indices = set(range(data_length))\n",
    "\n",
    "    chosen_indices = []\n",
    "    for i in range(num_of_val_samples):\n",
    "        if not available_indices:\n",
    "            raise ValueError(\"Nie można wygenerować więcej próbek z uwzględnieniem minimalnego dystansu\")\n",
    "\n",
    "        # Losuj indeks z dostępnych indeksów\n",
    "        chosen_index = np.random.choice(list(available_indices))\n",
    "        chosen_indices.append(chosen_index)\n",
    "\n",
    "        # Oblicz zakres indeksów do usunięcia\n",
    "        start = max(0, chosen_index - (2 * min_distance))\n",
    "        end = min(data_length, chosen_index + min_distance)\n",
    "\n",
    "        # Usuń indeksy zbyt blisko wybranego indeksu z zbioru available_indices\n",
    "        for idx in range(start, end + 1):\n",
    "            available_indices.discard(idx)  # discard nie zgłasza błędu, jeśli element nie istnieje\n",
    "\n",
    "        # Wydrukuj postęp\n",
    "        print(\n",
    "            f\"Postęp: {i + 1}/{num_of_val_samples} indeksów wygenerowanych. ({(i + 1) / num_of_val_samples * 100:.2f}%)\")\n",
    "\n",
    "    return chosen_indices\n",
    "\n",
    "\n",
    "# Przykładowe wywołanie funkcji\n",
    "data_length = 10000\n",
    "num_of_val_samples = 10\n",
    "sequence_length = 200\n",
    "\n",
    "try:\n",
    "    val_indices = generate_validation_indices(data_length, num_of_val_samples, sequence_length)\n",
    "    print(\"Wygenerowane indeksy walidacyjne:\", val_indices)\n",
    "    print(\"len(val_indices):\", len(val_indices))\n",
    "except ValueError as e:\n",
    "    print(e)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def generate_validation_indices(data_length, num_of_val_samples, sequence_length):\n",
    "    # Ustal minimalną odległość pomiędzy indeksami\n",
    "    min_distance_forward = sequence_length + 1\n",
    "    min_distance_backward = 2 * sequence_length + 1\n",
    "    print(\"min_distance_forward:\", min_distance_forward)\n",
    "    print(\"min_distance_backward:\", min_distance_backward)\n",
    "    # Utwórz listę możliwych indeksów\n",
    "    available_indices = list(range(data_length))\n",
    "\n",
    "    chosen_indices = []\n",
    "    for i in range(num_of_val_samples):\n",
    "        if not available_indices:\n",
    "            raise ValueError(\"Nie można wygenerować więcej próbek z uwzględnieniem minimalnego dystansu\")\n",
    "        array = np.array(available_indices)\n",
    "        # Losuj indeks z dostępnych indeksów\n",
    "        chosen_index = np.random.choice(available_indices)\n",
    "        chosen_indices.append(chosen_index)\n",
    "\n",
    "        # Oblicz zakres indeksów do usunięcia\n",
    "        start = max(0, chosen_index - min_distance_backward)\n",
    "        end = min(data_length, chosen_index + min_distance_forward)\n",
    "\n",
    "        # Usuń indeksy zbyt blisko wybranego indeksu\n",
    "        available_indices = [idx for idx in available_indices if idx < start or idx > end]\n",
    "        print(\"len(available_indices):\", len(available_indices))\n",
    "        # Wydrukuj postęp\n",
    "        print(\n",
    "            f\"Postęp: {i + 1}/{num_of_val_samples} indeksów wygenerowanych. ({(i + 1) / num_of_val_samples * 100:.2f}%)\")\n",
    "\n",
    "    return chosen_indices\n",
    "\n",
    "\n",
    "# Przykładowe wywołanie funkcji\n",
    "data_length = 100\n",
    "num_of_val_samples = 100\n",
    "sequence_length = 200\n",
    "\n",
    "try:\n",
    "    val_indices = generate_validation_indices(data_length, num_of_val_samples, sequence_length)\n",
    "    print(\"Wygenerowane indeksy walidacyjne:\", val_indices)\n",
    "    print(\"len(val_indices):\", len(val_indices))\n",
    "except ValueError as e:\n",
    "    print(e)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def generate_validation_indices(data_length, num_of_val_samples, sequence_length):\n",
    "    min_distance = sequence_length + 1  # Minimalna odległość pomiędzy indeksami\n",
    "    available_indices = set(range(data_length))  # Tworzymy zbiór dostępnych indeksów\n",
    "\n",
    "    chosen_indices = []\n",
    "    for _ in range(num_of_val_samples):\n",
    "        if len(available_indices) == 0:\n",
    "            raise ValueError(\"Nie można wygenerować więcej próbek z uwzględnieniem minimalnego dystansu\")\n",
    "\n",
    "        chosen_index = np.random.choice(list(available_indices))  # Losujemy z dostępnych indeksów\n",
    "        chosen_indices.append(chosen_index)\n",
    "\n",
    "        # Usuwamy indeksy w zakresie `sequence_length` w obie strony od wybranego indeksu\n",
    "        indices_to_remove = set(range(max(0, chosen_index - (2 * sequence_length) - 3),\n",
    "                                      min(data_length, chosen_index + (2 * sequence_length) + 3)))\n",
    "        available_indices.difference_update(indices_to_remove)  # Aktualizujemy zbiór dostępnych indeksów\n",
    "\n",
    "    return chosen_indices\n",
    "\n",
    "\n",
    "# Przykładowe wywołanie funkcji\n",
    "data_length = 1000\n",
    "num_of_val_samples = 10\n",
    "sequence_length = 50\n",
    "\n",
    "try:\n",
    "    val_indices = generate_validation_indices(data_length, num_of_val_samples, sequence_length)\n",
    "    print(\"Wygenerowane indeksy walidacyjne:\", val_indices)\n",
    "except ValueError as e:\n",
    "    print(e)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def generate_mask(data_length, chosen_indices, sequence_length):\n",
    "    # Ustal minimalną odległość pomiędzy indeksami\n",
    "    min_distance = sequence_length + 1\n",
    "    # Utwórz maskę początkową ze wszystkimi wartościami ustawionymi na True\n",
    "    mask = np.ones(data_length, dtype=bool)\n",
    "\n",
    "    # Iteruj przez każdy wybrany indeks walidacyjny\n",
    "    for index in chosen_indices:\n",
    "        # Ustal zakres indeksów, które należy ustawić na False\n",
    "        start = max(0, index - min_distance)\n",
    "        end = min(data_length, index + min_distance)\n",
    "\n",
    "        # Ustaw odpowiednie wartości w masce na False\n",
    "        mask[start:end] = False\n",
    "\n",
    "    # Zwróć indeksy, gdzie maska jest True, czyli indeksy zbioru treningowego\n",
    "    training_indices = np.where(mask)[0]  # np.where(mask) zwraca tuple, [0] wyciąga array z indeksami\n",
    "    return training_indices\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def plot_val_indices(data_length, val_indices, sequence_length):\n",
    "    # Ustal minimalną odległość pomiędzy indeksami\n",
    "    min_distance = sequence_length + 1\n",
    "\n",
    "    # Inicjalizacja figury\n",
    "    plt.figure(figsize=(10, 2))\n",
    "    plt.title(\"Rozkład indeksów walidacyjnych i ich zakresy\")\n",
    "    plt.xlabel(\"Indeksy danych\")\n",
    "    plt.ylabel(\"Wartość (dla wizualizacji)\")\n",
    "\n",
    "    # Rysowanie linii dla całej długości danych\n",
    "    plt.plot([0, data_length - 1], [1, 1], label='Dane', color='blue')\n",
    "\n",
    "    # Rysowanie punktów dla walidacyjnych indeksów\n",
    "    for index in val_indices:\n",
    "        plt.scatter([index], [1], color='red')  # punkt walidacyjny\n",
    "        start = max(0, index - min_distance)\n",
    "        end = min(data_length, index + min_distance)\n",
    "        plt.axvspan(start, end, color='red', alpha=0.3)  # zakres wokół punktu)\n",
    "\n",
    "    plt.legend(['Dane', 'Indeksy walidacyjne i zakres'])\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Przykładowe wywołanie funkcji\n",
    "data_length = 200\n",
    "num_of_val_samples = 10\n",
    "sequence_length = 4\n",
    "\n",
    "try:\n",
    "    val_indices = generate_validation_indices(data_length, num_of_val_samples, sequence_length)\n",
    "    plot_val_indices(data_length, val_indices, sequence_length)\n",
    "except ValueError as e:\n",
    "    print(e)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def plot_train_val_indices(data_length, train_indices, val_indices, sequence_length):\n",
    "    # Ustal minimalną odległość pomiędzy indeksami\n",
    "    min_distance = sequence_length + 1\n",
    "\n",
    "    # Inicjalizacja figury\n",
    "    plt.figure(figsize=(10, 2))\n",
    "    plt.title(\"Rozkład indeksów walidacyjnych i ich zakresy\")\n",
    "    plt.xlabel(\"Indeksy danych\")\n",
    "    plt.ylabel(\"Wartość (dla wizualizacji)\")\n",
    "\n",
    "    # Rysowanie linii dla całej długości danych\n",
    "    plt.plot([0, data_length - 1], [1, 1], label='Dane', color='blue')\n",
    "\n",
    "    # Rysowanie punktów dla walidacyjnych indeksów\n",
    "    for index in val_indices:\n",
    "        plt.scatter([index], [1], color='red')  # punkt walidacyjny\n",
    "        start = max(0, index - min_distance)\n",
    "        end = min(data_length, index + min_distance)\n",
    "        plt.axvspan(start, end, color='red', alpha=0.3)  # zakres wokół punktu)\n",
    "    # if train_indices is not empty:\n",
    "    for index in train_indices:\n",
    "        plt.scatter([index], [1], color='red')  # punkt walidacyjny\n",
    "        start = index\n",
    "        end = min(data_length, index + min_distance)\n",
    "        plt.axvspan(start, end, color='blue', alpha=0.1)  # zakres wokół punktu)\n",
    "\n",
    "    plt.legend(['Dane', 'Indeksy walidacyjne i zakres'])\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Przykładowe wywołanie funkcji\n",
    "data_length = 200\n",
    "num_of_val_samples = 10\n",
    "sequence_length = 5\n",
    "\n",
    "try:\n",
    "    val_indices = generate_validation_indices(data_length, num_of_val_samples, sequence_length)\n",
    "    train_indices = generate_mask(data_length, val_indices, sequence_length)\n",
    "    plot_val_indices(data_length, val_indices, sequence_length)\n",
    "    plot_train_val_indices(data_length, train_indices, val_indices, sequence_length)\n",
    "except ValueError as e:\n",
    "    print(e)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def generate_mask(data_length, chosen_indices, sequence_length):\n",
    "    # Ustal minimalną odległość pomiędzy indeksami\n",
    "    min_distance = sequence_length + 1\n",
    "    # Utwórz maskę początkową ze wszystkimi wartościami ustawionymi na True\n",
    "    mask = np.ones(data_length, dtype=bool)\n",
    "\n",
    "    # Iteruj przez każdy wybrany indeks walidacyjny\n",
    "    for index in chosen_indices:\n",
    "        # Ustal zakres indeksów, które należy ustawić na False\n",
    "        start = max(0, index - min_distance)\n",
    "        end = min(data_length, index + min_distance)\n",
    "\n",
    "        # Ustaw odpowiednie wartości w masce na False\n",
    "        mask[start:end] = False\n",
    "\n",
    "    # Zwróć indeksy, gdzie maska jest True, czyli indeksy zbioru treningowego\n",
    "    training_indices = np.where(mask)[0]  # np.where(mask) zwraca tuple, [0] wyciąga array z indeksami\n",
    "    return training_indices\n",
    "\n",
    "\n",
    "# Przykładowe wywołanie funkcji\n",
    "data_length = 200\n",
    "num_of_val_samples = 10\n",
    "sequence_length = 4\n",
    "\n",
    "try:\n",
    "    val_indices = generate_validation_indices(data_length, num_of_val_samples, sequence_length)\n",
    "    training_indices = generate_mask(data_length, val_indices, sequence_length)\n",
    "    plot_validation_indices(data_length, training_indices, val_indices, sequence_length)\n",
    "    print(\"Wygenerowane indeksy walidacyjne:\", val_indices)\n",
    "    print(\"Indeksy zbioru treningowego:\", training_indices)\n",
    "except ValueError as e:\n",
    "    print(e)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "randomlist = [1, 2, 9, 10]\n",
    "index = np.random.choice(randomlist)\n",
    "index"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Przykładowe wywołanie funkcji\n",
    "data_length = 1000\n",
    "num_of_val_samples = 10\n",
    "sequence_length = 30\n",
    "\n",
    "try:\n",
    "    val_indices = generate_validation_indices(data_length, num_of_val_samples, sequence_length)\n",
    "    training_indices = generate_mask(data_length, val_indices, sequence_length)\n",
    "    print(\"len(training_indices):\", len(training_indices))\n",
    "except ValueError as e:\n",
    "    print(e)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "!pip install sidekit\n"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
