{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T09:24:44.470411Z",
     "start_time": "2024-05-24T09:24:43.978692Z"
    }
   },
   "cell_type": "code",
   "source": "!nvidia-smi",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri May 24 11:24:44 2024       \r\n",
      "+-----------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 550.67                 Driver Version: 550.67         CUDA Version: 12.4     |\r\n",
      "|-----------------------------------------+------------------------+----------------------+\r\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                        |               MIG M. |\r\n",
      "|=========================================+========================+======================|\r\n",
      "|   0  NVIDIA GeForce RTX 3050 ...    Off |   00000000:01:00.0 Off |                  N/A |\r\n",
      "| N/A   48C    P8              3W /   35W |       9MiB /   4096MiB |      0%      Default |\r\n",
      "|                                         |                        |                  N/A |\r\n",
      "+-----------------------------------------+------------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+-----------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                              |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\r\n",
      "|        ID   ID                                                               Usage      |\r\n",
      "|=========================================================================================|\r\n",
      "|    0   N/A  N/A      2222      G   /usr/lib/xorg/Xorg                              4MiB |\r\n",
      "+-----------------------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T09:24:57.821729Z",
     "start_time": "2024-05-24T09:24:44.476238Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import mne\n",
    "import pywt\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from torch import nn\n",
    "import torch\n",
    "import pickle\n",
    "import os\n",
    "from datetime import datetime\n",
    "import sqlite3\n",
    "from pytorch_lightning import LightningModule, Trainer\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchmetrics.functional.classification.accuracy import accuracy"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-24 11:24:52.894046: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-24 11:24:53.664291: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-24 11:24:56.317748: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T09:24:57.855115Z",
     "start_time": "2024-05-24T09:24:57.825149Z"
    }
   },
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Training on device: {device}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on device: cuda\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T09:24:57.877800Z",
     "start_time": "2024-05-24T09:24:57.860076Z"
    }
   },
   "source": [
    "class CWTDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset for EEG data after CWT transformation stored in SQLite database.\n",
    "    \n",
    "    Attributes:\n",
    "        db_path: str - path to SQLite database\n",
    "        sequence_length: int - length of the sequence\n",
    "    Methods:\n",
    "        __len__ - returns the number of samples in the dataset minus the sequence length\n",
    "        __getitem__ - returns a sample from the dataset\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, db_path, sequence_length=4000):\n",
    "        \"\"\"\n",
    "        Constructor for CWTDataset class that initializes the dataset.\n",
    "        Args:\n",
    "            db_path: str - path to SQLite database\n",
    "            sequence_length: int - length of the sequence\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        self.db_path = db_path\n",
    "        self.sequence_length = sequence_length\n",
    "        self.conn = sqlite3.connect(db_path)\n",
    "        self.cursor = self.conn.cursor()\n",
    "        self.cursor.execute(\"SELECT COUNT(*) FROM wavelet_transforms\")\n",
    "        self.total_samples = self.cursor.fetchone()[0]\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the number of samples in the dataset.\n",
    "        Args:\n",
    "            None\n",
    "        Returns:\n",
    "            int - number of samples in the dataset minus the sequence length\n",
    "        \"\"\"\n",
    "        return self.total_samples - self.sequence_length + 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        function that returns as many samples as the sequence length\n",
    "        Args:\n",
    "            idx: int - index of the sample\n",
    "        Returns:\n",
    "            tuple - (cwt_tensor, target_tensor)\n",
    "        \n",
    "        \"\"\"\n",
    "        query = (\n",
    "            \"SELECT cwt_data, target FROM wavelet_transforms WHERE id BETWEEN ? AND ?\"\n",
    "        )\n",
    "\n",
    "        self.cursor.execute(query, (idx + 1, idx + self.sequence_length))\n",
    "        rows = self.cursor.fetchall()\n",
    "\n",
    "        cwt_sequence = np.stack([pickle.loads(row[0]) for row in rows])\n",
    "\n",
    "        target = rows[-1][1]\n",
    "\n",
    "        cwt_tensor = torch.tensor(cwt_sequence, dtype=torch.float32)\n",
    "\n",
    "        target_tensor = torch.tensor(target, dtype=torch.int64)\n",
    "        return cwt_tensor, target_tensor\n",
    "\n",
    "    def __del__(self):\n",
    "        self.conn.close()"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T09:24:57.911604Z",
     "start_time": "2024-05-24T09:24:57.882983Z"
    }
   },
   "source": [
    "class CWTSubset(Dataset):\n",
    "    def __init__(self, dataset, indices):\n",
    "        self.dataset = dataset\n",
    "        self.indices = indices\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.dataset.__getitem__(int(self.indices[idx]))\n",
    "        return row\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T09:24:57.948398Z",
     "start_time": "2024-05-24T09:24:57.915510Z"
    }
   },
   "source": [
    "class CWT_EEG(LightningModule):\n",
    "    def __init__(\n",
    "            self,\n",
    "            batch_size,\n",
    "            sequence_length,\n",
    "            input_size,\n",
    "            hidden_size,\n",
    "            num_layers,\n",
    "            lr,\n",
    "            label_smoothing=0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.hparams.batch_size = batch_size\n",
    "        self.hparams.input_size = input_size\n",
    "        self.hparams.sequence_length = sequence_length\n",
    "        self.hparams.lr = lr\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.num_of_classes = 3\n",
    "        self.val_percent = 0.01\n",
    "        self.loss = torch.nn.CrossEntropyLoss(label_smoothing=label_smoothing)\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, self.num_of_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "\n",
    "        out, (hn, cn) = self.lstm(x, (h0, c0))\n",
    "        out = hn[-1, :, :]\n",
    "        out = self.fc(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "    # custom\n",
    "    def count_parameters(model):\n",
    "        return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "    # only for HP\n",
    "    def on_train_start(self):\n",
    "        self.logger.log_hyperparams(\n",
    "            self.hparams,\n",
    "            {\n",
    "                \"hp/train_loss\": float(\"nan\"),\n",
    "                \"hp/train_acc\": float(\"nan\"),\n",
    "                \"hp/val_loss\": float(\"nan\"),\n",
    "                \"hp/val_acc\": float(\"nan\"),\n",
    "            },\n",
    "        )\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.loss(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = accuracy(preds, y, task=\"multiclass\", num_classes=self.num_of_classes)\n",
    "\n",
    "        self.log(\"hp/train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"hp/train_acc\", acc, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.hparams.lr)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.loss(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = accuracy(preds, y, task=\"multiclass\", num_classes=self.num_of_classes)\n",
    "\n",
    "        self.log(\"hp/val_loss\", loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"hp/val_acc\", acc, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def generate_validation_indices(\n",
    "            self, data_length, num_of_val_samples, sequence_length\n",
    "    ):\n",
    "        available_indices = set(range(data_length))\n",
    "        val_indices = []\n",
    "        for _ in range(num_of_val_samples):\n",
    "            if len(available_indices) == 0:\n",
    "                raise ValueError(\n",
    "                    \"Nie można wygenerować więcej próbek z uwzględnieniem minimalnego dystansu\"\n",
    "                )\n",
    "            chosen_index = int(np.random.choice(list(available_indices)))\n",
    "            val_indices.append(chosen_index)\n",
    "            indices_to_remove = set(\n",
    "                range(\n",
    "                    max(0, chosen_index - (2 * sequence_length) - 3),\n",
    "                    min(data_length, chosen_index + (2 * sequence_length) + 3),\n",
    "                )\n",
    "            )\n",
    "            available_indices.difference_update(indices_to_remove)\n",
    "\n",
    "        return val_indices\n",
    "\n",
    "    def generate_train_indices(self, data_length, val_i, sequence_length):\n",
    "        min_distance = sequence_length + 1\n",
    "        mask = np.ones(data_length, dtype=bool)\n",
    "        for index in val_i:\n",
    "            start = max(0, index - min_distance)\n",
    "            end = min(data_length, index + min_distance + 1)\n",
    "\n",
    "            mask[start:end] = False\n",
    "\n",
    "        training_indices = list(np.where(mask)[0])\n",
    "        return training_indices\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.ds = CWTDataset(\"df_train_cwt_data.db\", self.hparams.sequence_length)\n",
    "        self.num_val_samples = int(\n",
    "            len(self.ds) / (4 * self.hparams.sequence_length + 6)\n",
    "        )\n",
    "\n",
    "        val_indices = self.generate_validation_indices(\n",
    "            len(self.ds), self.num_val_samples, self.hparams.sequence_length\n",
    "        )\n",
    "        train_indices = self.generate_train_indices(\n",
    "            len(self.ds), val_indices, self.hparams.sequence_length\n",
    "        )\n",
    "        print(\n",
    "            \"percent of val samples\",\n",
    "            len(val_indices) / (len(val_indices) + len(train_indices)),\n",
    "        )\n",
    "        self.train_set = CWTSubset(self.ds, train_indices)\n",
    "        self.val_set = CWTSubset(self.ds, val_indices)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.train_set,\n",
    "            batch_size=self.hparams.batch_size,\n",
    "            num_workers=7,\n",
    "            shuffle=True,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.val_set, batch_size=self.hparams.batch_size, num_workers=7\n",
    "        )\n",
    "\n",
    "    def get_len_train_val(self):\n",
    "        self.setup()\n",
    "        return len(self.train_set), len(self.val_set)"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T09:24:57.967586Z",
     "start_time": "2024-05-24T09:24:57.951675Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class CWT_EEG_CrossPersonValidation(CWT_EEG):\n",
    "    def __init__(self, batch_size, sequence_length, input_size, hidden_size, num_layers, lr, label_smoothing=0):\n",
    "        super().__init__(batch_size, sequence_length, input_size, hidden_size, num_layers, lr, label_smoothing)\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        se  #\n",
    "        lf.train_set = CWTDataset(\"./df_train_cwt_data.db\", self.hparams.sequence_length)\n",
    "        self.val_set = CWTDataset(\"./df_val_cwt_data.db\", self.hparams.sequence_length)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(self.train_set, batch_size=self.hparams.batch_size, num_workers=14,\n",
    "                                           shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(self.val_set, batch_size=self.hparams.batch_size, num_workers=14)\n"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T09:25:19.142359Z",
     "start_time": "2024-05-24T09:24:57.969814Z"
    }
   },
   "source": [
    "\n",
    "lr = 0.001\n",
    "\n",
    "model = CWT_EEG(batch_size=11, sequence_length=10, input_size=640, num_layers=3, hidden_size=3,\n",
    "                lr=lr).to(device)\n",
    "logger = TensorBoardLogger(\"logs\", name=\"CWT_EEG\", default_hp_metric=False)\n",
    "logger.log_hyperparams(model.hparams, {})\n",
    "trainer = Trainer(\n",
    "    max_epochs=2,\n",
    "    logger=logger\n",
    "\n",
    ")\n",
    "print(model.get_len_train_val())\n",
    "trainer.fit(model)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percent of val samples 0.041636477805149015\n",
      "(59523, 2586)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3050 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "/home/daniel/miniconda3/envs/EEG311/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T09:25:19.462853Z",
     "start_time": "2024-05-24T09:25:19.145567Z"
    }
   },
   "source": [
    "import datetime\n",
    "from pytorch_lightning import Trainer, loggers\n",
    "\n",
    "current_time = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "logger = loggers.TensorBoardLogger(\"logs\", name=f\"CWT_EEG_{current_time}\", default_hp_metric=False)\n",
    "lr = 0.001\n",
    "model = CWT_EEG_CrossPersonValidation(batch_size=11, sequence_length=10, input_size=640, num_layers=3, hidden_size=100,\n",
    "                                      lr=lr).to(device)\n",
    "logger.log_hyperparams(model.hparams)\n",
    "trainer = Trainer(\n",
    "    max_epochs=2,\n",
    "    logger=logger\n",
    ")\n",
    "trainer.fit(model)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: logs/CWT_EEG_2024-05-24_11-25-19\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'se' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[9], line 14\u001B[0m\n\u001B[1;32m      9\u001B[0m logger\u001B[38;5;241m.\u001B[39mlog_hyperparams(model\u001B[38;5;241m.\u001B[39mhparams)\n\u001B[1;32m     10\u001B[0m trainer \u001B[38;5;241m=\u001B[39m Trainer(\n\u001B[1;32m     11\u001B[0m     max_epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m,\n\u001B[1;32m     12\u001B[0m     logger\u001B[38;5;241m=\u001B[39mlogger\n\u001B[1;32m     13\u001B[0m )\n\u001B[0;32m---> 14\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/EEG311/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:544\u001B[0m, in \u001B[0;36mTrainer.fit\u001B[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001B[0m\n\u001B[1;32m    542\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mstatus \u001B[38;5;241m=\u001B[39m TrainerStatus\u001B[38;5;241m.\u001B[39mRUNNING\n\u001B[1;32m    543\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m--> 544\u001B[0m \u001B[43mcall\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_and_handle_interrupt\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    545\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit_impl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_dataloaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_dataloaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdatamodule\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mckpt_path\u001B[49m\n\u001B[1;32m    546\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/EEG311/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:44\u001B[0m, in \u001B[0;36m_call_and_handle_interrupt\u001B[0;34m(trainer, trainer_fn, *args, **kwargs)\u001B[0m\n\u001B[1;32m     42\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mlauncher \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     43\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mlauncher\u001B[38;5;241m.\u001B[39mlaunch(trainer_fn, \u001B[38;5;241m*\u001B[39margs, trainer\u001B[38;5;241m=\u001B[39mtrainer, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m---> 44\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtrainer_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     46\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m _TunerExitException:\n\u001B[1;32m     47\u001B[0m     _call_teardown_hook(trainer)\n",
      "File \u001B[0;32m~/miniconda3/envs/EEG311/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:580\u001B[0m, in \u001B[0;36mTrainer._fit_impl\u001B[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001B[0m\n\u001B[1;32m    573\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mfn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    574\u001B[0m ckpt_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_checkpoint_connector\u001B[38;5;241m.\u001B[39m_select_ckpt_path(\n\u001B[1;32m    575\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mfn,\n\u001B[1;32m    576\u001B[0m     ckpt_path,\n\u001B[1;32m    577\u001B[0m     model_provided\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m    578\u001B[0m     model_connected\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlightning_module \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    579\u001B[0m )\n\u001B[0;32m--> 580\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mckpt_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mckpt_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    582\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mstopped\n\u001B[1;32m    583\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/EEG311/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:949\u001B[0m, in \u001B[0;36mTrainer._run\u001B[0;34m(self, model, ckpt_path)\u001B[0m\n\u001B[1;32m    946\u001B[0m log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: preparing data\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    947\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_data_connector\u001B[38;5;241m.\u001B[39mprepare_data()\n\u001B[0;32m--> 949\u001B[0m \u001B[43mcall\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_setup_hook\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# allow user to set up LightningModule in accelerator environment\u001B[39;00m\n\u001B[1;32m    950\u001B[0m log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: configuring model\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    951\u001B[0m call\u001B[38;5;241m.\u001B[39m_call_configure_model(\u001B[38;5;28mself\u001B[39m)\n",
      "File \u001B[0;32m~/miniconda3/envs/EEG311/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:94\u001B[0m, in \u001B[0;36m_call_setup_hook\u001B[0;34m(trainer)\u001B[0m\n\u001B[1;32m     92\u001B[0m     _call_lightning_datamodule_hook(trainer, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msetup\u001B[39m\u001B[38;5;124m\"\u001B[39m, stage\u001B[38;5;241m=\u001B[39mfn)\n\u001B[1;32m     93\u001B[0m _call_callback_hooks(trainer, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msetup\u001B[39m\u001B[38;5;124m\"\u001B[39m, stage\u001B[38;5;241m=\u001B[39mfn)\n\u001B[0;32m---> 94\u001B[0m \u001B[43m_call_lightning_module_hook\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrainer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43msetup\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstage\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     96\u001B[0m trainer\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mbarrier(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpost_setup\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/miniconda3/envs/EEG311/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:157\u001B[0m, in \u001B[0;36m_call_lightning_module_hook\u001B[0;34m(trainer, hook_name, pl_module, *args, **kwargs)\u001B[0m\n\u001B[1;32m    154\u001B[0m pl_module\u001B[38;5;241m.\u001B[39m_current_fx_name \u001B[38;5;241m=\u001B[39m hook_name\n\u001B[1;32m    156\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mprofile(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m[LightningModule]\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpl_module\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mhook_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m--> 157\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    159\u001B[0m \u001B[38;5;66;03m# restore current_fx when nested context\u001B[39;00m\n\u001B[1;32m    160\u001B[0m pl_module\u001B[38;5;241m.\u001B[39m_current_fx_name \u001B[38;5;241m=\u001B[39m prev_fx_name\n",
      "Cell \u001B[0;32mIn[7], line 6\u001B[0m, in \u001B[0;36mCWT_EEG_CrossPersonValidation.setup\u001B[0;34m(self, stage)\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msetup\u001B[39m(\u001B[38;5;28mself\u001B[39m, stage\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m----> 6\u001B[0m     \u001B[43mse\u001B[49m\u001B[38;5;66;03m#\u001B[39;00m\n\u001B[1;32m      7\u001B[0m     lf\u001B[38;5;241m.\u001B[39mtrain_set \u001B[38;5;241m=\u001B[39m CWTDataset(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m./df_train_cwt_data.db\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhparams\u001B[38;5;241m.\u001B[39msequence_length)\n\u001B[1;32m      8\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mval_set \u001B[38;5;241m=\u001B[39m CWTDataset(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m./df_val_cwt_data.db\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhparams\u001B[38;5;241m.\u001B[39msequence_length)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'se' is not defined"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "model.hparams"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!ls\n",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from ray import tune\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "\n",
    "def train_model(config):\n",
    "    model = CWT_EEG_CrossPersonValidation(\n",
    "        batch_size=config[\"batch_size\"],  # hiperparametr rozmiaru batcha\n",
    "        sequence_length=config[\"sequence_length\"],  # hiperparametr długości sekwencji\n",
    "        input_size=640,  # hiperparametr rozmiaru wejścia\n",
    "        hidden_size=config[\"hidden_size\"],  # hiperparametr rozmiaru stanu ukrytego\n",
    "        num_layers=config[\"num_layers\"],  # hiperparametr liczby warstw\n",
    "        lr=config[\"lr\"],  # hiperparametr prędkości uczenia\n",
    "        label_smoothing=0  # hiperparametr wygładzania etykiet\n",
    "    )\n",
    "\n",
    "    # Callbacks\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        monitor='hp/val_loss',\n",
    "        dirpath='model_checkpoints',\n",
    "        filename='model-{epoch:02d}-{hp/val_loss:.2f}',\n",
    "        save_top_k=3,\n",
    "        mode='min'\n",
    "    )\n",
    "    early_stop_callback = EarlyStopping(\n",
    "        monitor='hp/val_loss',\n",
    "        min_delta=0.00,\n",
    "        patience=3,\n",
    "        verbose=False,\n",
    "        mode='min'\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        max_epochs=10,\n",
    "        callbacks=[checkpoint_callback, early_stop_callback],\n",
    "    )\n",
    "\n",
    "    trainer.fit(model)\n",
    "\n",
    "\n",
    "search_space = {\n",
    "    \"batch_size\": tune.choice([8, 16, 32, 64]),\n",
    "    \"sequence_length\": tune.choice([10, 100, 200]),\n",
    "    \"hidden_size\": tune.choice([256, 512, 1024]),\n",
    "    \"num_layers\": tune.choice([1, 2, 3]),\n",
    "    \"lr\": tune.loguniform(1e-4, 1e-1),\n",
    "}\n",
    "\n",
    "analysis = tune.run(\n",
    "    train_model,\n",
    "    config=search_space,\n",
    "    num_samples=10,\n",
    "    resources_per_trial={\"cpu\": 1, \"gpu\": 1}\n",
    ")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import os\n",
    "from ray import tune\n",
    "from ray.tune.integration.pytorch_lightning import TuneReportCallback\n",
    "from pytorch_lightning import Trainer, LightningModule\n",
    "import torch\n",
    "\n",
    "\n",
    "def train_cwt_eeg(config):\n",
    "    model = CWT_EEG_CrossPersonValidation(config)\n",
    "    trainer = Trainer(\n",
    "        max_epochs=10,\n",
    "        progress_bar_refresh_rate=0,  # Disable progress bar for clearer logs\n",
    "        callbacks=[TuneReportCallback({\"loss\": \"ptl/val_loss\"}, on=\"validation_end\")],\n",
    "    )\n",
    "    trainer.fit(model)\n",
    "\n",
    "\n",
    "search_space = {\n",
    "    \"batch_size\": tune.choice([8, 16, 32, 64]),\n",
    "    \"sequence_length\": tune.choice([10, 100, 200]),\n",
    "    \"input_size\": 640,  # This is fixed for our dataset\n",
    "    \"hidden_size\": tune.choice([256, 512, 1024]),\n",
    "    \"num_layers\": tune.choice([1, 2, 3]),\n",
    "    \"lr\": tune.loguniform(1e-5, 1e-1),\n",
    "    \"label_smoothing\": 0,\n",
    "}\n",
    "# Uruchomienie procesu optymalizacji\n",
    "analysis = tune.run(\n",
    "    train_cwt_eeg,\n",
    "    config=search_space,\n",
    "    num_samples=10,\n",
    "    resources_per_trial={\"cpu\": 1, \"gpu\": 1},  # Adjust based on your system's resources\n",
    ")\n",
    "\n",
    "print(\"Best hyperparameters found were: \", analysis.best_config)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T09:28:06.766714Z",
     "start_time": "2024-05-24T09:28:06.759374Z"
    }
   },
   "source": [
    "# Utworzenie folderu dla logów\n",
    "writer = SummaryWriter('./lightning_logs/CWT_EEG')"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T09:28:16.850064Z",
     "start_time": "2024-05-24T09:28:16.776215Z"
    }
   },
   "source": [
    "dummy_input = torch.randn(11, 10, 20)  # Przykładowe dane wejściowe (batch_size, input_size)\n",
    "writer.add_graph(model, dummy_input)\n",
    "writer.close()"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T09:27:19.009416Z",
     "start_time": "2024-05-24T09:27:18.775339Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class SimpleLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(SimpleLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # Warstwa LSTM\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size)\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        # Inicjalizacja stanu ukrytego i stanu komórki\n",
    "        # (num_layers * num_directions, batch, hidden_size)\n",
    "        h0 = torch.zeros(1, input_seq.size(1), self.hidden_size)\n",
    "        c0 = torch.zeros(1, input_seq.size(1), self.hidden_size)\n",
    "\n",
    "        # Przejście przez LSTM\n",
    "        lstm_out, _ = self.lstm(input_seq, (h0, c0))\n",
    "\n",
    "        return lstm_out\n",
    "\n",
    "\n",
    "# Parametry modelu\n",
    "input_size = 20  # Wymiary wejściowe (np. cechy)\n",
    "hidden_size = 10  # Wymiary stanu ukrytego LSTM\n",
    "\n",
    "# Tworzenie instancji modelu\n",
    "model = SimpleLSTM(input_size, hidden_size)\n",
    "\n",
    "dummy_input = torch.randn(1, 10, 20)  # Przykładowe dane wejściowe (batch_size, input_size)\n",
    "writer.add_graph(model, dummy_input)\n",
    "writer.close()\n",
    "# Wyświetlenie struktury modelu\n",
    "print(sum(p.numel() for p in model.parameters() if p.requires_grad))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def create_train_val_split(data_length, val_percent, sequence_length):\n",
    "    available_lenght = data_length - sequence_length\n",
    "    val_count = int(val_percent * available_lenght)\n",
    "    all_indices = np.arange(available_lenght)\n",
    "    val_indices = np.sort(np.random.choice(all_indices, size=val_count, replace=False))\n",
    "    mask = np.ones(available_lenght, dtype=bool)\n",
    "    for idx in val_indices:\n",
    "        start = max(0, idx - sequence_length + 1)\n",
    "        end = min(available_lenght, idx + sequence_length)\n",
    "        mask[start:end] = False\n",
    "    train_indices = np.where(mask)[0]\n",
    "    # convert evry number to int\n",
    "    train_indices = list(train_indices)\n",
    "    val_indices = list(val_indices)\n",
    "\n",
    "    return train_indices, val_indices"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from tensorboard.backend.event_processing import event_accumulator\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def load_tensorboard_scalars(logdir):\n",
    "    # Tworzy akumulator do odczytu danych\n",
    "    ea = event_accumulator.EventAccumulator(logdir,\n",
    "                                            size_guidance={event_accumulator.SCALARS: 0})  # 0 = bez ograniczeń\n",
    "    ea.Reload()  # Wczytaj wszystkie dane z dysku\n",
    "\n",
    "    # Odczyt danych skalarnych\n",
    "    scalars = {}\n",
    "    for tag in ea.Tags()['scalars']:\n",
    "        events = ea.Scalars(tag)\n",
    "        scalars[tag] = [(e.wall_time, e.step, e.value) for e in events]\n",
    "\n",
    "    return scalars\n",
    "\n",
    "\n",
    "# Ścieżka do katalogu z logami TensorBoard\n",
    "logdir = '/home/daniel/repos/Decoding_of_EEG/lightning_logs/CWT_EEG/version_51/events.out.tfevents.1713204451.pop-os.32833.5'\n",
    "\n",
    "# Wczytanie danych\n",
    "scalars = load_tensorboard_scalars(logdir)\n",
    "\n",
    "# Przykład wyświetlenia danych skalarnych\n",
    "tag = 'hp/train_acc_step'  # Zmień na odpowiedni tag, który chcesz wyświetlić\n",
    "times, steps, values = zip(*scalars[tag])\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(steps, values, label=tag)\n",
    "plt.xlabel('Krok')\n",
    "plt.ylabel('Wartość')\n",
    "plt.title('Wykres danych z TensorBoard')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "tag = 'hp/val_acc_step'  # Zmień na odpowiedni tag, który chcesz wyświetlić\n",
    "times, steps, values = zip(*scalars[tag])\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(steps, values, label=tag)\n",
    "plt.xlabel('Krok')\n",
    "plt.ylabel('Wartość')\n",
    "plt.title('Wykres danych z TensorBoard')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def generate_validation_indices(data_length, num_of_val_samples, sequence_length):\n",
    "    # Ustal minimalną odległość pomiędzy indeksami\n",
    "    min_distance = sequence_length + 1\n",
    "    # Utwórz set możliwych indeksów\n",
    "    available_indices = set(range(data_length))\n",
    "\n",
    "    chosen_indices = []\n",
    "    for i in range(num_of_val_samples):\n",
    "        if not available_indices:\n",
    "            raise ValueError(\"Nie można wygenerować więcej próbek z uwzględnieniem minimalnego dystansu\")\n",
    "\n",
    "        # Losuj indeks z dostępnych indeksów\n",
    "        chosen_index = np.random.choice(list(available_indices))\n",
    "        chosen_indices.append(chosen_index)\n",
    "\n",
    "        # Oblicz zakres indeksów do usunięcia\n",
    "        start = max(0, chosen_index - (2 * min_distance))\n",
    "        end = min(data_length, chosen_index + min_distance)\n",
    "\n",
    "        # Usuń indeksy zbyt blisko wybranego indeksu z zbioru available_indices\n",
    "        for idx in range(start, end + 1):\n",
    "            available_indices.discard(idx)  # discard nie zgłasza błędu, jeśli element nie istnieje\n",
    "\n",
    "        # Wydrukuj postęp\n",
    "        print(\n",
    "            f\"Postęp: {i + 1}/{num_of_val_samples} indeksów wygenerowanych. ({(i + 1) / num_of_val_samples * 100:.2f}%)\")\n",
    "\n",
    "    return chosen_indices\n",
    "\n",
    "\n",
    "# Przykładowe wywołanie funkcji\n",
    "data_length = 10000\n",
    "num_of_val_samples = 10\n",
    "sequence_length = 200\n",
    "\n",
    "try:\n",
    "    val_indices = generate_validation_indices(data_length, num_of_val_samples, sequence_length)\n",
    "    print(\"Wygenerowane indeksy walidacyjne:\", val_indices)\n",
    "    print(\"len(val_indices):\", len(val_indices))\n",
    "except ValueError as e:\n",
    "    print(e)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def generate_validation_indices(data_length, num_of_val_samples, sequence_length):\n",
    "    # Ustal minimalną odległość pomiędzy indeksami\n",
    "    min_distance_forward = sequence_length + 1\n",
    "    min_distance_backward = 2 * sequence_length + 1\n",
    "    print(\"min_distance_forward:\", min_distance_forward)\n",
    "    print(\"min_distance_backward:\", min_distance_backward)\n",
    "    # Utwórz listę możliwych indeksów\n",
    "    available_indices = list(range(data_length))\n",
    "\n",
    "    chosen_indices = []\n",
    "    for i in range(num_of_val_samples):\n",
    "        if not available_indices:\n",
    "            raise ValueError(\"Nie można wygenerować więcej próbek z uwzględnieniem minimalnego dystansu\")\n",
    "        array = np.array(available_indices)\n",
    "        # Losuj indeks z dostępnych indeksów\n",
    "        chosen_index = np.random.choice(available_indices)\n",
    "        chosen_indices.append(chosen_index)\n",
    "\n",
    "        # Oblicz zakres indeksów do usunięcia\n",
    "        start = max(0, chosen_index - min_distance_backward)\n",
    "        end = min(data_length, chosen_index + min_distance_forward)\n",
    "\n",
    "        # Usuń indeksy zbyt blisko wybranego indeksu\n",
    "        available_indices = [idx for idx in available_indices if idx < start or idx > end]\n",
    "        print(\"len(available_indices):\", len(available_indices))\n",
    "        # Wydrukuj postęp\n",
    "        print(\n",
    "            f\"Postęp: {i + 1}/{num_of_val_samples} indeksów wygenerowanych. ({(i + 1) / num_of_val_samples * 100:.2f}%)\")\n",
    "\n",
    "    return chosen_indices\n",
    "\n",
    "\n",
    "# Przykładowe wywołanie funkcji\n",
    "data_length = 100\n",
    "num_of_val_samples = 100\n",
    "sequence_length = 200\n",
    "\n",
    "try:\n",
    "    val_indices = generate_validation_indices(data_length, num_of_val_samples, sequence_length)\n",
    "    print(\"Wygenerowane indeksy walidacyjne:\", val_indices)\n",
    "    print(\"len(val_indices):\", len(val_indices))\n",
    "except ValueError as e:\n",
    "    print(e)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def generate_validation_indices(data_length, num_of_val_samples, sequence_length):\n",
    "    min_distance = sequence_length + 1  # Minimalna odległość pomiędzy indeksami\n",
    "    available_indices = set(range(data_length))  # Tworzymy zbiór dostępnych indeksów\n",
    "\n",
    "    chosen_indices = []\n",
    "    for _ in range(num_of_val_samples):\n",
    "        if len(available_indices) == 0:\n",
    "            raise ValueError(\"Nie można wygenerować więcej próbek z uwzględnieniem minimalnego dystansu\")\n",
    "\n",
    "        chosen_index = np.random.choice(list(available_indices))  # Losujemy z dostępnych indeksów\n",
    "        chosen_indices.append(chosen_index)\n",
    "\n",
    "        # Usuwamy indeksy w zakresie `sequence_length` w obie strony od wybranego indeksu\n",
    "        indices_to_remove = set(range(max(0, chosen_index - (2 * sequence_length) - 3),\n",
    "                                      min(data_length, chosen_index + (2 * sequence_length) + 3)))\n",
    "        available_indices.difference_update(indices_to_remove)  # Aktualizujemy zbiór dostępnych indeksów\n",
    "\n",
    "    return chosen_indices\n",
    "\n",
    "\n",
    "# Przykładowe wywołanie funkcji\n",
    "data_length = 1000\n",
    "num_of_val_samples = 10\n",
    "sequence_length = 50\n",
    "\n",
    "try:\n",
    "    val_indices = generate_validation_indices(data_length, num_of_val_samples, sequence_length)\n",
    "    print(\"Wygenerowane indeksy walidacyjne:\", val_indices)\n",
    "except ValueError as e:\n",
    "    print(e)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def generate_mask(data_length, chosen_indices, sequence_length):\n",
    "    # Ustal minimalną odległość pomiędzy indeksami\n",
    "    min_distance = sequence_length + 1\n",
    "    # Utwórz maskę początkową ze wszystkimi wartościami ustawionymi na True\n",
    "    mask = np.ones(data_length, dtype=bool)\n",
    "\n",
    "    # Iteruj przez każdy wybrany indeks walidacyjny\n",
    "    for index in chosen_indices:\n",
    "        # Ustal zakres indeksów, które należy ustawić na False\n",
    "        start = max(0, index - min_distance)\n",
    "        end = min(data_length, index + min_distance)\n",
    "\n",
    "        # Ustaw odpowiednie wartości w masce na False\n",
    "        mask[start:end] = False\n",
    "\n",
    "    # Zwróć indeksy, gdzie maska jest True, czyli indeksy zbioru treningowego\n",
    "    training_indices = np.where(mask)[0]  # np.where(mask) zwraca tuple, [0] wyciąga array z indeksami\n",
    "    return training_indices\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def plot_val_indices(data_length, val_indices, sequence_length):\n",
    "    # Ustal minimalną odległość pomiędzy indeksami\n",
    "    min_distance = sequence_length + 1\n",
    "\n",
    "    # Inicjalizacja figury\n",
    "    plt.figure(figsize=(10, 2))\n",
    "    plt.title(\"Rozkład indeksów walidacyjnych i ich zakresy\")\n",
    "    plt.xlabel(\"Indeksy danych\")\n",
    "    plt.ylabel(\"Wartość (dla wizualizacji)\")\n",
    "\n",
    "    # Rysowanie linii dla całej długości danych\n",
    "    plt.plot([0, data_length - 1], [1, 1], label='Dane', color='blue')\n",
    "\n",
    "    # Rysowanie punktów dla walidacyjnych indeksów\n",
    "    for index in val_indices:\n",
    "        plt.scatter([index], [1], color='red')  # punkt walidacyjny\n",
    "        start = max(0, index - min_distance)\n",
    "        end = min(data_length, index + min_distance)\n",
    "        plt.axvspan(start, end, color='red', alpha=0.3)  # zakres wokół punktu)\n",
    "\n",
    "    plt.legend(['Dane', 'Indeksy walidacyjne i zakres'])\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Przykładowe wywołanie funkcji\n",
    "data_length = 200\n",
    "num_of_val_samples = 10\n",
    "sequence_length = 4\n",
    "\n",
    "try:\n",
    "    val_indices = generate_validation_indices(data_length, num_of_val_samples, sequence_length)\n",
    "    plot_val_indices(data_length, val_indices, sequence_length)\n",
    "except ValueError as e:\n",
    "    print(e)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def plot_train_val_indices(data_length, train_indices, val_indices, sequence_length):\n",
    "    # Ustal minimalną odległość pomiędzy indeksami\n",
    "    min_distance = sequence_length + 1\n",
    "\n",
    "    # Inicjalizacja figury\n",
    "    plt.figure(figsize=(10, 2))\n",
    "    plt.title(\"Rozkład indeksów walidacyjnych i ich zakresy\")\n",
    "    plt.xlabel(\"Indeksy danych\")\n",
    "    plt.ylabel(\"Wartość (dla wizualizacji)\")\n",
    "\n",
    "    # Rysowanie linii dla całej długości danych\n",
    "    plt.plot([0, data_length - 1], [1, 1], label='Dane', color='blue')\n",
    "\n",
    "    # Rysowanie punktów dla walidacyjnych indeksów\n",
    "    for index in val_indices:\n",
    "        plt.scatter([index], [1], color='red')  # punkt walidacyjny\n",
    "        start = max(0, index - min_distance)\n",
    "        end = min(data_length, index + min_distance)\n",
    "        plt.axvspan(start, end, color='red', alpha=0.3)  # zakres wokół punktu)\n",
    "    # if train_indices is not empty:\n",
    "    for index in train_indices:\n",
    "        plt.scatter([index], [1], color='red')  # punkt walidacyjny\n",
    "        start = index\n",
    "        end = min(data_length, index + min_distance)\n",
    "        plt.axvspan(start, end, color='blue', alpha=0.1)  # zakres wokół punktu)\n",
    "\n",
    "    plt.legend(['Dane', 'Indeksy walidacyjne i zakres'])\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Przykładowe wywołanie funkcji\n",
    "data_length = 200\n",
    "num_of_val_samples = 10\n",
    "sequence_length = 5\n",
    "\n",
    "try:\n",
    "    val_indices = generate_validation_indices(data_length, num_of_val_samples, sequence_length)\n",
    "    train_indices = generate_mask(data_length, val_indices, sequence_length)\n",
    "    plot_val_indices(data_length, val_indices, sequence_length)\n",
    "    plot_train_val_indices(data_length, train_indices, val_indices, sequence_length)\n",
    "except ValueError as e:\n",
    "    print(e)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def generate_mask(data_length, chosen_indices, sequence_length):\n",
    "    # Ustal minimalną odległość pomiędzy indeksami\n",
    "    min_distance = sequence_length + 1\n",
    "    # Utwórz maskę początkową ze wszystkimi wartościami ustawionymi na True\n",
    "    mask = np.ones(data_length, dtype=bool)\n",
    "\n",
    "    # Iteruj przez każdy wybrany indeks walidacyjny\n",
    "    for index in chosen_indices:\n",
    "        # Ustal zakres indeksów, które należy ustawić na False\n",
    "        start = max(0, index - min_distance)\n",
    "        end = min(data_length, index + min_distance)\n",
    "\n",
    "        # Ustaw odpowiednie wartości w masce na False\n",
    "        mask[start:end] = False\n",
    "\n",
    "    # Zwróć indeksy, gdzie maska jest True, czyli indeksy zbioru treningowego\n",
    "    training_indices = np.where(mask)[0]  # np.where(mask) zwraca tuple, [0] wyciąga array z indeksami\n",
    "    return training_indices\n",
    "\n",
    "\n",
    "# Przykładowe wywołanie funkcji\n",
    "data_length = 200\n",
    "num_of_val_samples = 10\n",
    "sequence_length = 4\n",
    "\n",
    "try:\n",
    "    val_indices = generate_validation_indices(data_length, num_of_val_samples, sequence_length)\n",
    "    training_indices = generate_mask(data_length, val_indices, sequence_length)\n",
    "    plot_validation_indices(data_length, training_indices, val_indices, sequence_length)\n",
    "    print(\"Wygenerowane indeksy walidacyjne:\", val_indices)\n",
    "    print(\"Indeksy zbioru treningowego:\", training_indices)\n",
    "except ValueError as e:\n",
    "    print(e)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "randomlist = [1, 2, 9, 10]\n",
    "index = np.random.choice(randomlist)\n",
    "index"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Przykładowe wywołanie funkcji\n",
    "data_length = 1000\n",
    "num_of_val_samples = 10\n",
    "sequence_length = 30\n",
    "\n",
    "try:\n",
    "    val_indices = generate_validation_indices(data_length, num_of_val_samples, sequence_length)\n",
    "    training_indices = generate_mask(data_length, val_indices, sequence_length)\n",
    "    print(\"len(training_indices):\", len(training_indices))\n",
    "except ValueError as e:\n",
    "    print(e)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "!pip install sidekit\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T14:45:31.987444Z",
     "start_time": "2024-06-06T14:45:31.959020Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import psycopg2\n",
    "\n",
    "conn = psycopg2.connect(database=\"dbval\", host=\"0.0.0.0\", user=\"user\", password=\"1234\", port=\"5434\")\n",
    "cursor = conn.cursor()\n",
    "query = (\n",
    "    \"SELECT cwt_data, target FROM wavelet_transforms WHERE id BETWEEN %s AND %s\"\n",
    ")\n",
    "\n",
    "cursor.execute(query, (4 + 1, 4 + 10))\n",
    "rows = cursor.fetchall()\n",
    "print(rows)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(<memory at 0x7db4a3fed840>, 0), (<memory at 0x7db4a3fed000>, 0), (<memory at 0x7db4a3fecf40>, 0), (<memory at 0x7db4a3fed900>, 0), (<memory at 0x7db4a3fed9c0>, 0), (<memory at 0x7db4a3feda80>, 0), (<memory at 0x7db4a3fedb40>, 0), (<memory at 0x7db4a3fedc00>, 0), (<memory at 0x7db4a3fedcc0>, 0), (<memory at 0x7db4a3fedd80>, 0)]\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (EEG311)",
   "language": "python",
   "name": "eeg311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
