{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import mne\n",
    "import pywt\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch import nn\n",
    "import torch\n",
    "import pickle\n",
    "import os\n",
    "from datetime import datetime\n",
    "import sqlite3\n",
    "from pytorch_lightning import LightningModule, Trainer\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "from torchmetrics.functional.classification.accuracy import accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Training on device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def read_cwt_data(db_path):\n",
    "#     conn = sqlite3.connect(db_path)\n",
    "#     cursor = conn.cursor()\n",
    "#     cursor.execute(\"SELECT cwt_data FROM wavelet_transforms\")\n",
    "#     data = cursor.fetchall()\n",
    "#     conn.close()\n",
    "\n",
    "#     # Deserializacja danych\n",
    "#     cwt_arrays = [pickle.loads(d[0]) for d in data]\n",
    "#     return cwt_arrays\n",
    "\n",
    "\n",
    "# # Odczytanie danych z bazy danych\n",
    "# cwt_data_list = read_cwt_data(\"cwt_data.db\")\n",
    "\n",
    "\n",
    "# # Przykładowy odczyt jednego tensora CWT\n",
    "# print(cwt_data_list[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CWTDataset(Dataset):\n",
    "    def __init__(self, db_path, sequence_length=4000):\n",
    "        self.db_path = db_path\n",
    "        self.sequence_length = sequence_length\n",
    "        self.conn = sqlite3.connect(db_path)\n",
    "        self.cursor = self.conn.cursor()\n",
    "        self.cursor.execute(\"SELECT COUNT(*) FROM wavelet_transforms\")\n",
    "        self.total_samples = self.cursor.fetchone()[0]\n",
    "\n",
    "    def __len__(self):\n",
    "        # Aby umożliwić nachodzenie, liczba możliwych sekwencji będzie równa liczbie próbek minus długość sekwencji + 1\n",
    "        return self.total_samples - self.sequence_length + 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Zwraca sekwencję próbek i target z ostatniej próbki\n",
    "        \n",
    "        query = (\n",
    "            \"SELECT cwt_data, target FROM wavelet_transforms WHERE id BETWEEN ? AND ?\"\n",
    "        )\n",
    "        print(query,(idx + 1, idx + self.sequence_length))\n",
    "        self.cursor.execute(\n",
    "            query, (idx + 1, idx + self.sequence_length)\n",
    "        )  # SQLite indeksuje od 1\n",
    "        rows = self.cursor.fetchall()\n",
    "\n",
    "        cwt_sequence = np.array([pickle.loads(row[0]) for row in rows])\n",
    "\n",
    "        # Target ostatniej próbki w sekwencji\n",
    "        target = rows[-1][1]\n",
    "\n",
    "        cwt_tensor = torch.tensor(cwt_sequence, dtype=torch.float32)\n",
    "        target_tensor = torch.tensor(target, dtype=torch.int64)\n",
    "        return cwt_tensor, target_tensor\n",
    "\n",
    "    def __del__(self):\n",
    "        self.conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Tworzenie instancji datasetu\n",
    "cwt_dataset = CWTDataset('cwt_data.db', 4000)\n",
    "\n",
    "# batch_size = 10  # Liczba sekwencji w jednym batchu\n",
    "# train_loader = DataLoader(dataset=cwt_dataset, batch_size=batch_size, shuffle=True,num_workers=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT cwt_data, target FROM wavelet_transforms WHERE id BETWEEN ? AND ? (1, 4000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4000, 64, 10])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwt_dataset.__getitem__(0)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT cwt_data, target FROM wavelet_transforms WHERE id BETWEEN ? AND ? (2, 4001)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4000, 64, 10])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwt_dataset.__getitem__(1)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT cwt_data, target FROM wavelet_transforms WHERE id BETWEEN ? AND ? (2001, 6000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwt_dataset.__getitem__(2000)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class LSTMModel(nn.Module):\n",
    "#     def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "#         super(LSTMModel, self).__init__()\n",
    "#         self.hidden_dim = hidden_dim\n",
    "#         self.layer_dim = layer_dim\n",
    "#         self.lstm = nn.LSTM(input_dim, hidden_dim, layer_dim, batch_first=True)\n",
    "#         self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         # Inicjalizacja stanów ukrytych\n",
    "#         h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim, device=x.device)\n",
    "#         c0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim, device=x.device)\n",
    "        \n",
    "#         # Forward pass through LSTM layer\n",
    "#         out, (hn, cn) = self.lstm(x, (h0, c0))\n",
    "        \n",
    "#         # Forward pass through linear layer\n",
    "#         out = self.fc(out[:, -1, :])\n",
    "#         return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Parametry\n",
    "# input_dim = 640\n",
    "# hidden_dim = 100\n",
    "# layer_dim = 1\n",
    "# output_dim = 1\n",
    "# num_epochs = 20\n",
    "# learning_rate = 0.01\n",
    "\n",
    "# model = LSTMModel(input_dim, hidden_dim, layer_dim, output_dim).to(device)\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# # Pętla treningowa\n",
    "# for epoch in range(num_epochs):\n",
    "#     model.train()\n",
    "#     total_loss = 0\n",
    "#     for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "#         # Przeniesienie danych na GPU\n",
    "#         data = data.view(-1, 4000, 640).to(device)\n",
    "#         targets = targets.to(device)\n",
    "        \n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(data)\n",
    "        \n",
    "#         loss = criterion(outputs, targets.float().unsqueeze(1))\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "#         total_loss += loss.item()\n",
    "#         print(f'Epoch: {epoch+1}, Batch: {batch_idx+1}/{len(train_loader)}, Loss: {loss.item():.4f}')\n",
    "#     avg_train_loss = train_loss / len(train_loader)\n",
    "#     # Walidacja\n",
    "#     val_loss = evaluate_model(model, validation_loader, device)  # załóżmy, że mamy validation_loader\n",
    "\n",
    "#     # Wyświetlanie postępów\n",
    "#     print(f'Epoch: {epoch+1}, Training Loss: {avg_train_loss:.4f}, Validation Loss: {val_loss:.4f}')\n",
    "\n",
    "#     # Zapisywanie modelu, gdy jest najlepszy na walidacji\n",
    "#     if val_loss < best_val_loss:\n",
    "#         best_val_loss = val_loss\n",
    "#         torch.save(model.state_dict(), 'best_model.pth')\n",
    "#         print(f'Best model saved with validation loss: {val_loss:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True, num_workers=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CWT_EEG(LightningModule):\n",
    "    def __init__(self,batch_size, input_size, hidden_size, num_layers, lr , label_smoothing=0):\n",
    "        super().__init__()\n",
    "        self.hparams.batch_size=batch_size\n",
    "        self.hparams.lr = lr\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.num_of_classes = 3\n",
    "\n",
    "        self.save_hyperparameters()\n",
    "        self.val_percent = 0.2\n",
    "        self.loss = torch.nn.CrossEntropyLoss(label_smoothing=label_smoothing)\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, self.num_of_classes)  # Klasyfikacja na 3 klasy\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "\n",
    "        out, (hn, cn) = self.lstm(x, (h0, c0), device=x.device)\n",
    "        out = hn[-1, :, :]  # Ostatnia warstwa LSTM (batch_size, hidden_size)\n",
    "        out = self.fc(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "    # custom\n",
    "    def count_parameters(model):\n",
    "        return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "    # only for HP\n",
    "    def on_train_start(self):\n",
    "        self.logger.log_hyperparams(\n",
    "            self.hparams,\n",
    "            {\n",
    "                \"hp/train_loss\": float(\"nan\"),\n",
    "                \"hp/train_acc\": float(\"nan\"),\n",
    "                \"hp/val_loss\": float(\"nan\"),\n",
    "                \"hp/val_acc\": float(\"nan\"),\n",
    "            },\n",
    "        )\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.loss(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = accuracy(preds, y)\n",
    "\n",
    "        self.log(\"hp/train_loss\", loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"hp/train_acc\", acc, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.hparams.lr)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.loss(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = accuracy(preds, y)\n",
    "\n",
    "        self.log(\"hp/val_loss\", loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"hp/val_acc\", acc, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.ds = CWTDataset(\"cwt_data.db\", 4000)\n",
    "        val_count = int(self.val_percent * len(self.ds))\n",
    "        self.train_set, self.val_set = torch.utils.data.random_split(\n",
    "            self.ds, [len(self.ds) - val_count, val_count]\n",
    "        )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.train_set, batch_size=self.hparams.batch_size, num_workers=12\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.val_set, batch_size=self.hparams.batch_size, num_workers=12\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "lr = 0.001\n",
    "\n",
    "model = CWT_EEG( batch_size= 4000 ,input_size=10 , num_layers=10,hidden_size=10, lr=lr)\n",
    "logger = TensorBoardLogger(\"lightning_logs\", name=\"CWT_EEG\")\n",
    "trainer = Trainer(\n",
    "    max_epochs=10,\n",
    "    logger=logger\n",
    ")\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EEG311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
