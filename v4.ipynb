{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#334a4ba3ee7a3dc9ff8373e22d7cf2fd31e6198668a4ae16\n",
    "#!pip install PyWavelets mne  pandas numpy matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import mne\n",
    "import pywt\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "import pickle\n",
    "import os\n",
    "from datetime import datetime\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_to_DataDrame(path):\n",
    "    \"\"\"\n",
    "    This function takes in a file path and returns a dataframe with the data and the target values\n",
    "    format:\n",
    "        Fc5\t        Fc3\t        Fc1\t        ...\tOz\t        O2\t        Iz\t        target\n",
    "    0\t-0.000046\t-0.000041\t-0.000032\t...\t0.000040\t0.000108\t0.000055\t0\n",
    "    1\t-0.000054\t-0.000048\t-0.000034\t...\t0.000064\t0.000114\t0.000074\t0\n",
    "    ...\n",
    "    \"\"\"\n",
    "\n",
    "    reader = mne.io.read_raw_edf(path, preload=True)\n",
    "    annotations = reader.annotations  # get the values of the annotations\n",
    "    codes = annotations.description  # get the codes from the annotations\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        reader.get_data().T,\n",
    "        columns=[channel.replace(\".\", \"\") for channel in reader.ch_names],\n",
    "    )  # transpose the data to get the right shape\n",
    "    df = df[~(df == 0).all(axis=1)]  # remove rows with all zeros\n",
    "    timeArray = np.array(\n",
    "        [round(x, 10) for x in np.arange(0, len(df) / 160, 0.00625)]\n",
    "    )  # create an array of time values\n",
    "\n",
    "    codeArray = []\n",
    "    counter = 0\n",
    "    for timeVal in timeArray:\n",
    "        if (\n",
    "            timeVal in annotations.onset\n",
    "        ):  # if the time value is in the onset array, add the corresponding code to the codeArray\n",
    "            counter += 1\n",
    "        code_of_target = int(\n",
    "            codes[counter - 1].replace(\"T\", \"\")\n",
    "        )  # convert T0 to 0, T1 to 1, etc\n",
    "        codeArray.append(code_of_target)\n",
    "\n",
    "    df[\"target\"] = np.array(codeArray).T\n",
    "    return df\n",
    "\n",
    "\n",
    "def save_to_pickle(data, filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "    print(f\"File {filename} saved successfully.\")\n",
    "\n",
    "\n",
    "\n",
    "def load_from_pickle(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    print(f\"File {filename} loaded successfully.\")\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_all_file_df(num_exp=[3, 4], num_people=2):\n",
    "    \"\"\"condct all files in one dataframe\"\"\"\n",
    "    all_df = pd.DataFrame()\n",
    "    for subject in range(1, num_people):\n",
    "        for file in num_exp:\n",
    "            fileName = f\"files/S{subject:03d}/S{subject:03d}R{file:02d}.edf\"\n",
    "            df = file_to_DataDrame(fileName)\n",
    "            all_df = pd.concat([all_df, df], axis=0)\n",
    "    return all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from /home/daniel/repos/Decoding_of_EEG/files/S001/S001R03.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Extracting EDF parameters from /home/daniel/repos/Decoding_of_EEG/files/S001/S001R04.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n"
     ]
    }
   ],
   "source": [
    "df = read_all_file_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pickle\n",
    "\n",
    "\n",
    "def create_database(db_path):\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\n",
    "        \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS wavelet_transforms (\n",
    "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "            cwt_data BLOB,\n",
    "            target INTEGER\n",
    "        )\n",
    "    \"\"\"\n",
    "    )\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "\n",
    "def insert_cwt_data(db_path, cwt_data, targets):\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "    cwt_data = cwt_data.transpose(2, 0, 1)\n",
    "    \n",
    "    cwt_data = cwt_data.reshape(cwt_data.shape[0], -1) # <-------- this is option \n",
    "    print(f\"success save: {cwt_data.shape}\")\n",
    "    i = 0\n",
    "    for single_cwt in cwt_data:\n",
    "\n",
    "        cwt_blob = pickle.dumps(np.array(single_cwt, dtype=np.float32))\n",
    "        cursor.execute(\n",
    "            \"INSERT INTO wavelet_transforms (cwt_data, target) VALUES (?, ?)\",\n",
    "            (cwt_blob, targets[i]),\n",
    "        )\n",
    "        i += 1\n",
    "    conn.commit()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_CWTfiles(\n",
    "    df, num_of_rows=1000, wave=\"cgau4\", frq=160, resolution=100, db_path=\"cwt_data.db\"\n",
    "):\n",
    "    # Utworzenie bazy danych, jeÅ›li nie istnieje\n",
    "    create_database(db_path)\n",
    "\n",
    "    for i in range(0, len(df), num_of_rows):\n",
    "        if i + num_of_rows > len(df):\n",
    "            break\n",
    "        signals = df.iloc[i : i + num_of_rows].values\n",
    "        list_cwt = []\n",
    "        targets = ()\n",
    "        if signals.shape == (num_of_rows, 65):\n",
    "            signals = signals.transpose(1, 0)\n",
    "        j = 0\n",
    "        # print(len(signals))\n",
    "        for signal in signals:\n",
    "            j += 1\n",
    "            if j == len(signals):\n",
    "                targets = signal\n",
    "                break\n",
    "            signal = (signal - np.min(signal)) / (np.max(signal) - np.min(signal))\n",
    "            time = np.linspace(0, len(signal) / frq, len(signal))\n",
    "            widths = np.geomspace(1, 200, num=resolution)\n",
    "            sampling_period = np.diff(time).mean()\n",
    "            cwtmatr, freqs = pywt.cwt(\n",
    "                signal, widths, wave, sampling_period=sampling_period\n",
    "            )\n",
    "            cwtmatr = np.abs(cwtmatr)\n",
    "            list_cwt.append(cwtmatr)\n",
    "\n",
    "        array_cwt = np.stack(list_cwt, axis=0)\n",
    "        insert_cwt_data(db_path, array_cwt, targets)  # Zapis do bazy danych\n",
    "        del array_cwt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success save: (1000, 640)\n",
      "success save: (1000, 640)\n",
      "success save: (1000, 640)\n",
      "success save: (1000, 640)\n",
      "success save: (1000, 640)\n",
      "success save: (1000, 640)\n",
      "success save: (1000, 640)\n",
      "success save: (1000, 640)\n",
      "success save: (1000, 640)\n",
      "success save: (1000, 640)\n",
      "success save: (1000, 640)\n",
      "success save: (1000, 640)\n",
      "success save: (1000, 640)\n",
      "success save: (1000, 640)\n",
      "success save: (1000, 640)\n",
      "success save: (1000, 640)\n",
      "success save: (1000, 640)\n",
      "success save: (1000, 640)\n",
      "success save: (1000, 640)\n",
      "success save: (1000, 640)\n",
      "success save: (1000, 640)\n",
      "success save: (1000, 640)\n",
      "success save: (1000, 640)\n",
      "success save: (1000, 640)\n",
      "success save: (1000, 640)\n",
      "success save: (1000, 640)\n",
      "success save: (1000, 640)\n",
      "success save: (1000, 640)\n",
      "success save: (1000, 640)\n",
      "success save: (1000, 640)\n",
      "success save: (1000, 640)\n",
      "success save: (1000, 640)\n",
      "success save: (1000, 640)\n",
      "success save: (1000, 640)\n",
      "success save: (1000, 640)\n",
      "success save: (1000, 640)\n",
      "success save: (1000, 640)\n",
      "success save: (1000, 640)\n",
      "success save: (1000, 640)\n"
     ]
    }
   ],
   "source": [
    "df_to_CWTfiles(\n",
    "    df, num_of_rows=1000, wave=\"cgau4\", frq=160, resolution=10, db_path=\"cwt_data.db\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EEG311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
